@article{doi:10.1177/1176934319840289,
author = {Teerna Bhattacharyya and Ramanathan Sowdhamini},
title = {Genome-Wide Search for Tyrosine Phosphatases in the Human Genome Through Computational Approaches Leads to the Discovery of Few New Domain Architectures},
journal = {Evolutionary Bioinformatics},
volume = {15},
number = { },
pages = {1176934319840289},
year = {2019a},
doi = {10.1177/1176934319840289},
note = {PMID:31007525},
URL = {https://doi-org.crai.referencistas.com/10.1177/1176934319840289},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1176934319840289},
abstract = {Reversible phosphorylation maintained by protein kinases and phosphatases is an integral part of intracellular signalling, and phosphorylation on tyrosine is extensively utilised in higher eukaryotes. Tyrosine phosphatases are enzymes that not only scavenge phosphotyrosine but are also involved in wide range of signalling pathways. As a result, mutations in these enzymes have been implicated in the pathogenesis of several diseases like cancer, autoimmune disorders, and muscle-related diseases. The genes that harbour phosphatase domain also display diversity in co-existing domains suggesting the recruitment of the catalytic machinery in diverse pathways. We have examined the current draft of the human genome, using a combination of 3 sequence search methods and validations, and identified 101 genes encoding tyrosine phosphatase-containing gene products, agreeing with previous reports. Such gene products adopt 37 unique domain architectures (DAs), including few new ones and harbouring few co-existing domains that have not been reported before. This semi-automated computational approach for detection of gene products belonging to a particular superfamily can now be easily applied at whole genome level on other mammalian genomes and for other protein domains as well.}
}

@article{doi:10.1177/10755470231165941,
author = {Miles C. Coleman and Brandon Simon and Matt Pierce and Charles A. Schutte},
title = {Emergent Sonification: Using Computational Media to Communicate the Anthropocene in ByrdBot},
journal = {Science Communication},
volume = {45},
number = {2},
pages = {252–266},
year = {2023b},
doi = {10.1177/10755470231165941},
URL = {https://doi-org.crai.referencistas.com/10.1177/10755470231165941},
eprint = {https://doi-org.crai.referencistas.com/10.1177/10755470231165941},
abstract = {This research note describes ByrdBot, a science communication tool that leverages bird songs to communicate data regarding human impacts on the environment. With ByrdBot, listeners can compare simulated soundscapes of 1970, 2017, and 2065 to immediately, and viscerally, experience decades of past or projected future environmental change. The communication tactic of ByrdBot—what we call emergent sonification—is discussed as one that capitalizes on computational media to facilitate attunement to nonhuman voices and, subsequently, to offer an affective grasping of the impacts of such phenomena as habitat destruction and climate change on wildlife displacement and loss.}
}

@article{doi:10.1177/09610006241265102,
author = {Rosaura Fernández-Pascual and Maria Pinto and Francisco Javier García Marco},
title = {Emergence and evolution of data literacy: Insights from a bibliometric study},
journal = {Journal of Librarianship and Information Science},
volume = {0},
number = {0},
pages = {09610006241265102},
year = {2024c},
doi = {10.1177/09610006241265102},
URL = {https://doi-org.crai.referencistas.com/10.1177/09610006241265102},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09610006241265102},
abstract = {This study aims to contribute to the pertinent body of knowledge by examining the field of data literacy (DL) to better understand its trends and evolution, thematic clusters, relevant studies and the most productive authors and journals. The analysis of scientific literature indexed by Web of Science from 1980 to 2023 (n = 1704 items) combined co-occurrence (using VOSviewer) and co-citation (using CiteSpace) techniques based on the words in the title and abstract, as well as the keywords, authors and journals. There is evidence of four main trend topics (Data Literacy, Statistical Literacy, Data-based assessment and e-society) and six thematic clusters (Data Literacy, Statistical Literacy, Quantitative Literacy, Big Data, Data Science and Quantitative Skills). With DL emerging in 2011, the research initially focused on both quantitative and statistical literacy, and later (2012–2016) shifted toward applying statistical literacy to various disciplines. Since 2018, the use of data has led to the emergence of fields like big data and data science, resulting in progress being made in data literacy. The combination of the two analysis techniques offers complementary perspectives: co-word analysis reveals fields of application, and co-citation analysis shows the internal evolution of the discipline. This study evidences a significant increase in publications on DL, indicating its expansion to several disciplines and a promising, yet uncertain, future.}
}

@article{doi:10.1177/1350650117743684,
author = {Qiang Gao and Lihua Lu and Wanqun Chen and Guanglin Wang},
title = {Optimal design of an annular thrust air bearing using parametric computational fluid dynamics model and genetic algorithms},
journal = {Proceedings of the Institution of Mechanical Engineers, Part J: Journal of Engineering Tribology},
volume = {232},
number = {10},
pages = {1203–1214},
year = {2018d},
doi = {10.1177/1350650117743684},
URL = {https://doi-org.crai.referencistas.com/10.1177/1350650117743684},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1350650117743684},
abstract = {The performance of air bearing is highly influenced by the geometrical parameters of its restrictor. This study aims to maximize the load-carrying capacity and stiffness of air bearing, and minimize its volume flow rate by optimizing the geometrical parameters of restrictor. To facilitate the calculation of air bearing performance, a parametric computational fluid dynamics model is developed. Then, it is combined with multiobjective optimization genetic algorithm to search the Pareto optimal solutions. Furthermore, as a case study, the optimal design of an annular thrust air bearing is implemented. The stiffness of air bearing is improved 38.5%, the load-carrying capacity is improved 33.9%, and the volume flow rate is declined 19.6%, which are finally validated by experiments. It proves the reliability of proposed parametric computational fluid dynamics model and genetic optimization algorithm.}
}

@article{doi:10.5301/jva.5000226,
author = {David M. Hoganson and Cameron J. Hinkel and Xiaomin Chen and Ramesh K. Agarwal and Surendra Shenoy},
title = {Validation of Computational Fluid Dynamics-Based Analysis to Evaluate                     Hemodynamic Significance of access Stenosis},
journal = {The Journal of Vascular Access},
volume = {15},
number = {5},
pages = {409–414},
year = {2014e},
doi = {10.5301/jva.5000226},
note = {PMID:24811588},
URL = {https://doi-org.crai.referencistas.com/10.5301/jva.5000226},
eprint = {https://doi-org.crai.referencistas.com/10.5301/jva.5000226},
abstract = {Purpose Stenosis in a vascular access circuit is the predominant cause of access dysfunction. Hemodynamic significance of a stenosis identified by angiography in an access circuit is uncertain. This study utilizes computational fluid dynamics (CFD) to model flow through arteriovenous fistula to predict the functional significance of stenosis in vascular access circuits. Methods Three-dimensional models of fistulas were created with a range of clinically relevant stenoses using SolidWorks. Stenoses diameters ranged from 1.0 to 3.0 mm and lengths from 5 to 60 mm within a fistula diameter of 7 mm. CFD analyses were performed using a blood model over a range of blood pressures. Eight patient-specific stenoses were also modeled and analyzed with CFD and the resulting blood flow calculations were validated by comparison with brachial artery flow measured by duplex ultrasound. Results Predicted flow rates were derived from CFD analysis of a range of stenoses. These stenoses were modeled by CFD and correlated with the ultrasound measured flow rate through the fistula of eight patients. The calculated flow rate using CFD correlated within 20% of ultrasound measured flow for five of eight patients. The mean difference was 17.2% (ranged from 1.3% to 30.1%). Conclusions CFD analysis-generated flow rate tables provide valuable information to assess the functional significance of stenosis detected during imaging studies. The CFD study can help in determining the clinical relevance of a stenosis in access dysfunction and guide the need for intervention.}
}

@article{doi:10.1179/0308018814Z.00000000082,
author = {Wolfgang Kaltenbrunner},
title = {Decomposition as Practice and Process: Creating Boundary Objects in Computational Humanities},
journal = {Interdisciplinary Science Reviews},
volume = {39},
number = {2},
pages = {143–161},
year = {2014f},
doi = {10.1179/0308018814Z.00000000082},
URL = {https://doi-org.crai.referencistas.com/10.1179/0308018814Z.00000000082},
eprint = {https://doi-org.crai.referencistas.com/10.1179/0308018814Z.00000000082},
abstract = {The emergent reflexive process, by which researchers in a computational humanities project work towards a viable organizational modality for interdisciplinary collaboration, is analyzed. Using the metaphor of decomposition, successful collaboration between computer scientists and humanities scholars can be seen to require a reflexive scrutiny — a decomposition — of the disciplinary research processes that are involved, thus allowing crucial differences with respect to typical ways of posing research questions, the role of data, and the rhythm of the research process to be highlighted. It is argued that the currently popular expectation towards data as a self-identical organizational unit tends to downplay the role of decomposition as practice and process. A European cyberinfrastructure initiative that tries to respect the specificities of scholarly practice in the humanities is critically assessed, reflecting in particular on the inherent tension between ‘mutual shaping’ of digital tools and their users on the one hand, and the policy interest in efficient, functionalist design principles on the other.}
}

@article{doi:10.1177/0165551515615842,
author = {Saraschandra Karanam and Herre van Oostendorp and Wai Tat Fu},
title = {Performance of computational cognitive models of web-navigation on real websites},
journal = {Journal of Information Science},
volume = {42},
number = {1},
pages = {94–113},
year = {2016g},
doi = {10.1177/0165551515615842},
URL = {https://doi-org.crai.referencistas.com/10.1177/0165551515615842},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0165551515615842},
abstract = {Computational cognitive models of web-navigation developed so far have largely been tested only on mock-up websites. In this paper, for the first time, we compare and contrast the performance of two models, CoLiDeS and CoLiDeS+, on two real websites from the domains of technology and health, under two conditions of task difficulty, simple and difficult. We found that CoLiDeS+ predicted more hyperlinks on the correct path and had a higher path completion ratio than CoLiDeS. CoLiDeS+ found the target page more often than CoLiDeS, took more steps to reach the target page and was more ‘disoriented’ than CoLiDeS for difficult tasks. Difficult tasks in general for both models had less task success and lower path completion ratio, predicted less hyperlinks on the correct path, visited pages with lower mean LSA and took more steps to complete compared with simple tasks. Overall, inclusion of context from previously visited pages and implementation of backtracking strategies (which are both part of CoLiDeS+) led to better modelling performance. Suggestions to further improve the performance of these computational cognitive models on real websites are discussed.}
}

@article{doi:10.1179/1743285514Y.0000000056,
author = {D. R. Swinbourne},
title = {Understanding ferronickel smelting from laterites through computational thermodynamics modelling},
journal = {Mineral Processing and Extractive Metallurgy},
volume = {123},
number = {3},
pages = {127–140},
year = {2014h},
doi = {10.1179/1743285514Y.0000000056},
URL = {https://doi-org.crai.referencistas.com/10.1179/1743285514Y.0000000056},
eprint = {https://doi-org.crai.referencistas.com/10.1179/1743285514Y.0000000056},
abstract = {The smelting of nickel laterite ores to ferronickel alloy is unique in extractive metallurgy. It treats feed that is very low grade with respect to the target metal and, as a result, produces much more waste slag than valuable metal product. The energy consumption per tonne of product is therefore high and requires sustained research and design development in an effort to improve the economics of laterite smelting. In this work, the main characteristics of nickel laterite smelting are reviewed, and then a simple and transparent computational thermodynamics model of the electric furnace smelting step is developed. This model predicts the nickel grade, nickel recovery and FeO content of the slag as functions of the iron recovery to ferronickel satisfactorily. It correctly predicts that the carbon and silicon contents in ferronickel increase sharply at high iron recoveries. However, in common with more sophisticated models, it incorrectly predicts the iron recovery at which this increase is observed in practice. It is concluded that the model provides an accessible and a satisfactorily accurate vehicle for understanding the relationships between process variables and process outcomes during nickel laterite smelting.}
}

@article{doi:10.1177/1094428118780308,
author = {Jeffrey B. Vancouver and Mo Wang and Xiaofei Li},
title = {Translating Informal Theories Into Formal Theories: The Case of the Dynamic Computational Model of the Integrated Model of Work Motivation},
journal = {Organizational Research Methods},
volume = {23},
number = {2},
pages = {238–274},
year = {2020i},
doi = {10.1177/1094428118780308},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094428118780308},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094428118780308},
abstract = {Theories are the core of any science, but many imprecisely stated theories in organizational and management science are hampering progress in the field. Computational modeling of existing theories can help address the issue. Computational models are a type of formal theory that are represented mathematically or by other formal logic and can be simulated, allowing theorists to assess whether the theory can explain the phenomena intended as well as make testable predictions. As an example of the process, Locke’s integrated model of work motivation is translated into static and dynamic computational models. Simulations of these models are compared to the empirical data used to develop and test the theory. For the static model, the simulations revealed largely strong associations with robust empirical findings. However, adding dynamics created several challenges to key precepts of the theory. Moreover, the effort revealed where empirical work is needed to further refine or refute the theory. Discussion focuses on the value of computational modeling as a method for formally testing, pruning, and extending extant theories in the field.}
}

@article{doi:10.4137/BECB.S5594,
author = {Zahra Zamani and Amirhossein Hajihosseini and Ali Masoudi-Nejad},
title = {Computational Methodologies for Analyzing, Modeling and Controlling Gene Regulatory Networks},
journal = {Biomedical Engineering and Computational Biology},
volume = {2},
number = { },
pages = {BECB.S5594},
year = {2010j},
doi = {10.4137/BECB.S5594},
URL = {https://doi-org.crai.referencistas.com/10.4137/BECB.S5594},
eprint = {https://doi-org.crai.referencistas.com/10.4137/BECB.S5594},
abstract = {Molecular biology focuses on genes and their interactions at the transcription, regulation and protein level. Finding genes that cause certain behaviors can make therapeutic interventions more effective. Although biological tools can extract the genes and perform some analyses, without the help of computational methods, deep insight of the genetic function and its effects will not occur. On the other hand, complex systems can be modeled by networks, introducing the main data as nodes and the links in-between as the transactions occurring within the network. Gene regulatory networks are examples that are modeled and analyzed in order to gain insight of their exact functions. Since a cell’s specific functionality is greatly determined by the genes it expresses, translation or the act of converting mRNA to proteins is highly regulated by the control network that directs cellular activities. This paper briefly reviews the most important computational methods for analyzing, modeling and controlling the gene regulatory networks.}
}

