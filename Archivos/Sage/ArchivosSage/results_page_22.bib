@article{doi:10.3233/FI-2020-1872,
author = {Daniela Besozzi and Luca Manzoni and Marco S. Nobile and Simone Spolaor and Mauro Castelli and Leonardo Vanneschi and Paolo Cazzaniga and Stefano Ruberto and Leonardo Rundo and Andrea Tangherloni et al.},
title = {Computational Intelligence for Life Sciences},
journal = {Fundamenta Informaticae},
volume = {171},
number = {1–4},
pages = {57–80},
year = {2019a},
doi = {10.3233/FI-2020-1872},
URL = {https://doi-org.crai.referencistas.com/10.3233/FI-2020-1872},
eprint = {https://doi-org.crai.referencistas.com/10.3233/FI-2020-1872},
abstract = {Computational Intelligence (CI) is a computer science discipline encompassing the theory, design, development and application of biologically and linguistically derived computational paradigms. Traditionally, the main elements of CI are Evolutionary Computation, Swarm Intelligence, Fuzzy Logic, and Neural Networks. CI aims at proposing new algorithms able to solve complex computational problems by taking inspiration from natural phenomena. In an intriguing turn of events, these nature-inspired methods have been widely adopted to investigate a plethora of problems related to nature itself. In this paper we present a variety of CI methods applied to three problems in life sciences, highlighting their effectiveness: we describe how protein folding can be faced by exploiting Genetic Programming, the inference of haplotypes can be tackled using Genetic Algorithms, and the estimation of biochemical kinetic parameters can be performed by means of Swarm Intelligence. We show that CI methods can generate very high quality solutions, providing a sound methodology to solve complex optimization problems in life sciences.}
}

@article{doi:10.1177/0735633120945935,
author = {Yue Hu and Cheng-Huan Chen and Chien-Yuan Su},
title = {Exploring the Effectiveness and Moderators of Block-Based Visual Programming on Student Learning: A Meta-Analysis},
journal = {Journal of Educational Computing Research},
volume = {58},
number = {8},
pages = {1467–1493},
year = {2021b},
doi = {10.1177/0735633120945935},
URL = {https://doi-org.crai.referencistas.com/10.1177/0735633120945935},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0735633120945935},
abstract = {Block-based visual programming tools, such as Scratch, Alice, and MIT App Inventor, provide an intuitive and easy-to-use editing interface through which to promote programming learning for novice students of various ages. However, very little attention has been paid to investigating these tools’ overall effects on students’ academic achievement and the study features that may moderate the effects of block-based visual programming from a comprehensive perspective. Thus, the present study carried out a meta-analysis to systemically examine 29 empirical studies (extracting 34 effect sizes) using experimental or quasi-experiments involving the programming learning effects of employing block-based visual programming tools to date (until the end of 2019). The results showed a small to medium significant positive overall mean effect size (fixed-effect model g = 0.37; random-effects model g = 0.47) of the use of these block-based visual programming tools with respect to students’ academic achievement. Furthermore, the overall mean effect size was significantly affected by the educational stage, programming tool used, experimental treatment, and school location. Discussions and implications based on the findings are provided.}
}

@article{doi:10.1177/2378023119849803,
author = {David M. Liu and Matthew J. Salganik},
title = {Successes and Struggles with Computational Reproducibility: Lessons from the Fragile Families Challenge},
journal = {Socius},
volume = {5},
number = { },
pages = {2378023119849803},
year = {2019c},
doi = {10.1177/2378023119849803},
URL = {https://doi-org.crai.referencistas.com/10.1177/2378023119849803},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2378023119849803},
abstract = {Reproducibility is fundamental to science, and an important component of reproducibility is computational reproducibility: the ability of a researcher to recreate the results of a published study using the original author’s raw data and code. Although most people agree that computational reproducibility is important, it is still difficult to achieve in practice. In this article, the authors describe their approach to enabling computational reproducibility for the 12 articles in this special issue of Socius about the Fragile Families Challenge. The approach draws on two tools commonly used by professional software engineers but not widely used by academic researchers: software containers (e.g., Docker) and cloud computing (e.g., Amazon Web Services). These tools made it possible to standardize the computing environment around each submission, which will ease computational reproducibility both today and in the future. Drawing on their successes and struggles, the authors conclude with recommendations to researchers and journals.}
}

@article{doi:10.1179/030801803225010340,
author = {Roddam Narasimha},
title = {The Indian half of Needham’s question: some thoughts on axioms, models, algorithms, and computational positivism},
journal = {Interdisciplinary Science Reviews},
volume = {28},
number = {1},
pages = {54–66},
year = {2003d},
doi = {10.1179/030801803225010340},
URL = {https://doi-org.crai.referencistas.com/10.1179/030801803225010340},
eprint = {https://doi-org.crai.referencistas.com/10.1179/030801803225010340},
abstract = {Much debate has taken place on Joseph Needham’s question regarding ‘the failure of China and India to give rise to distinctively modern science while being ahead of Europe for fourteen previous centuries’. It is argued in this paper that while there is probably some truth in many of the sociocultural explanations that have been offered for the failure in India, they are in the final analysis not entirely convincing. The proposal in this paper is in two parts. The first is that the scientific revolution, which was part of a European miracle, was triggered in part by the advent of a variety of technologies from China and the new numeral system and other mathematical inventions from India - both via creative West Asian intermediaries. India had experienced a mathematical (more specifically algoristic or computational) revolution heralded by Ārya-bhata in the fifth century CE. The new computational power unleashed by this revolution combined with the classical Greek penchant for axiomatised modelmaking and a technology empowered experimental philosophy, in what appears to have been a very creative and uniquely European cultural fusion that led to the scientific (and later the industrial) revolution. The second part of the proposal is that there was an epistemological reason why the Indian mathematical revolution did not lead to a corresponding ‘distinctively modern’ scientific one. The Indic approach was basically not that of modelmakers but of ingenious algorisers, and showed a deep and studied distrust of axioms and physical models. This led to an attitude described here as ‘computational positivism’, which considers observation and computation as the only things that matter. In retrospect, that distrust appears not unjustified, especially in the light of twentieth century developments in quantum and classical mechanics and in logic; but it was historically expensive for India, as Europe achieved unreasonably and unexpectedly spectacular successes in science. To the Indians, it was Newton who was the extraordinary epistemological revolutionary, not Heisenberg or Gödel. In summary, Indian science could not move forward without the modelmaking and technology enabled experimental abilities that grew in the West, just as European modelmaking had earlier been unable to progress without the advent of powerful technologies and computational tools whose roots can be traced to China and India.}
}

@article{doi:10.1177/0002716215569446,
author = {Matthew Brook O’Donnell and Emily B. Falk},
title = {Big Data under the Microscope and Brains in Social Context: Integrating Methods from Computational Social Science and Neuroscience},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {659},
number = {1},
pages = {274–289},
year = {2015e},
doi = {10.1177/0002716215569446},
URL = {https://doi-org.crai.referencistas.com/10.1177/0002716215569446},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0002716215569446},
abstract = {Methods for analyzing neural and computational social science data are usually used by different types of scientists and generally seen as distinct, but they strongly complement one another. Computational social science methodologies can strengthen and contextualize individual-level analysis, specifically our understanding of the brain. Neuroscience can help to unpack the mechanisms that lead from micro- through meso- to macro-level observations. Integrating levels of analysis is essential to unified progress in social research. We present two example areas that illustrate this integration. First, combining egocentric social network data with neural variables from the “egos” provides insight about why and for whom certain types of antismoking messages may be more or less effective. Second, combining tools from natural language processing with neuroimaging reveals mechanisms involved in successful message propagation, and suggests links from microscopic to macroscopic scales.}
}

@article{doi:10.1177/1086296X231202722,
author = {Bradley Robinson},
title = {You Will Perish: A Case Study of Serendipitous Literacies and Novice Video Game Design},
journal = {Journal of Literacy Research},
volume = {55},
number = {3},
pages = {275–301},
year = {2023f},
doi = {10.1177/1086296X231202722},
URL = {https://doi-org.crai.referencistas.com/10.1177/1086296X231202722},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1086296X231202722},
abstract = {This study focused on the digital design practices of Raul, a 15-year-old participant at a summer video game design camp for adolescents. As Raul developed his original game, You Will Perish, I wondered what his design process might reveal about (a) the practice of affectively and procedurally literate video game design and (b) the literacy pedagogies that can support such design. Guided by the concept of serendipity, I describe Raul’s design practice as an open process characterized by bouts of failure, chance, and discovery, and I examine how such forces shaped the emergence of his game. Using transversal analysis, I trace Raul’s design through an account of frustration and failure, perseverance and pride, showing how the challenges of the game’s creator become those of the game’s players. The study highlights the generative potential of serendipitous literacies wherever and whenever literacy happens.}
}

@article{doi:10.1177/2167702614565359,
author = {Thomas V. Wiecki and Jeffrey Poland and Michael J. Frank},
title = {Model-Based Cognitive Neuroscience Approaches to Computational Psychiatry: Clustering and Classification},
journal = {Clinical Psychological Science},
volume = {3},
number = {3},
pages = {378–399},
year = {2015g},
doi = {10.1177/2167702614565359},
URL = {https://doi-org.crai.referencistas.com/10.1177/2167702614565359},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2167702614565359},
abstract = {Psychiatric research is in crisis. We highlight efforts to overcome current challenges by focusing on the emerging field of computational psychiatry, which might enable the field to move from a symptom-based description of mental illness to descriptors based on objective computational multidimensional functional variables. We survey recent efforts toward this goal and describe a set of methods that together form a toolbox to aid this research program. We identify four levels in computational psychiatry: (a) behavioral tasks that index various psychological processes, (b) computational models that identify the generative psychological processes, (c) parameter-estimation methods concerned with quantitatively fitting these models to subject behavior by focusing on hierarchical Bayesian estimation as a rich framework with many desirable properties, and (d) machine-learning clustering methods that identify clinically significant conditions and subgroups of individuals. As a proof of principle, we apply these methods to two different data sets. Finally, we highlight challenges for future research.}
}

@article{doi:10.1177/0002716215570576,
author = {Rodrigo Zamith and Seth C. Lewis},
title = {Content Analysis and the Algorithmic Coder: What Computational Social Science Means for Traditional Modes of Media Analysis},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {659},
number = {1},
pages = {307–318},
year = {2015h},
doi = {10.1177/0002716215570576},
URL = {https://doi-org.crai.referencistas.com/10.1177/0002716215570576},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0002716215570576},
abstract = {To deal with ever-larger datasets, media scholars are increasingly using computational analytic methods. This article focuses on how the traditional (manual) approach to conducting a content analysis—a primary method in the study of media messages—is being reconfigured, assesses what is gained and lost in turning to computational solutions, and builds on a “hybrid” approach to content analysis. We argue that computational methods are most fruitful when variables are readily identifiable in texts and when source material is easily parsed. Manual methods, though, are most appropriate for complex variables and when source material is not well digitized. These modes can be effectively combined throughout the process of content analysis to facilitate expansive and powerful analyses that are reliable and meaningful.}
}

@article{doi:10.1177/15485129211073612,
author = {Koen van der Zwet and Ana I Barros and Tom M van Engers and Peter M A Sloot},
title = {Promises and pitfalls of computational modelling for insurgency conflicts},
journal = {The Journal of Defense Modeling and Simulation},
volume = {20},
number = {3},
pages = {333–350},
year = {2023i},
doi = {10.1177/15485129211073612},
URL = {https://doi-org.crai.referencistas.com/10.1177/15485129211073612},
eprint = {https://doi-org.crai.referencistas.com/10.1177/15485129211073612},
abstract = {Insurgency conflicts pose significant challenges to societies globally. The increase of insurgency conflicts creates a need to understand how insurgencies arise, and to identify societal drivers of insurgencies or effective strategies to counter them. In this paper, we analyze the contributions of computational modeling methods for the analysis of insurgent conflicts. We formalize a specific literature-based analysis framework using the identified key factors and drivers, which enables the evaluation of specific models in this domain. Through a systematic literature search, we identify 64 computational models to apply our framework. We highlight the development and contributions of various methodologies through an in-depth analysis of 13 high-quality models. The evaluation of these computational models revealed promising directions and future topics to design specific simulation models for all identified factors. In addition, our analysis revealed specific pitfalls concerning validity issues for each of the modeling methods.}
}

@article{doi:10.2190/EC.49.4.g,
title = {Journal of Educational Computing Research Index—Contents of Volume 49, 2013},
journal = {Journal of Educational Computing Research},
volume = {49},
number = {4},
pages = {543–545},
year = {2013j},
doi = {10.2190/EC.49.4.g},
URL = {https://doi-org.crai.referencistas.com/10.2190/EC.49.4.g},
eprint = {https://doi-org.crai.referencistas.com/10.2190/EC.49.4.g}
}

