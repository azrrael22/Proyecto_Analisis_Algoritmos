@article{doi:10.1177/14614448241251804,
author = {Marcus Bösch and Tom Divon},
title = {The sound of disinformation: TikTok, computational propaganda, and the invasion of Ukraine},
journal = {New Media & Society},
volume = {26},
number = {9},
pages = {5081–5106},
year = {2024a},
doi = {10.1177/14614448241251804},
URL = {https://doi-org.crai.referencistas.com/10.1177/14614448241251804},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14614448241251804},
abstract = {TikTok has emerged as a powerful platform for the dissemination of mis- and disinformation about the war in Ukraine. During the initial three months after the Russian invasion in February 2022, videos under the hashtag #Ukraine garnered 36.9 billion views, with individual videos scaling up to 88 million views. Beyond the traditional methods of spreading misleading information through images and text, the medium of sound has emerged as a novel, platform-specific audiovisual technique. Our analysis distinguishes various war-related sounds utilized by both Ukraine and Russia and classifies them into a mis- and disinformation typology. We use computational propaganda features—automation, scalability, and anonymity—to explore how TikTok’s auditory practices are exploited to exacerbate information disorders in the context of ongoing war events. These practices include reusing sounds for coordinated campaigns, creating audio meme templates for rapid amplification and distribution, and deleting the original sounds to conceal the orchestrators’ identities. We conclude that TikTok’s recommendation system (the “for you” page) acts as a sound space where exposure is strategically navigated through users’ intervention, enabling semi-automated “soft” propaganda to thrive by leveraging its audio features.}
}

@article{doi:10.1177/089443939401200410,
author = {Kathleen Carley},
title = {Sociology: Computational Organization Theory},
journal = {Social Science Computer Review},
volume = {12},
number = {4},
pages = {611–624},
year = {1994b},
doi = {10.1177/089443939401200410},
URL = {https://doi-org.crai.referencistas.com/10.1177/089443939401200410},
eprint = {https://doi-org.crai.referencistas.com/10.1177/089443939401200410},
abstract = {Computational organization theory is a growing interdisciplinary area centered on the development of organization theory through the use of computational techniques. Research in this area grows out of work in many scientific areas including sociology, psychology, classic organization theory, and distributed artificial intelligence. The research in this area is united by a view of organizations as collections of processes and intelligent adaptive agents that are task oriented, socially situated, and technologically bound. This paper reviews this growing area and discusses both issues involved in the development of models in this area and theoretical issues that are being explored by work in this area. Keywords’ simulation, organization theory, organizational learning, social networks, expert systems, computers.}
}

@article{doi:10.1177/27538699221128218,
author = {Nathan Crilly},
title = {Design research and the study of the possible},
journal = {Possibility Studies & Society},
volume = {1},
number = {1–2},
pages = {46–50},
year = {2023c},
doi = {10.1177/27538699221128218},
URL = {https://doi-org.crai.referencistas.com/10.1177/27538699221128218},
eprint = {https://doi-org.crai.referencistas.com/10.1177/27538699221128218},
abstract = {Design research has much to contribute to and much to gain from the emerging field of possibility studies. In this short essay, I discuss these opportunities with respect to four topics: (1) processes of mediation and representation, (2) systems perspectives on creative work, (3) methodological options for investigation, and (4) educational challenges that should be addressed. Considering design research’s contributions to each of these topics raises interesting questions that possibility studies might address as it develops. Conversely, possibility studies is already raising issues that design research should also attend to.}
}

@article{doi:10.1177/0265532210378031,
author = {Scott A. Crossley and Tom Salsbury and Danielle S. McNamara and Scott Jarvis},
title = {Predicting lexical proficiency in language learner texts using computational indices},
journal = {Language Testing},
volume = {28},
number = {4},
pages = {561–580},
year = {2011d},
doi = {10.1177/0265532210378031},
URL = {https://doi-org.crai.referencistas.com/10.1177/0265532210378031},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0265532210378031},
abstract = {The authors present a model of lexical proficiency based on lexical indices related to vocabulary size, depth of lexical knowledge, and accessibility to core lexical items. The lexical indices used in this study come from the computational tool Coh-Metrix and include word length scores, lexical diversity values, word frequency counts, hypernymy values, polysemy values, semantic co-referentiality, word meaningfulness, word concreteness, word imagability, and word familiarity. Human raters evaluated a corpus of 240 written texts using a standardized rubric of lexical proficiency. To ensure a variety of text levels, the corpus comprised 60 texts each from beginning, intermediate, and advanced second language (L2) adult English learners. The L2 texts were collected longitudinally from 10 English learners. In addition, 60 texts from native English speakers were collected. The holistic scores from the trained human raters were then correlated to a variety of lexical indices. The researchers found that lexical diversity, word hypernymy values and content word frequency explain 44% of the variance of the human evaluations of lexical proficiency in the examined writing samples. The findings represent an important step in the development of a model of lexical proficiency that incorporates both vocabulary size and depth of lexical knowledge features.}
}

@article{doi:10.1177/17470161241247686,
author = {Seliem El-Sayed and Filip Paspalj},
title = {No recognised ethical standards, no broad consent: navigating the quandary in computational social science research},
journal = {Research Ethics},
volume = {20},
number = {3},
pages = {433–452},
year = {2024e},
doi = {10.1177/17470161241247686},
URL = {https://doi-org.crai.referencistas.com/10.1177/17470161241247686},
eprint = {https://doi-org.crai.referencistas.com/10.1177/17470161241247686},
abstract = {Recital 33 GDPR has often been interpreted as referring to ‘broad consent’. This version of informed consent was intended to allow data subjects to provide their consent for certain areas of research, or parts of research projects, conditional to the research being in line with ‘recognised ethical standards’. In this article, we argue that broad consent is applicable in the emerging field of Computational Social Science (CSS), which lies at the intersection of data science and social science. However, the lack of recognised ethical standards specific to CSS poses a practical barrier to the use of broad consent in this field and other fields that lack recognised ethical standards. Upon examining existing research ethics standards in social science and data science, we argue that they are insufficient for CSS. We further contend that the fragmentation of European Union (EU) law and research ethics sources makes it challenging to establish universally recognised ethical standards for scientific research. As a result, CSS researchers and other researchers in emerging fields that lack recognised ethical standards are left without sufficient guidance on the use of broad consent as provided for in the GDPR. We conclude that responsible EU bodies should provide additional guidance to facilitate the use of broad consent in CSS research.}
}

@article{doi:10.1177/1745691620970585,
author = {Olivia Guest and Andrea E. Martin},
title = {How Computational Modeling Can Force Theory Building in Psychological Science},
journal = {Perspectives on Psychological Science},
volume = {16},
number = {4},
pages = {789–802},
year = {2021f},
doi = {10.1177/1745691620970585},
note = {PMID:33482070},
URL = {https://doi-org.crai.referencistas.com/10.1177/1745691620970585},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1745691620970585},
abstract = {Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined—what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.}
}

@article{doi:10.1177/0143624418759783,
author = {Susana Hormigos-Jimenez and Miguel Ángel Padilla-Marcos and Alberto Meiss and Roberto Alonso Gonzalez-Lezcano and Jesús Feijó-Muñoz},
title = {Computational fluid dynamics evaluation of the furniture arrangement for ventilation efficiency},
journal = {Building Services Engineering Research and Technology},
volume = {39},
number = {5},
pages = {557–571},
year = {2018g},
doi = {10.1177/0143624418759783},
URL = {https://doi-org.crai.referencistas.com/10.1177/0143624418759783},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0143624418759783},
abstract = {People spend most of their time indoors; therefore, maintaining a good indoor air quality and meeting the requirements of comfort and energy efficiency are essential. One of the most widespread strategies to achieve this objective is improving ventilation efficiency; therefore, the main aim of this study was to show an optimization of the ventilation efficiency, in a specific room, considering 47 variations (case studies) in the furniture arrangement. For this purpose, a numerical analysis using computational fluid dynamics techniques, validated by the tracer gas decay technique, was used to assess the distribution of the age of air within the space. The concept of “age of air” was implemented in the computational fluid dynamics code through user-defined functions, using the steady-state method based on the resolution of a transport equation for an additional scalar. Variations up to 5.75% in the ventilation efficiency between the cases studied have been achieved. It is concluded that an improvement up to 1.65% can be obtained when the elements of the study are introduced in a way that facilitates the air movement towards the exhaust; therefore, improvement of the ventilation efficiency through specific furniture distributions is possible, although not significant, according to the outcomes.}
}

@article{doi:10.1177/10762175211070350,
author = {Kim Krusen McComas},
title = {Investigating Crickets: Jumping Across the Disciplines in a Naturally Interdisciplinary Project},
journal = {Gifted Child Today},
volume = {45},
number = {2},
pages = {105–109},
year = {2022h},
doi = {10.1177/10762175211070350},
URL = {https://doi-org.crai.referencistas.com/10.1177/10762175211070350},
eprint = {https://doi-org.crai.referencistas.com/10.1177/10762175211070350},
abstract = {A phenomenon from the natural world, cricket chirping behavior in relation to ambient temperature, is used as the springboard for engaging the curiosity of gifted students in an interdisciplinary classroom curriculum. Mathematics and science standards and disciplinary practices are prominent in the investigation, while other disciplines deepen the experience. An analysis of the cricket project in terms of the Parallel Curriculum (core, connections, practice, and identity) provides an interesting lens for examining interdisciplinarity (see Tomlinson, C. A., Kaplan, S. N., Renzulli, and J. S., et al. (2009). Parallel curriculum: A design to develop learner potential and challenge advanced learners. Corwin Press).}
}

@article{doi:10.1177/09610006221124619,
author = {Evan Muzzall and Vijoy Abraham and Ron Nakao},
title = {A perspective on computational research support programs in the library: More than 20 years of data from Stanford University Libraries},
journal = {Journal of Librarianship and Information Science},
volume = {56},
number = {1},
pages = {267–283},
year = {2024i},
doi = {10.1177/09610006221124619},
URL = {https://doi-org.crai.referencistas.com/10.1177/09610006221124619},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09610006221124619},
abstract = {Presentation of data is a major component to academic research. However, programming languages, computational tools, and methods for exploring and analyzing data can be time consuming and frustrating to learn and finding help with these stages of the broader research process can be daunting. In this work, we highlight the impacts that computational research support programs housed in library contexts can have for fulfilling gaps in student, staff, and faculty research needs. The archival history of one such organization, Software and Services for Data Science (SSDS) in the Stanford University Cecil H. Green Library, is used to outline challenges faced by social sciences and humanities researchers from the 1980s to the present day. To compliment this history, participation metrics from consulting services (1999–2021) and workshops (2000–2021) are presented along with updated workshop participant feedback forms (n = 99) and further illustrate the profound impacts that these services can have for helping researchers succeed. Consulting and workshop metrics indicate that SSDS has supported at least 27,031 researchers between 1999 and 2021 (average of more than 1175 per year). A t-test on the feedback form data indicates that participant knowledge in workshops statistically significantly increased more than one scale point from workshop start to completion. Results also indicate that despite our successes, many past challenges continue to present barriers regardless of exponential advances in computing, teaching, and learning—specifically around learning to access data and learning the software and tools to use it. We hope that our story helps other institutions understand how indispensable computational research support is within the library.}
}

@article{doi:10.1177/1475472X221079557,
author = {Wei Ying and Ryu Fattah and Sinforiano Cantos and Siyang Zhong and Tatiana Kozubskaya},
title = {Computational aeroacoustics of aerofoil leading edge noise using the volume penalization-based immersed boundary methods},
journal = {International Journal of Aeroacoustics},
volume = {21},
number = {1–2},
pages = {74–94},
year = {2022j},
doi = {10.1177/1475472X221079557},
URL = {https://doi-org.crai.referencistas.com/10.1177/1475472X221079557},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1475472X221079557},
abstract = {Broadband noise due to the turbulence-aerofoil interaction, which is also called the leading edge noise, is one of the major noise sources of aircraft (including the engine). To study the noise properties numerically is a popular approach with the increasing power of computers. Conventional approaches of using body-fitted grids at the boundaries would be convoluted due to the complex geometries, which can constrain the efficiency of parametric studies. A promising approach to tackle this issue is to use the immersed boundary method (IBM). Among various IBM variants, the volume penalization (VP) approach employs a masking function to identify the immersed solid boundary, and continuous forcing terms are added to the original flow governing equations to account for the boundary conditions. It is, therefore, efficient and easy to implement into the existing computational aeroacoustics solvers. In this work, the VP-based IBM is used to simulate the leading edge noise by combining with the advanced synthetic turbulence method. The simulations are conducted for both the isolated aerofoils and cascade, and the results are compared with the well-validated body-fitted grid solutions. The viscosity effect is also highlighted by comparing the results obtained by solving both Euler and Navier–Stokes equations.}
}

