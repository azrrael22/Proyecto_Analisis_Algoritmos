ENTRYTYPE,ID,abstract,author,doi,eprint,journal,number,pages,title,url,volume,year,note
article,doi:10.1177/1475725716659252,"Computational thinking is an approach to problem solving that is typically employed by computer programmers. The advantage of this approach is that solutions can be generated through algorithms that can be implemented as computer code. Although computational thinking has historically been a skill that is exclusively taught within computer science, there has been a more recent movement to introduce these skills within other disciplines. Psychology is an excellent example of a discipline that would benefit from computational thinking skills because of the nature of questions that are typically asked within the discipline. However, there has not been a formal curriculum proposed to teach computational thinking within psychology and the behavioural sciences. I will argue that computational thinking is a fundamental skill that can easily be introduced to psychology students throughout their undergraduate education. This would provide students with the skills necessary to become successful researchers, and would also provide a practical and marketable skill to all psychology graduates.",Nicole D. Anderson,10.1177/1475725716659252,https://doi-org.crai.referencistas.com/10.1177/1475725716659252,Psychology Learning & Teaching,3,226–234,A Call for Computational Thinking in Undergraduate Psychology,https://doi-org.crai.referencistas.com/10.1177/1475725716659252,15,2016a,
article,doi:10.1177/07356331211033158,"This article provides an overview of the diverse ways in which computational thinking has been operationalised in the literature. Computational thinking has attracted much interest and debatably ranks in importance with the time-honoured literacy skills of reading, writing, and arithmetic. However, learning interventions in this subject have modelled computational thinking differently. We conducted a systematic review of 81 empirical studies to examine the nature, explicitness, and patterns of definitions of computational thinking. Data analysis revealed that most of the reviewed studies operationalised computational thinking as a composite of programming concepts and preferred definitions from assessment-based frameworks. On the other hand, a substantial number of the studies did not establish the meaning of computational thinking when theorising their interventions nor clearly distinguish between computational thinking and programming. Based on these findings, this article proposes a model of computational thinking that focuses on algorithmic solutions supported by programming concepts which advances the conceptual clarity between computational thinking and programming.",Ndudi O. Ezeamuzie and Jessica S. C. Leung,10.1177/07356331211033158,https://doi-org.crai.referencistas.com/10.1177/07356331211033158,Journal of Educational Computing Research,2,481–511,Computational Thinking Through an Empirical Lens: A Systematic Review of Literature,https://doi-org.crai.referencistas.com/10.1177/07356331211033158,60,2022b,
article,doi:10.1177/21582440211016418,"Computational thinking (CT) is being recognized as a critical component of student success in the digital era. Many contend that integrating CT into core curricula is the surest method for providing all students with access to CT. However, the CT community lacks an agreed-upon conceptualization of CT that would facilitate this integration, and little effort has been made to critically analyze and synthesize research on CT/content integration (CTCI). Conflicting CT conceptualizations and little understanding of evidence-based strategies for CTCI could result in significant barriers to increasing students’ access to CT. To address these concerns, we analyzed 80 studies on CT education, focusing on both the CT conceptualizations guiding current CT education research and evidence-based strategies for CTCI. Our review highlights the code-centric nature of CT education and reveals significant gaps in our understanding of CTCI and CT professional development for teachers. Based on these findings, we propose an approach to operationalizing CT that promotes students’ participation in CT, present promising methods for infusing content with CT, and discuss future directions for CT education research.",Vance Kite and Soonhye Park and Eric Wiebe,10.1177/21582440211016418,https://doi-org.crai.referencistas.com/10.1177/21582440211016418,Sage Open,2,21582440211016416,The Code-Centric Nature of Computational Thinking Education: A Review of Trends and Issues in Computational Thinking Education Research,https://doi-org.crai.referencistas.com/10.1177/21582440211016418,11,2021c,
article,doi:10.1177/07356331221121052,"Computational thinking (CT) is an emerging and multifaceted competence important to the computing era. However, despite the growing consensus that CT is a competence domain, its theoretical and empirical account remain scarce in the current literature. To address this issue, rigorous psychometric evaluation procedures were adopted to investigate the structure of CT competency, as measured by Computational Thinking Challenge (Lai, 2021a), in a large sample of 1,130 British secondary school students (Mage = 14.14 years, SDage = 1.45). Based on model comparison from an exploratory multidimensional item response theory approach, the results supported the multidimensional operationalization of CT competency. A confirmatory bi-factor item response theory model further suggested CT competency is comprised of a general CT competency factor and two specific factors for programming and non-programming problem-solving. Despite the multidimensionality, the common variance is largely explained by a primary general factor of CT competency, thus the use of a single scale score is recommended. Psychometric evaluation from the bi-factor model indicated good psychometric properties of the assessment tool. Overall, the bi-factor model provides a useful approach to investigating CT competency and serves as a robust test validation tool.",Rina PY Lai and Michelle R Ellefson,10.1177/07356331221121052,https://doi-org.crai.referencistas.com/10.1177/07356331221121052,Journal of Educational Computing Research,2,259–282,How Multidimensional is Computational Thinking Competency? A Bi-Factor Model of the Computational Thinking Challenge,https://doi-org.crai.referencistas.com/10.1177/07356331221121052,61,2023d,
article,doi:10.3102/00346543241241327,"Teaching coding and computational thinking is an emerging educational imperative, now embedded in compulsory curriculum in the United States, Finland, the UK, Germany, Belgium, the Netherlands, New Zealand, and Australia. This meta-synthesis of 49 studies critically reviews recent international research (2009–2022) of coding and computational thinking as core and integrated across the curriculum. It addresses four essential problems: (a) What are the key features of learning environments that successfully develop students’ coding and computational thinking? (b) What is the impact of student engagement in coding and computational thinking on learning outcomes across curriculum areas? (c) What pedagogical constraints are evident for coding and computational thinking, including across curriculum areas? and (d) Which conceptual frameworks support coding and computational thinking, and what has been marginalized or excluded? The review advances knowledge of coding and computational thinking—vital to guide and develop future AI-based solutions to real-world problems that challenge disciplinary boundaries.",Kathy A. Mills and Jen Cope and Laura Scholes and Luke Rowe,10.3102/00346543241241327,https://doi-org.crai.referencistas.com/10.3102/00346543241241327,Review of Educational Research,0,00346543241241327,Coding and Computational Thinking Across the Curriculum: A Review of Educational Outcomes,https://doi-org.crai.referencistas.com/10.3102/00346543241241327,0,2024e,
article,doi:10.1177/07356331241226746,"This study was grounded in the spatial computational thinking model developed by the 3D Weather project funded by the NSF STEM+C program. The model reflects a discipline-based perspective towards computational thinking and captures the spatial nature of computational thinking in meteorology and the reliance of computational thinking on spatial thinking for geospatial analysis. The research was conducted among nineteen teachers attending the summer workshop offered by the project in its third project year to prepare them for teaching spatial computational thinking with IDV (Integrated Data Viewer, downloadable at https://www.unidata.ucar.edu/software/idv/) visualization of weather data. Quantitative survey data were collected measuring these teachers’ meteorology content knowledge, spatial computational thinking, self-efficacy for teaching spatial computational thinking, and epistemic cognition of teaching meteorology. The data were analyzed to examine the effects of the workshop in terms of these variables and the correlations among them were also explored.",Yan Sun and Jamie Dyer and Jonathan Harris,10.1177/07356331241226746,https://doi-org.crai.referencistas.com/10.1177/07356331241226746,Journal of Educational Computing Research,4,1061–1086,Preparing Teachers for Teaching Spatial Computational Thinking With Integrated Data Viewer Visualization of Weather Data: A Discipline-Based Perspective of Computational Thinking,https://doi-org.crai.referencistas.com/10.1177/07356331241226746,62,2024f,
article,doi:10.1177/0735633120972356,"Computational thinking has received tremendous attention from computer science educators and educational researchers in the last decade. However, most prior literature defines computational thinking as thinking outcomes rather than thinking processes. Based on Selby and Woodland’s framework, this study developed and validated the Computational Thinking Scale (CTS) to assess all students’ thought processes of computational thinking for both general and specific problem-solving contexts in five dimensions: abstraction, decomposition, algorithmic thinking, evaluation and generalization. A survey including 25 candidate items for CTS as well as demographic variables was administered to 388 junior high school students in Taiwan. An explorative factor analysis using the principal axis method with the oblimin rotation was used to validate the scale. Finally, 19 items were extracted successfully under the designed five dimensions, with a total explained variance of 64.03% and an overall reliability of 0.91. Results of the demographic comparisons showed that boys had a greater disposition than girls in decomposition thinking when solving problems using computer programming. In addition, programming learning experience, especially self-directed learning and after-school learning, had significant positive effects on all dimensions of CTS. Several future studies are suggested using this tool.",Meng-Jung Tsai and Jyh-Chong Liang and Chung-Yuan Hsu,10.1177/0735633120972356,https://doi-org.crai.referencistas.com/10.1177/0735633120972356,Journal of Educational Computing Research,4,579–602,The Computational Thinking Scale for Computer Literacy Education,https://doi-org.crai.referencistas.com/10.1177/0735633120972356,59,2021g,
article,doi:10.1177/07356331211017794,"A prior study developed the Computational Thinking Scale (CTS) for assessing individuals’ computational thinking dispositions in five dimensions: decomposition, abstraction, algorithmic thinking, evaluation, and generalization. This study proposed the Developmental Model of Computational Thinking through validating the structural relationships among the five factors of the CTS. To examine the model, a questionnaire including the CTS was administered to 472 middle school students. A confirmatory factor analysis was used to confirm the construct of the measurements, and a PLS-SEM analysis was used to validate the structural relationships among the factors. The results confirmed that the 19-item CTS has good item reliability, internal consistency, and construct reliability for measuring computational thinking (CT). In the Developmental Model of CT, decomposition and abstraction significantly predict all other three CT dispositions, suggesting that they are the two fundamental factors required for CT development. Moreover, a significant linear prediction path was shown starting from algorithmic thinking, evaluation, until generalization. Thus, a multi-level model was confirmed for the conceptual framework of CT. This model suggests a possible sequence for CT development which may provide a guideline for the teaching objectives of CT for different learning stages in different school levels. Decomposition and abstraction are especially suggested to be emphasized in school curricula before teaching algorithmic thinking or algorithm designs.",Meng-Jung Tsai and Jyh-Chong Liang and Silvia Wen-Yu Lee and Chung-Yuan Hsu,10.1177/07356331211017794,https://doi-org.crai.referencistas.com/10.1177/07356331211017794,Journal of Educational Computing Research,1,56–73,Structural Validation for the Developmental Model of Computational Thinking,https://doi-org.crai.referencistas.com/10.1177/07356331211017794,60,2022h,
article,doi:10.1177/0735633120988807,"Currently, many countries actively cultivate students to develop computational thinking ability. Many visual programming environments (VPEs) and physical robot courses have been integrated into computational thinking learning in the elementary education stage. This study explores the relationship between the programming learning environment (including VPE, physical robots, and no experience) and the computational thinking ability of higher-grade elementary school students of different genders. The results show that learning through VPE or physical robots can help students improve their computational thinking ability and that students learn better via physical robots. In addition, among the four dimensions of computational thinking ability, most students are weak in algorithm design. In terms of gender, no differences exist in computational thinking ability. Further analysis reveals that female students have better decomposition performance in VPE learning, while male students have better algorithm design performance.",Sheng-Yi Wu and Yu-Sheng Su,10.1177/0735633120988807,https://doi-org.crai.referencistas.com/10.1177/0735633120988807,Journal of Educational Computing Research,6,1075–1092,Visual Programming Environments and Computational Thinking Performance of Fifth- and Sixth-Grade Students,https://doi-org.crai.referencistas.com/10.1177/0735633120988807,59,2021i,
article,doi:10.1177/07356331231220313,"The study examined the effect of teaching text-based programming with a physical programming tool on secondary school students’ computational thinking skills and self-efficacy perceptions. The study was conducted according to a sequential explanatory design as a mixed method research. The study group consisted of 85 secondary school students. Within the scope of the study, a physical programming tool called Micro:bit was used to teach Python programming for a period of 6 weeks. Data were collected using the Self-Efficacy Perception Scale for Computational Thinking Skill, Bebras: International Challenge on Informatics and Computational Thinking Tasks, tests focused on programming tool, concepts, and processes, and through semi-structured interview questioning. According to the findings obtained from pretests and posttests, a significant and positive difference was found in the students’ computational thinking skills and self-efficacy perceptions towards computational thinking skill. As a result of having received instruction in programming, the students satisfactorily learnt the required programming concepts and processes. Through learning Python programming with a physical programming tool, the students not only gained the skills required to write appropriate syntax, and to test and debug code, but they also learnt programming concepts such as variables, conditional expressions, loops, and functions.",Ezgi Arzu Yurdakök and Filiz Kalelioğlu,10.1177/07356331231220313,https://doi-org.crai.referencistas.com/10.1177/07356331231220313,Journal of Educational Computing Research,3,785–815,The Effect of Teaching Physical Programming on Computational Thinking Skills and Self-Efficacy Perceptions Towards Computational Thinking,https://doi-org.crai.referencistas.com/10.1177/07356331231220313,62,2024j,
article,doi:10.1177/1046878119901286,"Background Recent years have seen the resurgence of board games designed for entertainment, and to teach or explicate real life problems. The revival of board gameplay has been discussed in mainstream media, and has drawn the attention of researchers. Yet, in the field of games studies, the conception of games as learning spaces is mostly emphasized through digital/video games. Aim This literature review reveals the current knowledge regarding the learning potential of board games in various settings, subjects, and diverse learners. Results Board games are spaces for mathematical learning and learning spaces that can enable the learning of various contents. Board games allow for various interactions that result in players engaging in computational thinking, teamwork, and creativity. Conclusion The relationship between board gameplay and learning is evidenced across disciplines and countries. Board games simplify complex issues and systems, which make them appropriate to further explore learning and concepts such as motivation and computational thinking in formal and informal settings. Furthermore, there is need to expand research on learning in commercial board games.",Rebecca Yvonne Bayeck,10.1177/1046878119901286,https://doi-org.crai.referencistas.com/10.1177/1046878119901286,Simulation & Gaming,4,411–431,Examining Board Gameplay and Learning: A Multidisciplinary Review of Recent Research,https://doi-org.crai.referencistas.com/10.1177/1046878119901286,51,2020a,
article,doi:10.1177/0735633116642774,"Computational thinking has been gaining new impetus in the academic community and in K-12 level education. Scratch is a visual programming environment that can be utilized to teach and learn introductory computing concepts. There are some studies investigating the effectiveness of Scratch for K-12 level education. However, studies that have been conducted at the collegiate level, especially in the context of preservice computing teacher education, are very rare. The present study aimed to investigate the effect of Scratch-based instruction on preservice teachers’ understanding of basic programming concepts and their attitudes toward programming. In the present study, a mixed method design was utilized. In the first phase of the study, the data were collected using an achievement test, a practice test, and a computer programming attitude scale. In the second phase of the study, data were collected through a semistructured interview. The results of the study indicated that preservice teachers in Scratch-based instruction had significantly better understanding of basic computing concepts. Qualitative data indicated that Scratch-based instruction was useful in constructing a more meaningful learning environment for preservice teachers. The results of this study have implications for researchers and preservice computing teacher educators when designing an introductory computing course.",Ibrahim Cetin,10.1177/0735633116642774,https://doi-org.crai.referencistas.com/10.1177/0735633116642774,Journal of Educational Computing Research,7,997–1021,Preservice Teachers’ Introduction to Computing: Exploring Utilization of Scratch,https://doi-org.crai.referencistas.com/10.1177/0735633116642774,54,2016b,
article,doi:10.1177/07356331231171622,"Pattern recognition is an important skill in computational thinking. In this study, an equation puzzle game was developed by combining pattern recognition with algebraic reasoning, and scaffolding was designed to support learners’ learning. Sixty participants were enrolled in this study, divided into a control group and an experimental group to compare the results and differences in game achievement, flow, anxiety, and motivation of participants with and without algebraic reasoning scaffolding. The results of the study showed that the participants in both groups had positive flow and motivation during the game, did not feel over-anxious, and there was no significant difference in the game achievement of the two groups. In addition, the game with the scaffolding may have the potential to make a positive correlation between game achievement and psychological status. The results of this study indicated that the game did not cause too much anxiety to the participants. The scaffolding-based design achieves the intended effect on the participants’ assistance and facilitates the participants’ engagement in pattern recognition problem solving. And as learners became more focused and engaged, they could also perform better in the game. This game mechanism can be used as a reference for designing pattern recognition games.",Yu-Chi Chen and Chi-Yu Chao and Huei-Tse Hou,10.1177/07356331231171622,https://doi-org.crai.referencistas.com/10.1177/07356331231171622,Journal of Educational Computing Research,6,1232–1251,Learning Pattern Recognition Skills From Games: Design of an Online Pattern Recognition Educational Mobile Game Integrating Algebraic Reasoning Scaffolding,https://doi-org.crai.referencistas.com/10.1177/07356331231171622,61,2023c,
article,doi:10.1177/23813377231182093,"Although participatory culture promotes productive engagement in online spaces, members may respond in ways that constrain digital composition practices. This article provides theoretical and contextual background regarding a shift toward digital media production and programming-as-writing for youth. In addition, I describe the intersecting of computational thinking, computational participation, and participatory culture within Scratch, an online programming community. Findings from a descriptive case study focused on early adolescents as they engaged in digital media composition within an online programming community called Scratch are examined. Specifically, I discuss the contrast in the digital composition experiences of two participants as they leveraged participatory culture in the creation of digital media. This research highlights assumptions made regarding participatory cultures and the need to consider how to foster productive and sustainable digital literacy practices for youth in participatory cultures.",Julia Hagge,10.1177/23813377231182093,https://doi-org.crai.referencistas.com/10.1177/23813377231182093,"Literacy Research: Theory, Method, and Practice",1,200–217,Productivity Versus Sustainability: A Tale of Two Authors’ Engagement in Participatory Culture,https://doi-org.crai.referencistas.com/10.1177/23813377231182093,72,2023d,
article,doi:10.1177/07356331211017793,"The integration of visual programming in early formal education has been found to promote computational thinking of students. Teachers’ intuitive perspectives about optimal learning processes – “folk psychology” – impact their perspectives about teaching “folk pedagogy” and play a significant role in integrating educational technologies, such as visual programming, within the formal curriculum. This study was conducted based on the mixed method research paradigm. First, a folk pedagogy questionnaire was distributed to 89 teachers who integrate differing technologies in their classroom in order to identify the teachers’ pedagogical perspectives: constructivist versus instructivist. Then, semi-structured interviews were conducted with 24 teachers who teach Scratch in order to gain a deeper understanding of their instructivist/constructivist perspectives and actual pedagogical practices and strategies. Finally, we analyzed 96 students’ programming artifacts to explore differences, if any, in students’ outcomes related to the pedagogical perspectives of their teachers. Findings revealed that pedagogical perspectives are reflected in teaching strategies and assessment practices employed in a visual programming environment. It is promising that teaching visual programming promoted constructivist pedagogy even among instructivist teachers and was consequently reflected in student perspectives and expressed in their programming artifacts. We discuss theoretical and educational implications of these findings.",Avital Kesler and Tamar Shamir-Inbal and Ina Blau,10.1177/07356331211017793,https://doi-org.crai.referencistas.com/10.1177/07356331211017793,Journal of Educational Computing Research,1,28–55,Active Learning by Visual Programming: Pedagogical Perspectives of Instructivist and Constructivist Code Teachers and Their Implications on Actual Teaching Strategies and Students’ Programming Artifacts,https://doi-org.crai.referencistas.com/10.1177/07356331211017793,60,2022e,
article,doi:10.1177/1532708616655771,"Re-emphasizing our agenda for this special issue as marking the shift from epistemological to ontological concerns in social science inquiry, Patti Lather locates it in challenging the orthodoxies of both positivist and critical approaches to the calculative, computational thinking and the limits of reason. With a focus on an escape from psychometrics in education research, she grounds her remarks in the context of the wider terrain of the possibilities of quantification for cultural studies and (post)critical inquiry.",Patti Lather,10.1177/1532708616655771,https://doi-org.crai.referencistas.com/10.1177/1532708616655771,Cultural Studies ↔ Critical Methodologies,5,502–505,Post-Face: Cultural Studies of Numeracy,https://doi-org.crai.referencistas.com/10.1177/1532708616655771,16,2016f,
article,doi:10.1177/1077695820904971,"This syndicate offers four recommendations to help educators adjust curricula to accommodate the rapid integration of data into journalism. First, instruction in numeracy and basic descriptive statistics must be required as either modules in existing courses or as separate offerings. Second, students should be taught to avoid mistakes in interpreting and writing about data in both reporting and visual classes. Third, ethics courses should discuss data as a transparency tool that poses distinctive dilemmas. Fourth, computational thinking, or how to dissect and solve problems like a computer does, can be incorporated into existing classes that teach logic.",Norman P. Lewis and Mindy McAdams and Florian Stalph,10.1177/1077695820904971,https://doi-org.crai.referencistas.com/10.1177/1077695820904971,Journalism & Mass Communication Educator,1,16–21,Data Journalism,https://doi-org.crai.referencistas.com/10.1177/1077695820904971,75,2020g,
article,doi:10.1177/0735633115612785,"While pedagogical and technological affordances of three-dimensional (3D) multiuser virtual worlds in various educational disciplines are largely well-known, a study about their effect on high school students’ engagement in introductory programming courses is still lacking. This case study presents students’ opinions about their participation in a 3D multiuser game-like environment, by harnessing Second Life in combination with the two-dimensional (2D) programming environment of Scratch4SL. Following a blended instructional format (face-to-face in a computer laboratory and supplementary online courses), 56 students utilizing Scratch4SL participated in this study, with a view to reduce the “steep learning curve” created during their first-time entrance into Second Life. This study identifies Papert’s theory of Constructionism as a potentially appropriate theoretical foundation for the development of an instructional framework, in order to assist students to coordinate and manage learning materials with other teammates, using their computational thinking skills in collaborative problem-based programming tasks. The study findings based on a mixed-method research (a close-ended questionnaire and an open-ended interview) indicated the effectiveness of this “constructionist-oriented” instructional process for students’ engagement to acquire or empower social, cognitive, higher-order, and computational thinking skills. Educational implications and recommendations for future research are also discussed.",Nikolaos Pellas and Efstratios Peroutseas,10.1177/0735633115612785,https://doi-org.crai.referencistas.com/10.1177/0735633115612785,Journal of Educational Computing Research,1,108–143,Gaming in Second Life via Scratch4SL: Engaging High School Students in Programming Courses,https://doi-org.crai.referencistas.com/10.1177/0735633115612785,54,2016h,
article,doi:10.1177/1478210319894785,"Programming and computational thinking have emerged as compulsory skills in elementary school education. In 2018, Sweden has integrated programming in mathematics education with the rationale that it fosters problem solving and logical thinking skills and motivates students to learn mathematics. We investigated how teachers introduce programming in mathematics education in a Swedish primary school using an explorative case study. We followed four mathematics teachers during the first semester in which programming was mandatory. They taught second-, sixth- and ninth-grade students. Our contributions are threefold: we provide an account of how programming is taught in mathematics education; we discuss how teachers reflect on the challenge of teaching programming in mathematics; and we report on students’ understanding of programming and their view on the relationship between programming and mathematics.",Henrik Stigberg and Susanne Stigberg,10.1177/1478210319894785,https://doi-org.crai.referencistas.com/10.1177/1478210319894785,Policy Futures in Education,4,483–496,Teaching programming and mathematics in practice: A case study from a Swedish primary school,https://doi-org.crai.referencistas.com/10.1177/1478210319894785,18,2020i,
article,doi:10.1177/07356331231209773,"Computational thinking (CT) has received much attention in mathematics education in recent years, and researchers have begun to experiment with the integration of CT into mathematics education to promote students’ CT and mathematical thinking (MT) development. However, there is a lack of empirical evidence and new theoretical perspectives on the mechanisms of interaction between CT and MT. To address this research gap, this study analyses the participants’ thinking processes in solving programming-based mathematical problems from a flexibility perspective, focusing on the interplay between computational and mathematical thinking, that is, how CT and MT work together to influence and determine the problem-solver’s choice of solution strategy. Using data collected from a large design-based study, we summarise two types of flexibility and six subtypes of flexibility demonstrated by participants in the programming-based mathematical problem-solving process using thematic analysis. These different types of flexibility provide researchers and mathematics educators with new theoretical perspectives to examine the interplay of CT and MT. Findings will also contribute toward student learning characteristics in programming-based mathematical problem-solving to sketch the big picture of how CT and MT emerge in complementary or mismatching ways.",Huiyan Ye and Oi-Lam Ng and Zhihao Cui,10.1177/07356331231209773,https://doi-org.crai.referencistas.com/10.1177/07356331231209773,Journal of Educational Computing Research,2,594–619,Conceptualizing Flexibility in Programming-Based Mathematical Problem-Solving,https://doi-org.crai.referencistas.com/10.1177/07356331231209773,62,2024j,
article,doi:10.1177/00472395211018801,"The computer science (CS) unplugged approach intends to teach CS concepts and computational thinking skills without employing any digital tools. The current study conducted a systematic literature review to analyze research studies that conducted investigations related to implementations of CS unplugged activities. A systematic review procedure was developed and applied to detect and subsequently review relevant research studies published from 2010 to 2019. It was found that 55 research studies (17 articles + 38 conference proceedings) satisfied the inclusion criteria for the analysis. These research studies were then examined with regard to their demographic characteristics, research methodologies, research results, and main findings. It was found that the unplugged approach was realized and utilized differently among researchers. The majority of the studies used the CS unplugged term when referring to “paper–pencil activities,” “problem solving,” “storytelling,” “games,” “tangible programming,” and even “robotics.”",Ali Battal and Gülgün Afacan Adanır and Yasemin Gülbahar,10.1177/00472395211018801,https://doi-org.crai.referencistas.com/10.1177/00472395211018801,Journal of Educational Technology Systems,1,24–47,Computer Science Unplugged: A Systematic Literature Review,https://doi-org.crai.referencistas.com/10.1177/00472395211018801,50,2021a,
article,doi:10.2190/EC.51.2.c,"Scratch, a visual programming language, was used in many studies in computer science education. Most of them reported positive results by integrating Scratch into K-12 computer courses. However, the object-oriented concept, one of the important computational thinking skills, is not represented well in Scratch. Alice, another visual programming language, seems to have better illustration of the object-oriented concept for programming novices. To demonstrate effects of Alice and Scratch, we compared students’ responses to both visual programming languages, especially for students with low performances, in an introductory programming course. The relationships among learning engagement, learning anxiety, and learning playfulness were explored. The results could be referred to by computer science instructors to select proper visual programming language for corrective instruction.",Chih-Kai Chang,10.2190/EC.51.2.c,https://doi-org.crai.referencistas.com/10.2190/EC.51.2.c,Journal of Educational Computing Research,2,185–204,Effects of Using Alice and Scratch in an Introductory Programming Course for Corrective Instruction,https://doi-org.crai.referencistas.com/10.2190/EC.51.2.c,51,2014b,
article,doi:10.1177/0042085913490554,"Following the belief that diversity breeds innovation in scientific endeavors, there is a national push for more diversity in the science, technology, engineering, and mathematics (STEM) workforce in order to maintain national economic competitiveness. Currently, STEM-related employment is only 28% non-White; however, greater efforts to recruit and retain underrepresented minorities should increase this figure. Amidst the attention given to supporting “leaky pipelines,” less emphasis has been placed on mitigating challenges associated with bringing diverse cultures together. This article presents a framework for supporting underrepresented minorities in building STEM-relevant skills and enhancing their ability to collaborate with peers different from themselves.",Shaundra Bryant Daily and Wanda Eugene,10.1177/0042085913490554,https://doi-org.crai.referencistas.com/10.1177/0042085913490554,Urban Education,5,682–704,Preparing the Future STEM Workforce for Diverse Environments,https://doi-org.crai.referencistas.com/10.1177/0042085913490554,48,2013c,
article,doi:10.1177/0047239520926971,"Courses on computer programming are included in the curricula of almost all engineering disciplines. We surveyed the research literature and identified the techniques that are commonly used by instructors for teaching these courses. We observed that visual programming and game-based learning can enhance computational thinking and problem-solving skills in students and may be used to introduce them to programming. Robot programming may be used to attract students to programming, but the success of this technique is subjected to the availability of robots. Pair and collaborative programming allows students to learn from one another and write efficient programs. Assessment systems help instructors in evaluating programs written by students and provide them with timely feedback. Furthermore, an analysis of citations showed that Scratch is the most researched tool for teaching programming. We discuss how these techniques may be used to teach introductory courses, advanced courses, and massive open online courses on programming.",Kanika and Shampa Chakraverty and Pinaki Chakraborty,10.1177/0047239520926971,https://doi-org.crai.referencistas.com/10.1177/0047239520926971,Journal of Educational Technology Systems,2,170–198,Tools and Techniques for Teaching Computer Programming: A Review,https://doi-org.crai.referencistas.com/10.1177/0047239520926971,49,2020d,
article,doi:10.1177/0255761419861442,"This study explored how Australian music technology courses teach employability skills. A curriculum mapping of 63 undergraduate courses was conducted with course learning outcomes aligned against two benchmarks. The first benchmark was the Ten Skills for the Future Workforce which identifies key employability skills graduates will require in the coming decade. The second benchmark was the Australian Qualifications Framework Specification for the Bachelor Degree which defines the generic skills graduates must obtain through Australian Bachelor Degrees. This curriculum mapping reveals that Australian music technology courses teach Novel and Adaptive Thinking, Computational Thinking, New Media Literacy, and Design Mindsets universally. However, this curriculum mapping also reveals a deficit in employability skills related to Cross-Cultural Competency, Transdisciplinarity, Virtual Collaboration, and Collaboration more generally. The implications of this mapping is that Australian music technology educators seem to be prioritizing specific technical and creative skills over higher-order applications of skills and knowledge which are contextualized in their broader social and cultural contexts. Finally, this article shows how curriculum mapping can be implemented to embed employability skills progressively across a program sequence using a case study from the School of Music, University of Queensland.",Eve Klein and James Lewandowski-Cox,10.1177/0255761419861442,https://doi-org.crai.referencistas.com/10.1177/0255761419861442,International Journal of Music Education,4,636–653,Music technology and Future Work Skills 2020: An employability mapping of Australian undergraduate music technology curriculum,https://doi-org.crai.referencistas.com/10.1177/0255761419861442,37,2019e,
article,doi:10.1111/j.1467-9280.1994.tb00625.x,"Traditional theories of cognitive development predict that children progress from intuitive to computational thinking, whereas fuzzy-trace theory makes the opposite prediction To evaluate these alternatives, framing problems were administered to preschoolers, second graders, and fifth graders Consistent with fuzzy-trace theory, results indicated (a) that younger children focused on quantitative differences between outcomes and did not exhibit framing effects (risk avoidance for gains, risk seeking for losses) and (b) that older children assimilated these quantitative differences and displayed framing effects",Valerie F Reyna and Susan C Ellis,10.1111/j.1467-9280.1994.tb00625.x,https://doi-org.crai.referencistas.com/10.1111/j.1467-9280.1994.tb00625.x,Psychological Science,5,275–279,Fuzzy-Trace Theory and Framing Effects in Children’s Risky Decision Making,https://doi-org.crai.referencistas.com/10.1111/j.1467-9280.1994.tb00625.x,5,1994f,
article,doi:10.1177/1464884914545729,"Research on ‘digital’ journalism has focused largely on online news, with comparatively less interest in the longer-term implications of software and computational technologies. Drawing upon a 6-year study of the Toronto Star, this article provides an account of TOPS, an in-house web content management system which served as the backbone of thestar.com for 6 years. For some, TOPS was a successful software innovation, while for others, a strategic digital ‘property’. But for most journalists, it was slow, deficient in functionality, aesthetically unappealing and cumbersome. Although several organizational factors can explain TOPS’ obstinacy, I argue for particular attention to the complex ontology of software. Based on an outline of this ontology, I suggest software be taken seriously as an object of journalism, which implies acknowledging its partial autonomy from human use or authorization, accounting for its ability to mutate indefinitely and analysing its capacity to encourage forms of ‘computational thinking’.",Scott Rodgers,10.1177/1464884914545729,https://doi-org.crai.referencistas.com/10.1177/1464884914545729,Journalism,1,10–26,"Foreign objects? Web content management systems, journalistic cultures and the ontology of software",https://doi-org.crai.referencistas.com/10.1177/1464884914545729,16,2015g,
article,doi:10.1177/1470412920964905,"This article proposes thinking of media archaeology as an operating table upon which historical, material and technological interconnections between fashion and film are made. By exploring how early cinema and digital film can be coupled to textile as technology, more specifically through the mechanisms of the sewing machine and the Jacquard loom, it extends the historical span from the mid-1890s, with the invention of cinema as projection, to the early 1800s, when computational thinking was successfully implemented as weaving technique. Instead of focusing on film and fashion as means of visual representation, the author relies on the concept of inscription for a better understanding of both cinema (as recording of light and movement) and textile (with its various thread techniques of weaving, stitching, knitting, etc.).",Wanda Strauven,10.1177/1470412920964905,https://doi-org.crai.referencistas.com/10.1177/1470412920964905,Journal of Visual Culture,3,362–377,Sewing machines and weaving looms: a media archaeological encounter between fashion and film,https://doi-org.crai.referencistas.com/10.1177/1470412920964905,19,2020h,
article,doi:10.1177/0735633117746747,"Computer programming has been gradually emphasized in recent computer literacy education and regarded as a requirement for all middle school students in some countries. To understand young students’ perceptions about their own learning in computer programming, this study aimed to develop an instrument, Computer Programming Self-Efficacy Scale (CPSES), for all students above middle school levels. Based on Berland and Lee’s computational thinking framework, this study developed the CPSES items at a literacy level and finally the instrument included the five subscales: Logical Thinking, Algorithm, Debug, Control, and Cooperation. An exploratory factor analysis and reliability tests were conducted in this study. The reliability alpha was .96 for the overall scale, and ranged from .84 to .96 for the subscales. This study also confirmed the positive correlation between computer programming experience and computer programming self-efficacy. In addition, for low- and middle-experienced learners, significant gender differences were found in two subscales: Algorithm and Debug. The CPSES can be applied as an evaluation tool in computer education, robotics education, as well as integrated STEM or STEAM education in which computer programming was regarded as a part of computer literacy.",Meng-Jung Tsai and Ching-Yeh Wang and Po-Fen Hsu,10.1177/0735633117746747,https://doi-org.crai.referencistas.com/10.1177/0735633117746747,Journal of Educational Computing Research,8,1345–1360,Developing the Computer Programming Self-Efficacy Scale for Computer Literacy Education,https://doi-org.crai.referencistas.com/10.1177/0735633117746747,56,2019i,
article,doi:10.1177/1478077117734660,"Parquet Deformation is an architectural studio exercise introduced by William Huff in 1960s. It aims to improve students’ reasoning of spatiotemporal variation by utilizing sequential shapeshifting of patterns. This article examines the outcomes of this educational research from a perspective of design computing with a purpose to remark its pedagogical significance. A multilayered reading about the exercise will reveal its historical, theoretical, and artistic backgrounds. Then the common structural elements and different construction approaches are explained along with a novel design and analysis method. The proposed method embeds variations of two-dimensional pattern deformations on a third dimension. It enables various analyses such as the measurement of regularity and locating the attractor points. This study is expected to exemplify how computational thinking and new digital tools change the way designers would approach to such systematic compositions.",Tuğrul Yazar,10.1177/1478077117734660,https://doi-org.crai.referencistas.com/10.1177/1478077117734660,International Journal of Architectural Computing,4,250–267,Revisiting Parquet Deformations from a computational perspective: A novel method for design and analysis,https://doi-org.crai.referencistas.com/10.1177/1478077117734660,15,2017j,
article,doi:10.1177/03064190211026207,"Active student engagement, teaching via experience in real-life settings and learning by doing, are pedagogical strategies appropriate to improve student-reasoning skills. By building models, performing investigations, examining and explaining experimental results, using theoretical and computational thinking, constructing representations, undergraduates can acquire a deeper understanding of fundamental disciplinary concepts while reinforcing transversal abilities. In this framework, Engineering courses should be designed with the final objective to develop practical skills, focusing on hands-on activities. This contribution presents two different inquiry-based learning environments recently experienced at the University of Palermo in the context of bioelectronic and biomedical Engineering. The first study describes a laboratory activity about digital ophthalmologic signal classification; the second laboratory focuses on the analysis of the prefrontal cortex activation during a memory task using functional Near InfraRed Spectroscopy (fNIRS). We introduce and discuss the learning workshops, with the research objective of improving current instruction and training in Engineering courses. Indeed, this contribution aims to suggest a conceptual framework in the form of a structured elective suite of modules tailored to meet the needs of Engineering graduates. The outcomes of both studies seem to highlight that self-directed learning activities could enhance students’ enthusiasm to learn and engagement in engineering investigations, contributing to improve the achievements of students and acquire a more effective learning approach.",Dominique Persano Adorno,10.1177/03064190211026207,https://doi-org.crai.referencistas.com/10.1177/03064190211026207,International Journal of Mechanical Engineering Education,3,629–647,Inquiry-based environments for bio-signal processing training in engineering education,https://doi-org.crai.referencistas.com/10.1177/03064190211026207,50,2022a,
article,doi:10.1177/1461444815624182,"This article examines the articulation of computational journalism, focusing on how the meaning of the computational is discursively constructed and mobilized as a specific constellation of intelligibility within news organizations. Relying on the concept of articulation developed in cultural studies, the article asks what, exactly, is meant by the computational in the context of journalism? Drawing on interviews with key managerial staff, editors and developers at Scandinavian news organizations, three broad claims about the linkage between the computational and journalism emerged. These articulations include the notion that machines don’t have instincts, that democracy can never be personalized and finally that the computational is something to think with, rather than simulate. The argument is made that what can and cannot be calculated is not merely a technical question, it is also a deeply social, cultural, political and economic one. Thus, the computational emerges as an important organising framework and discursive order for thinking and talking about journalism in the digital age.",Taina Bucher,10.1177/1461444815624182,https://doi-org.crai.referencistas.com/10.1177/1461444815624182,New Media & Society,6,918–933,‘Machines don’t have instincts’: Articulating the computational in journalism,https://doi-org.crai.referencistas.com/10.1177/1461444815624182,19,2017b,
article,doi:10.1177/17479541221136238,"The sports statistics community is rapidly evolving. R is an open-source software in constant development that has gained a lot of popularity within statistical communities and sports analytics. This work presents a systematic review of the available R CRAN sport packages following PRISMA guidelines. We consider all packages active as of 18 February 2021. A total of 81 sport R packages created since 2006 were detected. Of these, 35.9% were authored by an American national, 69.1% include a dataset, 43.2% provide vignettes, and 65.4% have been updated at least once. The sport with the highest representation is basketball (n = 14, 17.3%), followed by soccer (n = 12, 14.8%) and packages related to physical activity (n = 11, 13.6%). There are no sports packages directed solely for the female gender, while 59.3% of packages are focused on professional athletes. Fifty packages (61.7%) are related to the sports performance analysis category, and web scraping (n = 43, 53.1%) was the main functionality in the collected packages. The creation of new R packages in the area of sports could help solve questions and tasks that still remain a challenge in this field, while continuing to help to improve the level of statistical education and computational thinking skills.",Martí Casals and José Fernández and Victor Martínez and Michael Lopez and Klaus Langohr and Jordi Cortés,10.1177/17479541221136238,https://doi-org.crai.referencistas.com/10.1177/17479541221136238,International Journal of Sports Science & Coaching,2,621–629,A systematic review of sport-related packages within the R CRAN repository,https://doi-org.crai.referencistas.com/10.1177/17479541221136238,18,2023c,
article,doi:10.1177/2042753018757757,,Enrico Gandolfi,10.1177/2042753018757757,https://doi-org.crai.referencistas.com/10.1177/2042753018757757,E-Learning and Digital Media,3,128–145,You have got a (different) friend in me: Asymmetrical roles in gaming as potential ambassadors of computational and cooperative thinking,https://doi-org.crai.referencistas.com/10.1177/2042753018757757,15,2018d,
article,doi:10.1177/07356331221133560,"Reintroducing computer science (CS) education in K–12 schools to promote computational thinking (CT) has attracted significant attention among scholars and educators. Among the several essential components included in CS and CT education, program debugging is an indispensable skill. However, debugging teaching has often been overlooked in K–12 contexts, and relevant empirical studies are lacking in the literature. Moreover, novices generally have poor performance in domain knowledge and strategic knowledge concerning debugging. They also consistently experience a high cognitive burden in debugging learning. To address these gaps, we developed a flipped systematic debugging approach combined with a systematic debugging process (SDP) and the modeling method. A quasi-experimental study was conducted to explore the effectiveness of this flipped systematic debugging approach, in which 83 fifth-grade students attended the flipped debugging training lessons with the SDP–modeling method, and 75 fifth-grade students attended the unassisted flipped debugging training lessons without the SDP–modeling method. The results indicated that flipped debugging training using the SDP–modeling method improved students’ debugging skills. The results from the questionnaire showed that the proposed teaching approach increased the students’ investment in germane cognitive load by promoting schema construction. It also helped reduce students’ intrinsic and extraneous cognitive load in learning.",Xuemin Gao and Khe Foon Hew,10.1177/07356331221133560,https://doi-org.crai.referencistas.com/10.1177/07356331221133560,Journal of Educational Computing Research,5,1064–1095,A Flipped Systematic Debugging Approach to Enhance Elementary Students’ Program Debugging Performance and Optimize Cognitive Load,https://doi-org.crai.referencistas.com/10.1177/07356331221133560,61,2023e,
article,doi:10.1177/1464884913486393,"This article investigates a rapidly expanding branch of journalism innovation in online news media. The umbrella term computational exploration in journalism (CEJ), embraces the multifaceted development of algorithms, data, and social science methods in reporting and storytelling. CEJ typically involves the journalistic co-creation of quantitative news projects that transcend geographical, disciplinary, and linguistic boundaries. Drawing on extensive empirical data, this article provides a conceptual overview of the field by identifying three main pathways of computational exploration in journalism: the newsroom approach, the academic approach, and the entrepreneurial approach. Implications for changing journalistic practice are discussed, and the theorizing is summed up in a triplex proposition about changing mindset processes coming out of CEJ. The study indicates that the computational exploration not only leads to innovative uses of the technology, but also to innovative ways for journalists to think and behave; journalism innovation leads to innovation journalism.",Astrid Gynnild,10.1177/1464884913486393,https://doi-org.crai.referencistas.com/10.1177/1464884913486393,Journalism,6,713–730,Journalism innovation leads to innovation journalism: The impact of computational exploration on changing mindsets,https://doi-org.crai.referencistas.com/10.1177/1464884913486393,15,2014f,
article,doi:10.1177/1094342017738352,"The ever-increasing computational requirements of HPC and service provider applications are becoming a great challenge for hardware and software designers. These requirements are reaching levels where the isolated development on either computational field is not enough to deal with such challenge. A holistic view of the computational thinking is therefore the only way to success in real scenarios. However, this is not a trivial task as it requires, among others, of hardware–software codesign. In the hardware side, most high-throughput computers are designed aiming for heterogeneity, where accelerators (e.g. Graphics Processing Units (GPUs), Field-Programmable Gate Arrays (FPGAs), etc.) are connected through high-bandwidth bus, such as PCI-Express, to the host CPUs. Applications, either via programmers, compilers, or runtime, should orchestrate data movement, synchronization, and so on among devices with different compute and memory capabilities. This increases the programming complexity and it may reduce the overall application performance. This article evaluates different offloading strategies to leverage heterogeneous systems, based on several cards with the first-generation Xeon Phi coprocessors (Knights Corner). We use a 11-point 3-D Stencil kernel that models heat dissipation as a case study. Our results reveal substantial performance improvements when using several accelerator cards. Additionally, we show that computing of an approximate result by reducing the communication overhead can yield 23% performance gains for double-precision data sets.",Mario Hernández and Juan M Cebrián and José M Cecilia and José M García,10.1177/1094342017738352,https://doi-org.crai.referencistas.com/10.1177/1094342017738352,The International Journal of High Performance Computing Applications,2,199–207,Offloading strategies for Stencil kernels on the KNC Xeon Phi architecture: Accuracy versus performance,https://doi-org.crai.referencistas.com/10.1177/1094342017738352,34,2020g,
article,doi:10.1177/02663821221110042,"Libraries as social spaces are bound to evolve based on a society’s level of civilisation and information media. This paper argues that the emergence of smart libraries have changed the paradigms of library by acknowledging the potential benefits and transformation smart library brings to library operations and services. It notes that analytical and computational thinking, data literacy, information literacy, social intelligence, programs and project management, cross-cultural competency, transliteracy, transdisciplinary, design thinking and mindset, virtual collaboration and cognitive load management are skills to be possessed by smart librarians. It highlights cloud computing, big data, 3D printing, IoT, Artificial Intelligence, RFID, drones etc., as the emerging technologies used for smart libraries and further discusses smart services, smart people, smart places and smart governance as the dimensions of smart library. Revelations are further made that smart libraries aid space saving, expansion of library working hours and services and promotes access to information, while remarks are made that lack of technological know-how, technophobia, data privacy and security, etc., are the challenges of smart library. It concludes that the emergence of smart library have facilitated the redefinition of library services and operations and recommends amongst others that librarians should continuously update their skills so that they can meet up with competitions that may arise from the challenges of globalisation of the information landscape.",Kingsley N Igwe and Abdulakeem S Sulyman,10.1177/02663821221110042,https://doi-org.crai.referencistas.com/10.1177/02663821221110042,Business Information Review,4,147–152,Smart libraries: Changing the paradigms of library services,https://doi-org.crai.referencistas.com/10.1177/02663821221110042,39,2022h,
article,doi:10.1177/2042753017731357,,Jennifer Jenson and Milena Droumeva,10.1177/2042753017731357,https://doi-org.crai.referencistas.com/10.1177/2042753017731357,E-Learning and Digital Media,4,212–225,Revisiting the media generation: Youth media use and computational literacy instruction,https://doi-org.crai.referencistas.com/10.1177/2042753017731357,14,2017i,
article,doi:10.1177/2042753020980119,"Set in English Language Arts, this article takes up recent trends in literacy toward investigating ontological notions of digital texts. Two teacher educators recently implemented a series of readings and activities in their methods courses designed to help preservice teachers sophisticate their conceptions of texts beyond autonomous, neutral collections of information by considering digital age ideas such as software theory, textual ideology, and the algorithmic bias of the Internet. The authors review recent scholarship surrounding the integration of computational thinking and the humanities before illustrating a theoretical framework that combines software-driven interpretation and critical media literacy. Descriptions and applications of course texts and exercises precede a discussion on typological methodology. Through the analysis of semester-long writing reflections and course interactions, a typology of preservice teachers is then presented, illustrating three archetypes: Strategists, Hawkeyes, and Improvers. These archetypes are taken up to analyze the ways in which a range of teacher candidates considered ontological notions of digital texts to analyze instructional techniques, to sharpen their critical lenses, or to gain greater understanding of ELA as a discipline (or some combination of all three). This work demonstrates that as teacher educators and teacher candidates increasingly consider software-powered literacies, interrogations of who we are, who we are becoming, and what it all means requires attention to, and explicit practice with, the dark side of digital texts.",Rick Marlatt and Mark A Sulzer,10.1177/2042753020980119,https://doi-org.crai.referencistas.com/10.1177/2042753020980119,E-Learning and Digital Media,3,226–250,Illuminating the dark side: A typology for preservice ELA teachers engaging in ideologies of digital texts,https://doi-org.crai.referencistas.com/10.1177/2042753020980119,18,2021j,
article,doi:10.1177/1478077117735019,"This study sheds light on a holistic understanding of muqarnas with its historical, philosophical and conceptual backgrounds on one hand and formal, structural and algorithmic principles on the other hand. The vault-like Islamic architectural element, muqarnas, is generally considered to be a non-structural decorative element. Various compositional approaches have been proposed to reveal the inner logic of these complex geometric elements. Each of these approaches uses different techniques such as measuring, unit-based decoding or three-dimensional interpretation of two-dimensional patterns. However, the reflections of the inner logic onto different contexts, such as the usage of different initial geometries, materials or performative concerns, were neglected. In this study, we offer a new schema to approach the performative aspects of muqarnas tectonics. This schema contains new sets of elements, properties and relations deriving partly from previous approaches and partly from the technique of folding. Thus, this study first reviews the previous approaches to analyse the geometric and constructional principles of muqarnas. Second, it explains the proposed scheme through a series of algorithmic form-finding experiments. In these experiments, we question whether ‘fold’, as one of the performative techniques of making three-dimensional forms, contributes to the analysis of muqarnas in both a conceptual and computational sense. We argue that encoding vault-like systems via geometric and algorithmic relations based on the logic of the ‘fold’ provides informative and intuitive feedback for form-finding, specifically in the earlier phases of design. While focusing on the performative potential of a specific fold operation, we introduced the concept of bifurcation to describe the generative characteristics of folding technique and the way of subdividing the form with respect to redistribution of the forces. Thus, in this decoding process, the bifurcated fold explains not only to demystify the formal logic of muqarnas but also to generate new forms without losing contextual conditions.",Sema Alaçam and Orkan Zeynel Güzelci and Ethem Gürer and Saadet Zeynep Bacınoğlu,10.1177/1478077117735019,https://doi-org.crai.referencistas.com/10.1177/1478077117735019,International Journal of Architectural Computing,4,285–303,Reconnoitring computational potentials of the vault-like forms: Thinking aloud on muqarnas tectonics,https://doi-org.crai.referencistas.com/10.1177/1478077117735019,15,2017a,
article,doi:10.1177/0042098016664305,"As visions of smart urbanism gain traction around the world, it is crucial that we question the benefits that an increasingly technologised urbanity promise. It is not about the technology, but bettering peoples’ lives, insist smart city advocates. In this paper, I question the progressive potential of the smart city drawing on the case of Singapore’s Smart Nation initiative. Using the case studies of the smart home and ‘learning to code’ movement, I highlight the limits of such ‘smart’ interventions as they are stunted by the neoliberal-developmental logics of the state, thereby facilitating authoritarian consolidation in Singapore. As such, this paper distinguishes itself from previous works on the neoliberal smart city by situated smart urbanism within the socio-political dynamics of neoliberalism-as-developmental strategy. For smart urbanism to better peoples’ everyday lives, technological ‘solutionism’ needs to be replaced with more human-centric framings and understandings of urban challenges.",Ezra Ho,10.1177/0042098016664305,https://doi-org.crai.referencistas.com/10.1177/0042098016664305,Urban Studies,13,3101–3118,Smart subjects for a Smart Nation? Governing (smart)mentalities in Singapore,https://doi-org.crai.referencistas.com/10.1177/0042098016664305,54,2017b,
article,doi:10.1177/20592043221085659,"Traditional harmonic analysis annotations can be represented in a computer model of a piece of music by plain text strings. But whenever automated processing like analysis, comparison or retrieval is intended, a formal definition is helpful. This should cover not only the syntactic structure, but also the semantics, i.e. the intended meaning, and thus adheres to the technique of mathematical remodelling of existing cultural phenomena. The resulting models can serve as a basis for automated processing, but also help to clarify the communication and discussion among humans substantially. This article proposes such a definition in four layers, which address different problems of encoding and communication: (a) relation of symbol sequences to staff positions, (b) combining functions, (c) chord roots, and (d) interval structure and voice leading. Only one of them is specific to functional (Riemannian) theory and can possibly be replaced to represent scale degree theory. The proposal is configurable to different interval specification methods and open to localisation. Syntax and semantics are defined by precise mathematical means, borrowed from computer science, and thus are unambiguously documented.",Markus Lepper and Baltasar Trancòn y Widemann and Michael Oehler,10.1177/20592043221085659,https://doi-org.crai.referencistas.com/10.1177/20592043221085659,Music & Science, ,20592043221085660,funCode—Versatile Syntax and Semantics for Functional Harmonic Analysis Labels,https://doi-org.crai.referencistas.com/10.1177/20592043221085659,5,2022c,
article,doi:10.1177/0735633120932871,"The recent shift in compulsory education from ICT-focused computing curricula to informatics, digital literacy and computer science, has resulted in children being taught computing using block-based programming tools such as Scratch, with teaching that is often limited by school resources and teacher expertise. Even without these limitations, Scratch users often produce code with ‘code smells’ such as duplicate blocks and long scripts which impact how they understand and debug projects. These code smells can be removed using procedural abstraction, an important concept in computer science rarely taught to this age group. This article describes the design of a novel educational block-based programming game, Pirate Plunder, which concentrates on how procedural abstraction is introduced and reinforced. The article then reports an extended evaluation to measure the game’s efficacy with children aged 10 and 11, finding that children who played the game were then able to use procedural abstraction in Scratch. The article then uses game analytics to explore why the game was effective and gives three recommendations for educational game design based on this research: using learning trajectories and restrictive success conditions to introduce complex content, increasing learner investment through customisable avatars and suggestions for improving the evaluations of educational games.",Simon P. Rose and M. P. Jacob Habgood and Tim Jay,10.1177/0735633120932871,https://doi-org.crai.referencistas.com/10.1177/0735633120932871,Journal of Educational Computing Research,7,1372–1411,Designing a Programming Game to Improve Children’s Procedural Abstraction Skills in Scratch,https://doi-org.crai.referencistas.com/10.1177/0735633120932871,58,2020d,
article,doi:10.1177/01614681221103932,"Background: There has been a dearth of research on intersectional identities in STEM, including the fields of computing and engineering. In computing education research, much work has been done on broadening participation, but there has been little investigation into how the field of computer science (CS) presents opportunities for students with strong intersectional identities. This study explores the strengths and connections among the unique identities and the symbiotic relationships that elementary Latina students hold in CS identity attainment. Purpose: The aim of this article is to better understand how predominantly low-income, multilingual Latina students experience identity development through the lens of diverse group membership. We examine how young Latinas, through their participation in a yearlong culturally and linguistically responsive CS curriculum, leverage their intersecting identities to rewrite the formula of what a computer scientist is and can be, leaving space to include and invite other strong identities as well. Research Design: An explanatory sequential mixed-methods design was used that analyzed data from predominantly low-income, multilingual Latinas in upper elementary grades, including pre- and post-CS identity surveys (N = 50) delivered before and after implementation of the curriculum, and eight individual semi-structured student interviews. Findings: We found that Latina students developed significantly stronger identification with the field of CS from the beginning to the end of the school year with regard to their experiences with CS, perception of themselves as computer scientists, family support for CS and school, and friend support for CS and school. Interviews revealed that perception of their CS ability greatly influenced identification with CS and that girls’ self-perceptions stemmed from their school, cultural, and home learning environments. Conclusion: Our results highlight the wealth of resources that Latinas bring to the classroom through their home- and community-based assets, which are characterized by intersecting group membership. Students did not report on the intersection between language and CS identity development, which warrants further investigation.",Sharin Rawhiya Jacob and Jonathan Montoya and Mark Warschauer,10.1177/01614681221103932,https://doi-org.crai.referencistas.com/10.1177/01614681221103932,Teachers College Record,5,166–185,Exploring the Intersectional Development of Computer Science Identities in Young Latinas,https://doi-org.crai.referencistas.com/10.1177/01614681221103932,124,2022e,
article,doi:10.1177/23476311231183204,"Integration of computational data science (CDS) into the university curriculum offers several advantages for students, faculty and the institution. This article discusses the benefits to students of introducing CDS into the university curriculum with a focus on developing skills in cheminformatics, data analysis, structure–activity relationships, modelling and simulation. Moreover, CDS can enable students to engage with complex chemical and toxicological data in new and dynamic ways, helping them to develop a more nuanced understanding of the potential hazards and risks associated with different chemicals and substances. On the other hand, it can foster greater collaboration between students and faculty and with external partners in industry and government. This can lead to the development of more effective and efficient toxicological testing methods and tools to screen chemicals for potential hazards and aid the development of environmentally friendly chemicals. Overall, the integration of CDS into the university curriculum will help prepare the next generation of scientists giving them a competitive edge to make considerable contributions to green chemistry, designing safer chemicals and non-animal testing methods. It will enable them to tackle modern challenges facing society including identifying safer and more sustainable chemicals and predicting the health and environmental impacts of novel chemical substances.",N. Renu and K. Sunil,10.1177/23476311231183204,https://doi-org.crai.referencistas.com/10.1177/23476311231183204,Higher Education for the Future,2,183–195,Integrating Computational Data Science in University Curriculum for the New Generation of Scientists,https://doi-org.crai.referencistas.com/10.1177/23476311231183204,10,2023f,
article,doi:10.1177/14780771241260850,"This article describes generative algorithms and Digital Fabrication techniques with organic materials to create complex 3D objects for industrial design, sculpture, and architecture. Experimental artistic production using these algorithms concluded with a solution based on programmable meshes, which use identifiers to control the topological characteristics of vertices during the modeling process. On the other hand, the hybridization of analog and digital techniques was explored through fabrication. Comparing artistic production and hybrid techniques with generative AI, we will discuss topics of Computational Creativity in art, industrial design, and architecture. The programmable meshes solution, combined with hybrid fabrication processes, enables an incredible variety of complex forms, stimulates artistic creativity, and provides flexible feedback to bypass some Digital Fabrication issues. Our findings also elucidate the importance of original technology development and cultural identity in fostering creative and culturally inclusive technologies for art and education.",Umberto Luigi Roncoroni and Veronica Crousse de Vallongue and Octavio Centurion Bolaños,10.1177/14780771241260850,https://doi-org.crai.referencistas.com/10.1177/14780771241260850,International Journal of Architectural Computing,0,14780771241260850,Computational creativity issues in generative design and digital fabrication of complex 3D meshes,https://doi-org.crai.referencistas.com/10.1177/14780771241260850,0,2024g,
article,doi:10.1163/22125868-12340075,"The 21st century era of rapidly changing technology entails cognizance of the changing nature of knowledge, learning and environments. New models of knowledge building and knowledge co-creation are emerging. Personalized learning takes on new dimensions with mobile devices and new tools for sharing and meta-thinking. Evidences from research in learning sciences and neurosciences point to the importance of understanding human cognition and behaviors in optimizing the use of technology for learning. Future learning entails a powerful use of the cognitive propensity to learn by imitation and modeling as well as the novelty of inquiry and creation. Didactics are replaced by conversational learning with social media as powerful platforms. Apart from the analytics and logic, future learning incorporates big picture thinking, multiple perspective thinking and connective thinking to flourish problem-solving and creativity. The address will conclude with some implications for design and practice.",Oon Seng Tan,10.1163/22125868-12340075,https://doi-org.crai.referencistas.com/10.1163/22125868-12340075,International Journal of Chinese Education,1,81–104,"Technology, Future Learning and Flourishing Thinking",https://doi-org.crai.referencistas.com/10.1163/22125868-12340075,6,2017h,
article,doi:10.1177/0735633120967326,"To explore the role of design thinking in contemporary computer literacy education, this study aimed to examine the relationship between young students’ design thinking disposition and their computer programming self-efficacy. To assess students’ design thinking disposition, this study developed the Design Thinking Disposition Scale (DTDS) with a sample of 350 junior high school students who had computer programming experience in a STEAM course. A principle axis factor analysis with the promax rotation method was used to verify the DTDS’s construct under the four dimensions: empathize, define, ideate and prototype. The Cronbach’s alpha reliability was .90 for the overall scale. Correlation analyses results showed that all the four dimensions were significantly correlated with computer programming self-efficacy assessed by CPSES. A significant regression model was found in which the three factors, ideate, prototype and define, significantly predicted the overall computer programming self-efficacy. Meanwhile, except for the ideate subscale, no gender difference was found in the young students’ design thinking dispositions. The students’ self-directed programming learning experience was shown to benefit their design thinking disposition. The DTDS can be applied to design-thinking-embedded computer literacy curricula such as makers, STEAM, or robotics education. Several further studies are also suggested.",Meng-Jung Tsai and Ching-Yeh Wang,10.1177/0735633120967326,https://doi-org.crai.referencistas.com/10.1177/0735633120967326,Journal of Educational Computing Research,3,410–428,Assessing Young Students’ Design Thinking Disposition and Its Relationship With Computer Programming Self-Efficacy,https://doi-org.crai.referencistas.com/10.1177/0735633120967326,59,2021i,
article,doi:10.1177/14780771211025142,"This article introduces a methodology to implement Data-driven Thinking in the context of urban design. We present the results of a case study based on a 7-day workshop with 10 participants with landscape design and architecture background. The goal of the workshop was to expose participants to Data-driven Thinking through experimental design, multi-sensor data collection, data analysis, visualization, and insight generation. We evaluate their learning experience in designing an experimental setup, collecting real-time immediate environmental and physiological body reactions data. Our results from the workshop show that participants increased their knowledge about measuring, visualizing and understanding data of the surrounding built environment.",Bige Tunçer and Francisco Benita,10.1177/14780771211025142,https://doi-org.crai.referencistas.com/10.1177/14780771211025142,International Journal of Architectural Computing,2,316–333,Data-driven thinking for measuring the human experience in the built environment,https://doi-org.crai.referencistas.com/10.1177/14780771211025142,20,2022j,
article,doi:10.1177/1532708616655759,,Elizabeth de Freitas and Ezekiel Dixon-Román and Patti Lather,10.1177/1532708616655759,https://doi-org.crai.referencistas.com/10.1177/1532708616655759,Cultural Studies ↔ Critical Methodologies,5,431–434,Alternative Ontologies of Number: Rethinking the Quantitative in Computational Culture,https://doi-org.crai.referencistas.com/10.1177/1532708616655759,16,2016a,
article,doi:10.1080/03080188.2020.1865659,"The Faculty of Digital and Computational Studies (DCS) at Bowdoin College proposes a critical, analytical framework, referred to as the ‘4As,’ as an interdisciplinary means to interpret, evaluate, and create the data, operations, and devices of computing across all domains of knowledge production. Following other disciplines that have developed in symbiotic relationships to one another, DCS puts computation in conversation with fields from across the arts, humanities, physical, and social sciences. Our foundational premise is the bidirectional influence between these disciplines and digital artifacts and computation. The 4As (artifact, architecture, abstraction, and agency) benefit from both the scepticism of the liberal arts in the face of ubiquitous digital processes and the analytical opening for examining questions pertaining to creative and imaginative alternatives to the digital and computational status quo. We provide an ultra-contemporary case study to demonstrate the framework in use.",Crystal Hall and Eric Chown and Fernando Nascimento,10.1080/03080188.2020.1865659,https://doi-org.crai.referencistas.com/10.1080/03080188.2020.1865659,Interdisciplinary Science Reviews,4,458–476,"A critical, analytical framework for the digital machine",https://doi-org.crai.referencistas.com/10.1080/03080188.2020.1865659,46,2021b,
article,doi:10.1177/00131245241229666,"With the introduction and implementation of core literacy, scientific thinking (ST) has become an essential goal and key dimension of science teaching. At present, there is no agreement on how to cultivate students’ ST. This study took 238 sixth grade students from a public primary school in urban China as research sample, built a theoretical model of scientific thinking development based on the theory of the Bronfenbrenner’ ecological systems theory, and used multiple data to explore and analyze the impact path of ST development of primary school students using the fuzzy sets of qualitative comparative analysis method (fsQCA). The development of urban primary school students’ ST is the result of multiple factors at the level of individual drive, family environment, school teaching, and social resources. The result of data analysis showed that the influence path of ST development of urban primary school students driven by multiple factors includes three paths: parent participation leading, scientific practice leading, and home-school-community integration. We have interpreted the influence mechanism of each path in detail and put forward the enlightenment for science education policy and practice.",Lin Lin and Danhua Zhou and Xinyi Hu and Jingying Wang and Yu Wang,10.1177/00131245241229666,https://doi-org.crai.referencistas.com/10.1177/00131245241229666,Education and Urban Society,7,906–927,Multiple Factors Drive the Development of Scientific Thinking in Urban Primary School Students of China: FsQCA Analysis Based on the Ecological Systems Theory,https://doi-org.crai.referencistas.com/10.1177/00131245241229666,56,2024c,
article,doi:10.1177/14780771221097683,"Self-learning is receiving great attention internationally in different fields, along with the best utilization of different computational applications or methods. This paper introduces a novel computational approach for supporting Architectural Design Education (ADE) in its early stages; a computational implementation through MATLAB has been developed to conduct the proposed processes. As a scope, spaces’ furnishing design has been selected to demonstrate the proposed computational approach and implementation, while office workspaces have been selected as a representative case. However, the proposed approach provides and enhances ADE through three main concepts: (a) generating design alternatives for different cases of furnishing spaces, (b) providing accurate and flexible evaluations to students’/designers’ works with different levels, and (c) tracking students based on their defaults and relevant sensitive modifications. Different applications of the proposed approach have been generated, analyzed, and validated.",Randa M.A. Mahmoud and Amr M.A. Youssef,10.1177/14780771221097683,https://doi-org.crai.referencistas.com/10.1177/14780771221097683,International Journal of Architectural Computing,2,346–377,A computational framework for supporting architectural education of spaces’ furnishing design,https://doi-org.crai.referencistas.com/10.1177/14780771221097683,20,2022d,
article,doi:10.1177/1532708616655765,"This article reflects on how the ingression of computation in culture has not only transformed media into algorithmic devices but has also, more importantly, led to the automation of the most precious faculty of the human, namely, reasoning. This article problematizes the tout court refusal of algorithmic thinking as thinking and suggests that we are witnessing the advance of a dynamic form of automated reasoning, exposing the limits of the critical approach toward the calculative. The article points out that the alliance between algorithmic automation and the digital infrastructure of neoliberalism is not without significance, but attention must be paid to the specific posthuman form of cognitive capitalism.",Luciana Parisi,10.1177/1532708616655765,https://doi-org.crai.referencistas.com/10.1177/1532708616655765,Cultural Studies ↔ Critical Methodologies,5,471–481,Automated Thinking and the Limits of Reason,https://doi-org.crai.referencistas.com/10.1177/1532708616655765,16,2016e,
article,doi:10.1177/08944393231167692,"The domains of computational social anthropology and computational ethnography refer to the computational processing or computational modelling of data for anthropological or ethnographic research. In this context, the article surveys the use of computational methods regarding the production and the representation of knowledge. The ultimate goal of the study is to highlight the significance of modelling ethnographic data and anthropological knowledge by harnessing the potential of the semantic web. The first objective was to review the use of computational methods in anthropological research focusing on the last 25 years, while the second objective was to explore the potential of the semantic web focusing on existing technologies for ontological representation. For these purposes, the study explores the use of computers in anthropology regarding data processing and data modelling for more effective data processing. The survey reveals that there is an ongoing transition from the instrumentalisation of computers as tools for calculations, to the implementation of information science methodologies for analysis, deduction, knowledge representation, and reasoning, as part of the research process in social anthropology. Finally, it is highlighted that the ecosystem of the semantic web does not subserve quantification and metrics but introduces a new conceptualisation for addressing and meeting research questions in anthropology.",Manolis Peponakis and Sarantos Kapidakis and Martin Doerr and Eirini Tountasaki,10.1177/08944393231167692,https://doi-org.crai.referencistas.com/10.1177/08944393231167692,Social Science Computer Review,1,84–102,"From Calculations to Reasoning: History, Trends and the Potential of Computational Ethnography and Computational Social Anthropology",https://doi-org.crai.referencistas.com/10.1177/08944393231167692,42,2024f,
article,doi:10.1177/00472816211072533,"This article follows up on the conversation about new streams of approaches in technical communication and user experience (UX) design, i.e., design thinking, content strategy, and artificial intelligence (AI), which afford implications for professional practice. By extending such implications to technical communication pedagogy, we aim to demonstrate the importance of paying attention to these streams in our programmatic development and provide strategies for doing so.",Jason Tham and Tharon Howard and Gustav Verhulsdonck,10.1177/00472816211072533,https://doi-org.crai.referencistas.com/10.1177/00472816211072533,Journal of Technical Writing and Communication,4,428–459,"Extending Design Thinking, Content Strategy, and Artificial Intelligence into Technical Communication and User Experience Design Programs: Further Pedagogical Implications",https://doi-org.crai.referencistas.com/10.1177/00472816211072533,52,2022g,
article,doi:10.1177/0306419016674133,"This paper reports the recent development and implementation of three teaching modules in order to teach and enhance the students’ critical thinking skills in a level IV undergraduate/postgraduate course ‘Computational Fluid Dynamics (CFD) for Engineering Applications’. These teaching modules include a lecture module, an online test module and a CFD project module. The lecture module introduces the importance of critical thinking skills by an example case, critical thinking definition and processes, and the application of critical thinking skills in formulation of CFD problems. In the online test module, seven online tests have been developed to enhance the students’ understanding of the contents of lectures and practical sessions. Meanwhile, students apply their critical thinking skills to work out some of the tests. In the project module, a student-driven CFD project is designed to help students to apply CFD techniques and critical thinking skills in engineering problems. In the project, students choose their own project topic and problems. They use CFD skills learned in the course and critical thinking skills to critically analyse their problems, identify the important parameters and review results. They apply the critical writing skills to finalise a project report. To the best knowledge of the author, this systematical integration of teaching and enhancement of critical thinking skills in computational fluid dynamics course is innovative. Feedback from students is quite positive shown by an anonymous survey in 2014.",Zhao F Tian,10.1177/0306419016674133,https://doi-org.crai.referencistas.com/10.1177/0306419016674133,International Journal of Mechanical Engineering Education,1,76–88,Teaching and enhancement of critical thinking skills for undergraduate students in a computational fluid dynamics course,https://doi-org.crai.referencistas.com/10.1177/0306419016674133,45,2017h,
article,doi:10.1177/2053951715617783,"Coupled with the ‘smart city’, the idea of the ‘smart school’ is emerging in imaginings of the future of education. Various commercial, governmental and civil society organizations now envisage education as a highly coded, software-mediated and data-driven social institution. Such spaces are to be governed through computational processes written in computer code and tracked through big data. In an original analysis of developments from commercial, governmental and civil society sectors, the article examines two interrelated dimensions of an emerging smart schools imaginary: (1) the constant flows of digital data that smart schools depend on and the mobilization of analytics that enable student data to be used to anticipate and shape their behaviours; and (2) the ways that young people are educated to become ‘computational operatives’ who must ‘learn to code’ in order to become ‘smart citizens’ in the governance of the smart city. These developments constitute an emerging educational space fabricated from intersecting standards, technologies, discourses and social actors, all infused with the aspirations of technical experts to govern the city at a distance through both monitoring young people as ‘data objects’ and schooling them as active ‘computational citizens’ with the responsibility to compute the future of the city.",Ben Williamson,10.1177/2053951715617783,https://doi-org.crai.referencistas.com/10.1177/2053951715617783,Big Data & Society,2,2053951715617783,Educating the smart city: Schooling smart citizens through computational urbanism,https://doi-org.crai.referencistas.com/10.1177/2053951715617783,2,2015i,
article,doi:10.1177/20438206231179477,"This commentary lays out a framework for building on early critical cartographic and critical geographic information system work to develop a critical approach for the computational future of geographical thought and praxis. Computation – as a highly representational and structural form which combines speech and action – is a very particular way of building worlds. As computation becomes more prevalent in critiques of deep fakes, GeoAI, and platform geographies, geographers have also developed the foundations for a critical computational approach with an explicitly spatial or geographical focus that combines both theory and practice. Yet, while many of the technological affordances of spatial computation are relatively novel, the critiques raised by social, political, economic, and cultural geographers shadow debates that emerged two decades ago between cartographers and geospatial scientists about the power and praxis of mapping as it becomes translated into a digital era. This commentary argues that by returning to these debates, as well as critique by Black, queer, and Indigenous computing seen in other disciplines, geographers find themselves in a moment of opportunity to deeply influence the future of computation via a situated, critical geographical thought and praxis.",Clancy Wilmott,10.1177/20438206231179477,https://doi-org.crai.referencistas.com/10.1177/20438206231179477,Dialogues in Human Geography,2,332–336,Critical computation on a geographical register,https://doi-org.crai.referencistas.com/10.1177/20438206231179477,14,2024j,
article,doi:10.1177/02666669211049135,"New information and computer technologies transform the social interaction and impose new demands for skills and thinking upon media specialists. The aim of this study is to determine the most effective set of information technologies, which can help media specialists develop competencies and thus stay competitive in the labor market. The research methodology is based on the overview of case studies concerning issues such as technology trends, human capital, and talent competitiveness. The qualitative analysis was performed in three phases – overviewing case studies, distinguishing trends and problem-solving. Analyzing data on skill supply and demand, the key skills needed to succeed in the workplace were identified. The results of the three-phase research revealed that the most important competencies needed to be in demand today are technology literacy, stress tolerance, and big data skills. The major finding of this study is that a media specialist needs to focus on learning throughout his life and gain hard and soft skills in the process.",Nidal Al Said and Butheyna Zuheir Al-Rawashdeh,10.1177/02666669211049135,https://doi-org.crai.referencistas.com/10.1177/02666669211049135,Information Development,3,380–390,Information and computer technologies in media specialist preparation,https://doi-org.crai.referencistas.com/10.1177/02666669211049135,38,2022a,
article,doi:10.1177/14780771241279347,"Hybrid girihs refer to Islamic geometric patterns that include various stars/rosettes in their final pattern. In this paper, we first identified historical hybrid girihs and then categorized them based on symmetry groups and the number of stars/rosettes folds. In the next step, we analyzed the existing hybrid girihs to identify the generative parameters and present a method for generating historical and novel systematic and non-systematic hybrid girihs. The proposed method of this paper is a computational and parametric approach based on the symmetry groups theory. Its general steps include generating the minimal essential information (template motif) within the fundamental region, applying appropriate symmetry operations on the content of the fundamental region to create the content of the unit girih, and replicating the content of the unit girih in a suitable network according to the symmetry group to create the whole pattern. Our method is used to generate hybrid girih for adorning surfaces in digital spaces and for constructing facade modules (adorned with Islamic geometric patterns) and interior decorative partitions and furniture in physical spaces according to the aesthetic judgment of users.",Ali Azizi Naserabad and Abdulhamid Ghanbaran,10.1177/14780771241279347,https://doi-org.crai.referencistas.com/10.1177/14780771241279347,International Journal of Architectural Computing,0,14780771241279348,Computational approach in presentation a parametric method to construct hybrid girihs (hybrid Islamic geometric patterns),https://doi-org.crai.referencistas.com/10.1177/14780771241279347,0,2024b,
article,doi:10.1177/10762175221149256,"As technologically gifted students apply their abilities to computer science, they naturally flow through the talent development stages of potential, competency, and expertise. Processes that have always been important for gifted students to learn as they develop potential are embedded in learning code, which engages the beginning programmer in rich and complex authentic projects (Housand et al., 2017). As stakeholders present opportunities for open-ended, creative processes and products, the Computer Science Teachers Association (CSTA; 2017) and International Society for Technology in Education (ISTE; 2016) Standards can form guidelines for gifted students to self-direct their education through technology. Learning to code results in both cognitive and psychosocial skill development, including creative and critical thinking, logical and systematic reasoning, positive risk-taking and processing of feedback, perseverance through challenges, social skills, and collaboration.",Maryann R. Hebda,10.1177/10762175221149256,https://doi-org.crai.referencistas.com/10.1177/10762175221149256,Gifted Child Today,2,108–118,Technology Talent Development: Beyond an Hour of Code,https://doi-org.crai.referencistas.com/10.1177/10762175221149256,46,2023c,
article,doi:10.1177/003172171309500111,"Learning programming introduces students to solving problems, designing applications, and making connections online.",Yasmin B. Kafai and Quinn Burke,10.1177/003172171309500111,https://doi-org.crai.referencistas.com/10.1177/003172171309500111,Phi Delta Kappan,1,61–65,Computer Programming Goes Back to School,https://doi-org.crai.referencistas.com/10.1177/003172171309500111,95,2013d,
article,doi:10.1177/1326365X20980855,,Sundeep R. Muppidi,10.1177/1326365X20980855,https://doi-org.crai.referencistas.com/10.1177/1326365X20980855,Asia Pacific Media Educator,2,143–144,Editorial,https://doi-org.crai.referencistas.com/10.1177/1326365X20980855,30,2020e,
article,doi:10.1080/02103702.1992.10822322,"Piaget’s (1953, 1955) increasingly controversial claim that infant knowledge depends upon action need not be rejected, provided the mechanisms underlying infant ability are conceptualized appropriately in computational terms. Computational concepts solve many problems caused by Piaget’s notions of perception, behaviour, schemes, reciprocal-assimilation and action. Artificial intelligence work on vision offers a way of explaining early perceptual abilities that is precise, internally coherent and able to encompass recent findings of innate organization. Concepts from the procedural programming languages offer a way of accounting for both internal and overt aspects of behaviour, and for the functional coordination of perception and behaviour that characterizes infant anion. This perspective challenges Piaget’s view that development necessitates a radical reconstruction of action-based knowledge. Conceptualized computationally, perceptual-behavioural action can be seen to involve representation in a nontrivial sense. Restructuring of action mechanisms can account for some central phenomena of infant development.",Julie C. Rutkowska,10.1080/02103702.1992.10822322,https://doi-org.crai.referencistas.com/10.1080/02103702.1992.10822322,Journal for the Study of Education and Development,57,23–48,A computational alternative to the Piagetian infant,https://doi-org.crai.referencistas.com/10.1080/02103702.1992.10822322,15,1992f,
article,doi:10.1177/14782103231178069,"While a small number of school districts across the United States are well into the process of implementing system-wide computer science education (CSed), most districts are only just getting started. But what does it look like to “get started” on CSed for a whole district? This manuscript presents a single case study of a district’s process of initiating their CS instructional initiative, highlighting a distinct set of instructional leadership practices and the institutional conditions they were responding to. Early implementation research around CSed shows that in some districts, leadership practices are less often the focus of early activities. This study sheds light on what such leadership practices can look like in the early stages of a district’s CSed initiative. Our analysis, based on qualitative data collected longitudinally over 18 months of the district’s work, identified eight intertwined leadership practices that aimed to support instructional coherence, and in our findings, we share a narrative of the district’s initiation of its CS initiative around them. The case begins with the (1) initial leadership team formation and details how that team engaged in (2) content-specific instructional capacity building for its members and (3) sensemaking of ideas around CS with their relationship to existing district activities. It moves on to the team’s (4) development of an instructional vision and an (5) associated implementation strategy, which fed into processes of (6) sensegiving to foster buy-in among teachers, and providing encouragement to engage in (7) instructional piloting. Finally, leaders engaged in (8) landscape analysis activities in order to understand existing district resources and teacher perceptions related to CS. Throughout the case, we highlight the motivations behind these practices, what resources they drew on, intersections, and dependencies among them. We close our analysis exploring a number of tensions and unintended consequences associated with these leadership activities.",Rafi Santo and Leigh Ann DeLyser and June Ahn,10.1177/14782103231178069,https://doi-org.crai.referencistas.com/10.1177/14782103231178069,Policy Futures in Education,0,14782103231178068,Booting the system: Leadership practices for initiating and infrastructuring district-wide computer science instructional programs,https://doi-org.crai.referencistas.com/10.1177/14782103231178069,0,2023g,
article,doi:10.1177/07356331211053383,"Scratch, a kind of visual programming software, has been widely used in instruction for primary school children. Scratch constructs a digital world for children to design, develop, and create coursework in which their creative thinking is fostered. Different instructional methods have been designed and implemented to stimulate children’s creative thinking skills through their coursework. This study investigated whether scaffolding construction with mind mapping promoted children’s creative thinking in a Scratch course. Two groups of 84 fifth-grade pupils participated in the study. The experimental group of 44 students adopted the scaffolding construction with mind mapping in the Scratch course, while the control group of 40 students did not use the mind mapping method. The Torrance Tests of Creative Thinking-Figural (TTCT-F) and Torrance Creative Personality Self-Report Scale were used three times over the 16-week learning period. The results show that learning in the Scratch course promoted the children’s creative thinking. The difference between the two groups indicates that mind mapping was beneficial to improve the children’s creative thinking.",Yu-Sheng Su and Mingming Shao and Li Zhao,10.1177/07356331211053383,https://doi-org.crai.referencistas.com/10.1177/07356331211053383,Journal of Educational Computing Research,4,906–929,Effect of Mind Mapping on Creative Thinking of Children in Scratch Visual Programming Education,https://doi-org.crai.referencistas.com/10.1177/07356331211053383,60,2022h,
article,doi:10.1177/21582440231179710,"This study investigated the effect of educational board games and the creative thinking spiral teaching strategy (CTSTS) on the learning outcomes of beginner-level Chinese language learners. Two dimensions were measured: learning outcome and writing ability. A total of 82 learners from one university in Taiwan participated in this study. Participants were non-randomly selected using convenience sampling. The participants were divided into the control group (40 participants) and experimental group (42 participants). In the control group, the teacher used the board game “Conveyance GO” as a teaching tool; in the experimental group, both Conveyance GO and CTSTS were used to teach the Chinese language. The results indicate no significant difference in learning outcomes between the groups. However, the experimental group exhibited a significantly larger improvement in writing abilities than did the control group, especially in terms of cohesion, coherence, and grammatical accuracy.",Ju-May Wen and Hai-Dung Do and Eric Zhi-Feng Liu and Chun-Hung Lin and Shihping Kevin Huang,10.1177/21582440231179710,https://doi-org.crai.referencistas.com/10.1177/21582440231179710,Sage Open,3,21582440231179710,Strengthening Writing Ability Among Students Learning Chinese as a Second Language Through Creative Thinking Spiral Teaching Strategy,https://doi-org.crai.referencistas.com/10.1177/21582440231179710,13,2023i,
article,doi:10.1177/07356331231174929,"Coding is increasingly popular in schools around the world and is often taught by non-specialist teachers as an integrated task with other subject areas. In this article, we explore the relationship between computer science (CS) concepts and students’ multimodal expression in a coding animated narrative (CAN) task in the context of an integrated English-Technology unit of learning. Through this collective case study, we explore how CS concepts underpin semiotic elements of an animated narrative, analyse the factors that influence the extent to which students exercise those concepts, and reveal the tensions and opportunities that a CAN task may present for learning computer science concepts in regular, non-specialist, cross-curricular classrooms. The findings suggest that CAN tasks are unique in presenting opportunities for students to learn challenging CS concepts such as synchronisation and parallelism. At the same time, CAN tasks present tensions for teaching CS concepts in non-specialist classrooms, where student projects are often judged on their visual qualities. In such settings, procedural, rather than conceptual knowledge, may be a more efficient route to creative outcomes. It also means that drawing skills need to be prioritised. Role specialisation often led to better quality projects but at the expense of individual students’ conceptual development in computer science.",Karen Woo and Garry Falloon,10.1177/07356331231174929,https://doi-org.crai.referencistas.com/10.1177/07356331231174929,Journal of Educational Computing Research,7,1335–1358,The Search for Computer Science Concepts in Coding Animated Narratives: Tensions and Opportunities,https://doi-org.crai.referencistas.com/10.1177/07356331231174929,61,2023j,
article,doi:10.1177/01614681221103929,,Sylvia Celedón-Pattichis and Carlos A. LópezLeiva and Marios S. Pattichis and Marta Civil,10.1177/01614681221103929,https://doi-org.crai.referencistas.com/10.1177/01614681221103929,Teachers College Record,5,3–12,Teaching and Learning Mathematics and Computing in Multilingual Contexts,https://doi-org.crai.referencistas.com/10.1177/01614681221103929,124,2022a,
article,doi:10.1177/21582440241260612,"Since the first phase of the lockdown in Malaysia, the cinema has been the place which best exemplifies the implementation of the control order in the venue-based sectors. After almost 2 years of physical distancing and lifestyle changes, the authority attempted to bring a new form of “normal life” to its residents. Such a decision witnessed more economic sectors were permitted to reopen, cinema among them. This study employed a mixed-method approach which aims to identify the emerging factors which inform about Malaysian audiences’ perception of cinema-going in the context of the COVID-19 pandemic. It examines the audiences with the help of the Theory of Planned Behavior (TPB) as this theory claims that people are more likely to act in a certain way if they feel certain behaviors will lead to specific results that are in keeping with their values. This study identified the attitude toward cinema reopening and readiness toward visiting cinema are able to significantly predict all the related factors of cinemagoers’ willingness in the post COVID-19 era. The results informed on the concerns of their family members, friends, and those with whom they have regular physical contact have become the agent of decision-making in terms of cinema-going.",Wang Changsong and Low Jinghong and Aleena Tan Poh Ling and Muhammad Afiq Bin Sukiman and Lucyann Kerry,10.1177/21582440241260612,https://doi-org.crai.referencistas.com/10.1177/21582440241260612,Sage Open,2,21582440241260612,An Understanding of Malaysian Cinemagoers in the Post COVID-19 Era by Using a Computational Ontology,https://doi-org.crai.referencistas.com/10.1177/21582440241260612,14,2024b,
article,doi:10.3102/00346543231216958,"Computer programming provides a framework for interdisciplinary learning in sciences, arts and languages. However, increasing integration of programming in K–12 shows that the block-based and text-based dichotomy of programming environments does not reflect the spectrum of their affordance. Hence, educators are confronted with a fundamental hurdle of matching programming environments with learners’ cognitive abilities and learning objectives. This study addresses this challenge by analyzing 111 articles evaluating the affordances of programming environments to identify both structural and theoretical models to support educators’ choice of programming environments. The following dimensions of programming environments were identified: connectivity mode, interface natural language, language inheritance, age appropriateness, cost of environment, output interface, input interface, and project types. For each of these dimensions, the synthesis of the literature ranged from examining its nature and effect on learning programming to the implications of choosing an environment and the critical gaps that future studies should address. The findings offer instructors useful parameters to compare and assess programming environments’ suitability and alignment with learning objectives.",Ndudi Okechukwu Ezeamuzie and Mercy Noyenim Ezeamuzie,10.3102/00346543231216958,https://doi-org.crai.referencistas.com/10.3102/00346543231216958,Review of Educational Research,0,00346543231216958,Multidimensional Framing of Environments Beyond Blocks and Texts in K–12 Programming,https://doi-org.crai.referencistas.com/10.3102/00346543231216958,0,2024c,
article,doi:10.1177/0741932519843998,"The purpose of this literature review was to synthesize recent research (2009–2018) for teaching science to students with intellectual disability and intellectual disability/autism. Authors identified a total of 15 studies; of these, 12 were determined to be methodologically sound studies using the Council for Exceptional Children quality indicators. Based on the methodologically sound studies, authors analyzed the evidence base of the instructional practices to teach science content and science practices to students with intellectual disability and intellectual disability/autism. Unlike previous literature reviews in which the focus has been on teaching science content, authors contribute to the literature on teaching science to this population by determining the evidence for teaching the science practices (e.g., asking questions, communicating findings). Resulting analysis was used to offer research-based recommendations for providing quality science instruction to students with intellectual disability and intellectual disability/autism. We conclude with limitations and possibilities for future research.",Victoria F. Knight and Leah Wood and Bethany R. McKissick and Emily M. Kuntz,10.1177/0741932519843998,https://doi-org.crai.referencistas.com/10.1177/0741932519843998,Remedial and Special Education,6,327–340,Teaching Science Content and Practices to Students With Intellectual Disability and Autism,https://doi-org.crai.referencistas.com/10.1177/0741932519843998,41,2020d,
article,doi:10.1260/1478-0771.12.1.1,"The use of computational processes in architecture is a widespread practice which draws on a set of theories of computer science developed in the 60s and 70s. With the advent of computers, many of these methodologies were developed in research centres in the USA and the UK. Focussing on this period, this paper investigates the importance of the German Hochschule fur Gestaltung, Ulm (HfG) design school in the early stages of computation in design and architecture. Even though there were no computers in the school, it may be argued that its innovative pedagogy and distinguished faculty members launched analogical computational design methods that can be seen as the basis for further computational approaches in architecture. The paper draws on archive material, as well as at an original interview with Tomas Maldonado, to propose that the remarkable work pursued by Tomas Maldonado (the educational project), Max Bense (information aesthetics) and Horst Rittel (scientific methods) was fundamental in establishing HfG Ulm as the forerunner of computation in architecture.",Isabel Clara Neves and João Rocha and José Pinto Duarte,10.1260/1478-0771.12.1.1,https://doi-org.crai.referencistas.com/10.1260/1478-0771.12.1.1,International Journal of Architectural Computing,1,1–25,"Computational Design Research in Architecture: The Legacy of the Hochschule für Gestaltung, Ulm",https://doi-org.crai.referencistas.com/10.1260/1478-0771.12.1.1,12,2014e,
article,doi:10.1177/109804821702100210,"Advertising technology is advancing quickly incorporating digital techniques that may be beyond the experience of the individual faculty member. Collaborative teaching, where faculty members from different disciplines co-teach a course, may be a solution. This report assesses the learning outcomes of an advertising technology course taught by faculty from one university’s advertising, computer science and human-computer interaction programs. The course was run twice, with a third one in progress. Students were predominantly advertising majors, with a minority of computer science and design majors. Two semesters of pre- and post-tests were analyzed, finding increases in student comfort with preparing and presenting technologically advanced solutions to advertising challenges.",Jay Newell and Wallapak Tavanapong and Sherry Berghefer,10.1177/109804821702100210,https://doi-org.crai.referencistas.com/10.1177/109804821702100210,Journal of Advertising Education,2,45–53,"Teaching Ad Tech: Assessing Collaborative Teaching in an Advertising, Computer Science and Design Course",https://doi-org.crai.referencistas.com/10.1177/109804821702100210,21,2017f,
article,doi:10.1177/00491241221122616,"This paper considers the adoption of computational techniques within research designs modeled after the extended case method. Echoing calls to augment the power of contemporary researchers through the adoption of computational text analysis methods, we offer a framework for thinking about how such techniques can be integrated into quasi-ethnographic workflows to address broad, structural sociological claims. We focus, in particular, on how this adoption of novel forms of evidence impacts corpus design and interpretation (which we tie to matters of casing), theoretical elaboration (which we associate to moving empirical claims across scales and empirical domains), and verification (which we see as a process of reflexive scaffolding of theoretical claims). We provide an example of the use of this framework through a study of the marketization of social scientific knowledge in the United Kingdom.",Juan Pablo Pardo-Guerra and Prithviraj Pahwa,10.1177/00491241221122616,https://doi-org.crai.referencistas.com/10.1177/00491241221122616,Sociological Methods & Research,4,1826–1867,The Extended Computational Case Method: A Framework for Research Design,https://doi-org.crai.referencistas.com/10.1177/00491241221122616,51,2022g,
article,doi:10.1177/21582440221097916,"For 2 weeks in the summer of 2018, K-12 science, technology, engineering, and mathematics (STEM) teachers (n = 40) attended a professional development (PD) that included four sessions focused on computer science modeling with follow-up academic year sessions; however, overall, the teachers did not incorporate or utilize modeling means or how as the instructors intended. The purpose of the study is to examine why this occurred, and the authors looked at the teachers’ modeling discourse. Using two theories to connect to practice (terministic screens, and schema theory), the authors collected data via the surveys, interviews, and email reflections. The authors analyzed the results via coding to explore participants’ concept of models and the potential difficulties of implementing computer modeling in their classrooms. Findings show that the term model was interpreted differently by the PD’s faculty team and participants. Further, the authors found that the majority of presenters held differing theories of models than the participants. Participant concepts of models did improve slightly after the PD, but lingering model concepts caused confusion with the anticipated PD results. Conclusions include five general modeling concepts which are presented and explained. Implications are provided showcasing articulated keys for delivering PD that assists in eliminating discursive and theoretical issues. Included are considerations for STEM teacher educators, PD providers, and K-12 teachers. The main study limitations include mixed K-12 teaching participants, distance between participants, a self-selected population, and non-generalizable findings based on qualitative work. Future directions are outlined.",Todd Reynolds and Andrea C. Burrows and Mike Borowczak,10.1177/21582440221097916,https://doi-org.crai.referencistas.com/10.1177/21582440221097916,Sage Open,2,21582440221097916,Confusion Over Models: Exploring Discourse in a STEM Professional Development,https://doi-org.crai.referencistas.com/10.1177/21582440221097916,12,2022h,
article,doi:10.1177/07356331211053383,"Scratch, a kind of visual programming software, has been widely used in instruction for primary school children. Scratch constructs a digital world for children to design, develop, and create coursework in which their creative thinking is fostered. Different instructional methods have been designed and implemented to stimulate children’s creative thinking skills through their coursework. This study investigated whether scaffolding construction with mind mapping promoted children’s creative thinking in a Scratch course. Two groups of 84 fifth-grade pupils participated in the study. The experimental group of 44 students adopted the scaffolding construction with mind mapping in the Scratch course, while the control group of 40 students did not use the mind mapping method. The Torrance Tests of Creative Thinking-Figural (TTCT-F) and Torrance Creative Personality Self-Report Scale were used three times over the 16-week learning period. The results show that learning in the Scratch course promoted the children’s creative thinking. The difference between the two groups indicates that mind mapping was beneficial to improve the children’s creative thinking.",Yu-Sheng Su and Mingming Shao and Li Zhao,10.1177/07356331211053383,https://doi-org.crai.referencistas.com/10.1177/07356331211053383,Journal of Educational Computing Research,4,906–929,Effect of Mind Mapping on Creative Thinking of Children in Scratch Visual Programming Education,https://doi-org.crai.referencistas.com/10.1177/07356331211053383,60,2022i,
article,doi:10.1177/0735633121997360,"Although the current landscape in education emphasizes the importance of developing students’ information literacy in formal education settings, little attention has been paid to information literacy within the context of social media use. This study investigated the relationship between information literacy and social media competence (SMC) among 1843 university students. This was done in order to increase knowledge of the components that may be important for preparing university students to be information literate citizens in social media environments. Students’ information literacy and SMC were measured by the Student Information Literacy Test and the SMC-CS scale respectively. Correlation and regression analyses were utilized to explore the relationship between university students’ information literacy and their SMC. The results showed that university students’ ability to utilize information technology to solve problems, and their sense of responsible behavior in cyberspace, are the most critical factors in predicting students’ SMC. Based on the findings, theoretical and practical implications are discussed in terms of enhancing university students’ information literacy and SMC.",Sha Zhu and Harrison Hao Yang and Di Wu and Feixiong Chen,10.1177/0735633121997360,https://doi-org.crai.referencistas.com/10.1177/0735633121997360,Journal of Educational Computing Research,7,1425–1449,Investigating the Relationship Between Information Literacy and Social Media Competence Among University Students,https://doi-org.crai.referencistas.com/10.1177/0735633121997360,59,2021j,
article,doi:10.2304/elea.2013.10.3.324,,Daniel Araya,10.2304/elea.2013.10.3.324,https://doi-org.crai.referencistas.com/10.2304/elea.2013.10.3.324,E-Learning and Digital Media,3,324–327,Thinking Forward: Conrad Wolfram on the Computational Knowledge Economy,https://doi-org.crai.referencistas.com/10.2304/elea.2013.10.3.324,10,2013a,
article,doi:10.1177/1555412008317312,"This article provides an overview of computer software and instructional strategies intended to engage young people in making computer games, to achieve a variety of educational goals. It briefly describes the most popular of such programs and compares their key features, including the kinds of games that can be created with the software, the types of communities and resources that are associated with each program, claims made for learning outcomes resulting from use of the software, and the results of empirical research (if any) on the application and outcomes of the software in formal or informal educational settings. A key finding is that existing software and educational applications stress the goal of teaching users about computer programming and place little or no emphasis on teaching concepts related to game design. It concludes by discussing the potential value of explicit attention to “design thinking” as goal of game making in education.",Elisabeth R. Hayes and Ivan Alex Games,10.1177/1555412008317312,https://doi-org.crai.referencistas.com/10.1177/1555412008317312,Games and Culture,3–4,309–332,Making Computer Games and Design Thinking: A Review of Current Software and Strategies,https://doi-org.crai.referencistas.com/10.1177/1555412008317312,3,2008b,
article,doi:10.1177/07356331231170383,"Technology has become an integral part of teaching and learning, but there is still limited understanding of how it is utilized to support computing education in early childhood. To address this knowledge gap, this review investigated the current implementation of computing technologies in early childhood settings, the implementation of computing activities, the learning outcomes achieved by students, and the utilization of assessment strategies to evaluate student learning. Through a systematic review and synthesis of 31 empirical studies published between 2014 and 2020, this review identified: (1) Twenty-two computing technologies that feature three types of computing environments; (2) Eight types of learning activities to engage children in computing; (3) A variety of learning outcomes accomplished in cognitive and non-cognitive dimensions; (4) A wide range of assessment strategies to evaluate students’ outcomes in different dimensions. This review strengthened the evidence base for the benefits of teaching computing with technology to children, informed the design of age-appropriate computing technology and learning activities, and identified research gaps to inform future research. Implications were provided to inform the future design and delivery of computing instruction to early childhood learners.",Ruohan Liu and Feiya Luo and Maya Israel,10.1177/07356331231170383,https://doi-org.crai.referencistas.com/10.1177/07356331231170383,Journal of Educational Computing Research,6,1275–1311,Technology-Integrated Computing Education in Early Childhood: A Systematic Literature Review,https://doi-org.crai.referencistas.com/10.1177/07356331231170383,61,2023c,
article,doi:10.1177/0263276418818889,"As machines have become increasingly smart and have entangled human thinking with artificial intelligences, it seems no longer possible to distinguish among levels of decision-making that occur in the newly formed space between critical reasoning, logical inference and sheer calculation. Since the 1980s, computational systems of information processing have evolved to include not only deductive methods of decision, whereby results are already implicated in their premises, but have crucially shifted towards an adaptive practice of learning from data, an inductive method of retrieving information from the environment and establishing general premises. This shift in logical methods of decision-making does not simply concern technical apparatuses, but is a symptom of a transformation in logical thinking activated with and through machines. This article discusses the pioneering work of Katherine Hayles, whose study of the cybernetic and computational infrastructures of our culture particularly clarifies this epistemological transformation of thinking in relation to machines.",Luciana Parisi,10.1177/0263276418818889,https://doi-org.crai.referencistas.com/10.1177/0263276418818889,"Theory, Culture & Society",2,89–121,Critical Computation: Digital Automata and General Artificial Thinking,https://doi-org.crai.referencistas.com/10.1177/0263276418818889,36,2019d,
article,doi:10.2190/EC.51.1.e,"Learning styles are increasingly being integrated into computational-enhanced earning environments and a great deal of recent research work is taking place in this area. The purpose of this study was to examine the impact of the computational experiment approach, learning styles, epistemic beliefs, and engagement with the inquiry process on the learning performance of pre-service engineering students. The study used the Felder-Silverman learning style model (FSLSM), in order to provide information for the relation of FSLSM with the learning environment in order to examine whether the strength of learning styles has an effect on the students’ learning performance in mismatched courses. Our objective was: a) to investigate whether students with a strong preference for a specific learning style have more difficulties in learning, if their learning style is not supported in the learning environment; b) if the methodology of the computational experiment has an impact on students independently of their learning style; and c) if the epistemological beliefs are related to different learning styles. The learning environment was based on the methodology of the computational experiment and applications were developed using the Easy Java Simulator software, while the inquiry based teaching and learning process was adopted. The questionnaire responses were gathered from 79 pre-service engineering students in a higher education institute in Greece. Results indicate that students with no preferred learning style have a better learning performance in mismatched courses.",Sarantos Psycharis and Evanthia Botsari and George Chatzarakis,10.2190/EC.51.1.e,https://doi-org.crai.referencistas.com/10.2190/EC.51.1.e,Journal of Educational Computing Research,1,91–118,"Examining the Effects of Learning Styles, Epistemic Beliefs and the Computational Experiment Methodology on Learners’ Performance Using the Easy Java Simulator Tool in Stem Disciplines",https://doi-org.crai.referencistas.com/10.2190/EC.51.1.e,51,2014e,
article,doi:10.1177/01614681221104141,"Background/Context: Bi/multilingual students’ STEM learning is better supported when educators leverage their language and cultural practices as resources, but STEM subject divisions have been historically constructed based on oppressive, dominant values and exclude the ways of knowing of nondominant groups. Truly promoting equity requires expanding and transforming STEM disciplines. Purpose/Objective/Research Question/Focus of Study: This article contributes to efforts to illuminate emergent bi/multilingual students’ ways of knowing, languaging, and doing in STEM. We follow the development of syncretic literacies in relation to translanguaging practices, asking, How do knowledges and practices from different communities get combined and reorganized by students and teachers in service of new modeling practices? Setting and Participants: We focus on a seventh-grade science classroom, deliberately designed to support syncretic literacies and translanguaging practices, where computer science concepts were infused into the curriculum through modeling activities. The majority of the students in the bilingual program had arrived in the United States at most three years before enrolling, from the Caribbean and Central and South America. Research Design: We analyze one lesson that was part of a larger research–practice partnership focused on teaching computer science through leveraging translanguaging practices and syncretic literacies. The lesson was a modeling and computing activity codesigned by the teacher and two researchers about post–Hurricane María outmigration from Puerto Rico. Analysis used microethnographic methods to trace how students assembled translanguaging, social, and schooled practices to make sense of and construct models. Findings/Results: Findings show how students assembled representational forms from a variety of practices as part of accomplishing and negotiating both designed and emergent goals. These included sensemaking, constructing, explaining, justifying, and interpreting both the physical and computational models of migration. Conclusions/Recommendations: Implications support the development of theory and pedagogy that intentionally make space for students to engage in meaning-making through translanguaging and syncretic practices in order to provide new possibilities for lifting up STEM learning that may include, but is not constrained by, disciplinary learning. Additional implications for teacher education and student assessment practices call for reconceptualizing schooling beyond day-to-day curriculum as part of making an ontological shift away from prioritizing math, science, and CS disciplinary and language objectives as defined by and for schooling, and toward celebrating, supporting, and centering students’ diverse, syncretic knowledges and knowledge use.",Sarah C. Radke and Sara E. Vogel and Jasmine Y. Ma and Christopher Hoadley and Laura Ascenzi-Moreno,10.1177/01614681221104141,https://doi-org.crai.referencistas.com/10.1177/01614681221104141,Teachers College Record,5,206–228,Emergent Bilingual Middle Schoolers’ Syncretic Reasoning in Statistical Modeling,https://doi-org.crai.referencistas.com/10.1177/01614681221104141,124,2022f,
article,doi:10.3233/HSM-201118,"BACKGROUND: Today’s uncertain economic and social dynamics are leading companies to seek the sort of human talent that will help them to survive and thrive. Training demands are thus arising for specific skills and competencies that would make current students and employment seekers more employable. OBJECTIVE: The aim of this study was to identify the twenty-first century’s major employability skills and competencies as well as the main demand trends for skills and competencies. METHODS: An international panel of experts (from Spain, Thailand and Poland), from both, academic and professional business backgrounds, were asked to quantitatively project the importance of different generic and specific skills and competencies over the next five years. They were asked to do so twice, once before and once after a four-year interval (in 2016 and in 2019). Each time, they were interviewed to discuss the results. RESULTS: The most valued employability skills were of a generic nature, in all three countries. Regarding specific skills, those of a social and managerial nature were the most highly valued. Work experience and formal education became less relevant for employability. CONCLUSIONS: The study’s results can lead to recommendations on how to design a more employability-oriented curriculum in educational institutions.",Anna Rakowska and Susana de Juana-Espinosa and Aleš Trunk and David Dawson,10.3233/HSM-201118,https://doi-org.crai.referencistas.com/10.3233/HSM-201118,Human Systems Management,5,669–684,Ready for the future? Employability skills and competencies in the twenty-first century: The view of international experts,https://doi-org.crai.referencistas.com/10.3233/HSM-201118,40,2021g,
article,doi:10.1177/0306419019876866,"Computational fluid dynamics is taught in many universities and is a trending elective option among engineering students. Although analyzing computational fluid dynamics simulations is exciting enough, the theory is equation intensive, sometimes very abstract and also difficult to visualize for the novice. A creative thinking based approach termed synectics, which involves analogies, was therefore applied in classroom teaching to increase student comfort with the equations. For this purpose six analogies encompassing basic computational fluid dynamics concepts were developed along with pictorial representations, and are presented in this work. These analogies were integrated into classroom teaching via synectics procedures. Student feedback was positive and reflected higher engagement with the course compared to when the metaphoric activity was not implemented. This work attempts to demonstrate the feasibility and value of applying creative techniques, even when teaching a highly structured and equation oriented course such as computational fluid dynamics.",PC Sande and S Sharma,10.1177/0306419019876866,https://doi-org.crai.referencistas.com/10.1177/0306419019876866,International Journal of Mechanical Engineering Education,2,171–191,Synectics model applied in basic theory of computational fluid dynamics,https://doi-org.crai.referencistas.com/10.1177/0306419019876866,49,2021h,
article,doi:10.1177/0040059915597689,,Kristin Sayeski,10.1177/0040059915597689,https://doi-org.crai.referencistas.com/10.1177/0040059915597689,TEACHING Exceptional Children,1,7–8,"New Year, Expanded Opportunities",https://doi-org.crai.referencistas.com/10.1177/0040059915597689,48,2015i,
article,doi:10.1177/1932202X241230589,"An issue arising in emergency distance education procedures, such as the response to the COVID-19 pandemic, is a lack of appropriate high-quality content and course activities for high ability students suitable for distance education. In this study, online CAD-based learning experiences structured with the Tinkercad Circuits Platform designed for gifted students were investigated based on the opinions of students regarding the distance education activity and the evaluations of the students’ scientific writing skills. This study used a single case holistic design with 10 gifted 6th-grade students at Usak Science and Art Center in Türkiye. All of the students stated that they had not previously encountered an activity such as the “smart air conditioning system”. The students also stated that although the activity was carried out in the form of distance education, it was positive and fun to be application-based, and that it was fun to research, discuss, design, and code with Tinkercad to look for a solution to the given problem. The evaluation of students’ products showed participants’ high level of proficiency in activities requiring advanced problem-solving skills, including planning the solution to the problem, creating an alternative plan for the solution, realizing, and evaluating the design.",Cengiz Tüysüz and Nurettin Can Bodur and Ilker Ugulu,10.1177/1932202X241230589,https://doi-org.crai.referencistas.com/10.1177/1932202X241230589,Journal of Advanced Academics,2,329–356,Tinkercad Circuits Platform-Based Learning Experiences of Gifted Students in the Emergency Distance Education Process,https://doi-org.crai.referencistas.com/10.1177/1932202X241230589,35,2024j,
article,doi:10.1177/14648849241279579,"This article sheds light on the emerging forms of cultural capital that media practitioners need to acquire to work with automated news, as in Bourdieu’s understanding of unique abilities that include, among others, journalistic expertise and technical know-how. To uncover these new skills, we carried out 30 interviews with editorial staff, executives and technologists working at 23 media organisations based in Europe, North America and Australia. We show that these new forms of cultural capital are essentially two-fold: on the one hand, they involve taking a “structured journalism” approach so as to think of what an ideal story may look like, and then by breaking it down into smaller predictable elements that can be reusable across many versions of that same story; on the other hand, they also call for knowing how to embed a media organisation’s standards and practices into code for automated news. Overall this study argues that a new type of cultural capital emerges, as it is associated with the production of automated news. We call it the distinct-abstract capital, whereby journalism is thought of both as a one-off endeavour and as a process that can be deconstructed in an abstract way close to computer programming.",Samuel Danzon-Chambaud and Alessio Cornia,10.1177/14648849241279579,https://doi-org.crai.referencistas.com/10.1177/14648849241279579,Journalism,0,14648849241279580,"The cultural capital you need to work with automated news: Not only “your beautiful piece of work”, but also “patterns that emerge”",https://doi-org.crai.referencistas.com/10.1177/14648849241279579,0,2024a,
article,doi:10.1177/10944281241261913,"Computational modeling holds significant promise as a tool for improving how theory is developed, expressed, and used to inform empirical research and evaluation efforts. However, the knowledge and skillsets needed to build computational models are rarely developed in the training received by social and organizational scientists. The purpose of this manuscript is to provide an accessible introduction to and reference for building computational models to represent theory. We first discuss important principles and recommendations for “thinking about” theory and developing explanatory accounts in ways that facilitate translating their core assumptions, specifications, and ideas into a computational model. Next, we address some frequently asked questions related to building computational models that introduce several fundamental tasks/concepts involved in building models to represent theory and demonstrate how they can be implemented in the R programming language to produce executable model code. The accompanying supplemental materials describes additional considerations relevant to building and using computational models, provides multiple examples of complete computational model code written in R, and an interactive application offering guided practice on key model-building tasks/concepts in R.",James A. Grand and Michael T. Braun and Goran Kuljanin,10.1177/10944281241261913,https://doi-org.crai.referencistas.com/10.1177/10944281241261913,Organizational Research Methods,0,10944281241261912,Hello World! Building Computational Models to Represent Social and Organizational Theory,https://doi-org.crai.referencistas.com/10.1177/10944281241261913,0,2024b,
article,doi:10.1177/07356331221087773,"Fostering students’ computer programming skills has become an important educational issue in the globe. However, it remains a challenge for students to understand those abstract concepts when learning computer programming, implying the need to provide instant learning diagnosis and feedback in computer programming activities. In this study, a Two-Tier Test-Based Programming Training (T3PT) approach was proposed. Accordingly, an online learning system was developed to provide students with precision feedback for guiding them to identify misconceptions of computer programming to improve their computer programming learning achievement. In order to examine the effects of the proposed approach, a learning system was developed and a quasi-experiment was conducted. Two classes of 99 eighth-grade students from Taiwan were divided into an experimental group and a control group. The students in the experimental group used the learning system based on the T3PT approach, while the control group used the conventional learning system. The experimental results showed that the proposed approach was significantly superior to the conventional programming learning approach in terms of students’ programming logic concepts, problem-solving awareness, technology acceptance, and satisfaction with the learning approach. Accordingly, discussion and suggestions are provided for future research.",Gwo-Jen Hwang and Li-Hsien Tung and Jian-Wen Fang,10.1177/07356331221087773,https://doi-org.crai.referencistas.com/10.1177/07356331221087773,Journal of Educational Computing Research,8,1895–1917,Promoting Students’ Programming Logic and Problem-Solving Awareness With Precision Feedback: A Two-Tier Test-Based Online Programming Training Approach,https://doi-org.crai.referencistas.com/10.1177/07356331221087773,60,2023c,
article,doi:10.1177/18344909211038105,"This special issue raises two thematic questions: (1) How will AI change learning in the future and what role will human beings play in the interaction with machine learning, and (2), What can we learn from the articles in this special issue for future research? These questions are reflected in the frame of the recent discussion of human and machine learning. AI for learning provides many applications and multimodal channels for supporting people in cognitive and non-cognitive task domains. The articles in this special issue evidence that agency, engagement, self-efficacy, and collaboration are needed in learning and working with intelligent tools and environments. The importance of social elements is also clear in the articles. The articles also point out that the teacher’s role in digital pedagogy primarily involves facilitating and coaching. AI in learning has a high potential, but it also has many limitations. Many worries are linked with ethical issues, such as biases in algorithms, privacy, transparency, and data ownership. This special issue also highlights the concepts of explainability and explicability in the context of human learning. We need much more research and research-based discussion for making AI more trustworthy for users in learning environments and to prevent misconceptions.",Hannele Niemi,10.1177/18344909211038105,https://doi-org.crai.referencistas.com/10.1177/18344909211038105,Journal of Pacific Rim Psychology, ,18344909211038104,AI in learning: Preparing grounds for future learning,https://doi-org.crai.referencistas.com/10.1177/18344909211038105,15,2021d,
article,doi:10.1177/07419325231206483,"Whole number computations are a critical skill that serves as a foundation upon which higher-order concepts in mathematics are taught to children. To facilitate their instruction, educators often use multiple representations to support a child’s cognition. Representations with physical manipulatives are widely studied through a graduated instructional sequence featuring concrete, representational, and abstract stages of learning. In contrast, research on representational sequences featuring virtual manipulatives is less robust. Thus, this study evaluated an instructional strategy with virtual manipulatives, static representational drawings, and abstract algorithms to teach multiplication to three U.S. elementary students with mathematics difficulty. A functional relation was established via a single-subject multiple probe design between the treatment and students’ accuracy performance. Baseline-corrected Tau estimates confirmed a medium effect size for all three students, while student performance on measures assessing the number of errors committed and the duration of sessions also returned favorable findings.",Rajiv Satsangi and Stephanie D. Sigmon,10.1177/07419325231206483,https://doi-org.crai.referencistas.com/10.1177/07419325231206483,Remedial and Special Education,4,216–229,Teaching Multiplicative Thinking With Virtual Representations to Children With Mathematics Difficulty,https://doi-org.crai.referencistas.com/10.1177/07419325231206483,45,2024e,
article,doi:10.5964/ps.6115,"Computational methods have increased the objectivity of measures of human behavior and positioned personality science to benefit from the ongoing digital revolution. In this review, we define and discuss computational personality assessment (CPA), a measurement process that uses computational technologies to obtain estimates of personality. We briefly review some of the most promising sources of data currently used for CPA: mobile sensing, digital footprints from social media, images, language, and experience sampling. We present a concise overview of key findings, discuss the promise and opportunities of CPA (e.g., moving towards objective measures of personality, obtaining new insights from big data), and highlight important limitations and challenges in the development and application of CPA (e.g., establishing reliability and validity, selecting appropriate ground truth criterion, assessing affect and cognition, implications for ethics and privacy). We conclude with our perspective on how CPA could change our understanding of individual differences.",Clemens Stachl and Ryan L. Boyd and Kai T. Horstmann and Poruz Khambatta and Sandra C. Matz and Gabriella M. Harari,10.5964/ps.6115,https://doi-org.crai.referencistas.com/10.5964/ps.6115,Personality Science,1,e6115,Computational Personality Assessment,https://doi-org.crai.referencistas.com/10.5964/ps.6115,2,2021f,
article,doi:10.1177/07356331231183450,"This article presents the design, construct validation, and reliability of a self-report instrument in Spanish that aims to characterize different types of strategies that students can use to learn computer programming. We provide a comprehensive overview of the identification of learning strategies in the existing literature, the design and development of preliminary questionnaire items, the refinement of item wording, and the examination of the internal structure and reliability of the final instrument. The construction of the items was based on the educational theory of Self-Regulated Learning. The final version of the questionnaire, called the Computer Programming Learning Strategies Questionnaire (CEAPC), was administered to 647 students enrolled in computer programming courses. The data collected from the participants were used to examine the construct validity and reliability of the questionnaire. The CEAPC consists of 13 subscales, each corresponding to a different type of learning strategy, and a total of 89 items. Statistical analyses of the data indicate that the CEAPC has adequate construct validity. In addition, the results of the internal consistency analysis indicate satisfactory reliability across the different subscales of the instrument. This study contributes to the field of educational research, particularly in the area of self-regulated learning in computer programming.",Stephanie Torres Jiménez and Jhon Jairo Ramírez-Echeverry and Felipe Restrepo-Calle,10.1177/07356331231183450,https://doi-org.crai.referencistas.com/10.1177/07356331231183450,Journal of Educational Computing Research,8,103–138,The Development and Validation of the Questionnaire to Characterize Learning Strategies in Computer Programming (CEAPC),https://doi-org.crai.referencistas.com/10.1177/07356331231183450,61,2024g,
article,doi:10.1177/07356331231206071,"In higher education, it is challenging to cultivate non-computer science majors’ programming concepts. This study used the GAME model (gamification, assessment, modeling, and enquiry) in a programming education course to enhance undergraduates’ self-efficacy and performance of basic programming concepts. There were 83 undergraduates taking part in this study, which adopted a quasi-experimental research design. Students in the experimental group (n = 43) experienced a course in which the GAME model was used to design the block-based programming course. The control group (n = 40) was given a general information education course covering similar learning concepts without the game-based learning strategy. The analysis of covariance (ANCOVA) was adopted to investigate the effect of the GAME model on students’ learning outcomes for the quantitative data. In the qualitative analysis, students’ responses to the course perception questionnaire were coded and analyzed. The results showed that students in the experimental group outperformed their counterparts regarding self-efficacy and basic programming concepts. The experimental treatment resulted in a small to medium effect size difference between the two groups. The results showed that incorporating the GAME model into block-based programming teaching helped improve undergraduates’ self-efficacy and performance of basic programming concepts. In addition, these experimental group undergraduates also perceived the pedagogic GAME model positively. Several research suggestions are proposed based on the findings of the present study.",Chun-Yen Tsai and Yun-An Chen and Fu-Pei Hsieh and Min-Hsiung Chuang and Chien-Liang Lin,10.1177/07356331231206071,https://doi-org.crai.referencistas.com/10.1177/07356331231206071,Journal of Educational Computing Research,3,702–724,Effects of a Programming Course Using the GAME Model on Undergraduates’ Self-Efficacy and Basic Programming Concepts,https://doi-org.crai.referencistas.com/10.1177/07356331231206071,62,2024h,
article,doi:10.1177/21582440241254595,"Uzbekistan has not adopted robotics education as the school curriculum yet. However, several robotics learning centers have introduced robotics education in an informal setting. This research paper aims to highlight the essence of robotics education in Uzbekistan investigating the perception of parents and children to their full potential and identifying impediments to the process of implementing robotics in Uzbekistan. This research study involves primary and secondary research methods. A systematic literature review was conducted to examine the reflection of robotics education among primary and secondary school children. Official statistical data was gathered to prove the scope of demographics. Primary data was collected through the survey among parents whose children attended robotics classes. Ultimately, the authors have used empirical evidence to provide recommendations and solutions on how to implement robotics education effectively in Uzbekistan. Much emphasis has not been put on robotics education in Uzbekistan, despite reforms in the field of STEM education. Moreover, the condition (including teachers, lesson materials, classrooms, computers, and robotics kits) to implement robotics classes as more developed countries are doing has not been created properly, which hampers the introduction of robotics at schools. In addition, the majority of parents are not fully aware of the authentic value of robotics education in children’s lives. Hence, Uzbek schools are lagging in the field of robotics.",Indira Abdullaeva Yuldashevna and Karan Khurana,10.1177/21582440241254595,https://doi-org.crai.referencistas.com/10.1177/21582440241254595,Sage Open,2,21582440241254596,The Impediments to the Process of Implementing Robotics in the School Education System in Uzbekistan,https://doi-org.crai.referencistas.com/10.1177/21582440241254595,14,2024i,
article,doi:10.1177/0267323117753751b,,,10.1177/0267323117753751b,https://doi-org.crai.referencistas.com/10.1177/0267323117753751b,European Journal of Communication,1,109–110,"David M Berry and Anders Fagerjord, Digital Humanities",https://doi-org.crai.referencistas.com/10.1177/0267323117753751b,33,2018j,
article,doi:10.1177/0263276418818884,"In our contemporary moment, when machine learning algorithms are reshaping many aspects of society, the work of N. Katherine Hayles stands as a powerful corpus for understanding what is at stake in a new regime of computation. A renowned literary theorist whose work bridges the humanities and sciences among her many works, Hayles has detailed ways to think about embodiment in an age of virtuality (How We Became Posthuman, 1999), how code as performative practice is located (My Mother Was a Computer, 2005), and the reciprocal relations among human bodies and technics (How We Think, 2012). This special issue follows the 2017 publication of her book Unthought: The Power of the Cognitive Nonconscious, in which Hayles traces the nonconscious cognition of biological life-forms and computational media. The articles in the special issue respond in different ways to Hayles’ oeuvre, mapping the specific contours of computational regimes and developing some of the ‘inflection points’ she advocates in the deep engagement with technical systems.",Louise Amoore,10.1177/0263276418818884,https://doi-org.crai.referencistas.com/10.1177/0263276418818884,"Theory, Culture & Society",2,3–16,Introduction: Thinking with Algorithms: Cognition and Computation in the Work of N. Katherine Hayles,https://doi-org.crai.referencistas.com/10.1177/0263276418818884,36,2019a,
article,doi:10.1177/14780771221121829,"In the fourth industrial revolution, programming promises to be a fundamental subject like mathematics, science, languages ​​or the arts. Architects design more than buildings developing innovative methods and they are among the pioneers in visual programming development. However, after more than 10 years of visual programming in architecture, despite the fast-learning curve, visual programming presents considerable limitations to solve complex problems. To overcome limitations, the authors propose to associate the advantages of visual and textual languages in Python. The article addresses an ongoing research study to implement Computational Methods in Architectural Education. The authors began by describing the general goal of this project, and of this article in particular. This article focuses on the implementation of two disciplines ‘Computation for Architecture in Python’ I and II. The first discipline uses programming based on the construction of functions in the imperative language, implemented in the text editor, in visual programming, using Grasshopper methods. The second discipline, which is under development, intends to teach object-oriented programming. The results of the first discipline are encouraging; despite reported difficulties in programming fundamentals, such as lists, loops and recursion. The development of the second discipline, in object-oriented programming, deals with the concepts of classes and objects, and more abstract principles such abstraction, inheritance, polymorphism or encapsulation. This paradigm allows building robust programs, but requires a more in-depth syntax. The article reports this ongoing research on this new paradigm of object-oriented language, expanding the application of a hybrid visual-textual language in Architecture.",Goncalo Castro Henriques and Pedro Maciel Xavier and Victor de Luca Silva and Luca Rédua Bispo and João Victor Fraga,10.1177/14780771221121829,https://doi-org.crai.referencistas.com/10.1177/14780771221121829,International Journal of Architectural Computing,3,673–687,"Computation for Architecture, hybrid visual and textual language: Research developments and considerations about the implementation of structural imperative and object-oriented paradigms",https://doi-org.crai.referencistas.com/10.1177/14780771221121829,20,2022b,
article,doi:10.3102/0013189X20923708,"With the release of the consensus report English Learners in STEM Subjects: Transforming Classrooms, Schools, and Lives, we highlight foundational constructs and perspectives associated with STEM subjects and language with English learners (ELs) that frame the report. The purpose here is to elevate these constructs and perspectives for discussion among the broader education research community. First, we provide an overview of the unique contributions of the report to move the ELs and STEM fields forward. Second, we describe ELs in terms of their heterogeneity and the inconsistency of educational policies that affect their learning opportunities in STEM subjects. Third, we describe contemporary views on STEM subjects and language with ELs that indicate that instructional shifts across STEM subjects and language are mutually supportive. Fourth, we describe promising instructional strategies to promote STEM learning and language development with ELs. Lastly, we close the article by reimagining STEM education with ELs and offer potential next steps. These foundational constructs and perspectives on STEM subjects and language with ELs are critical because they provide the conceptual grounding for the design of the education system for ELs. The report could contribute to building a knowledge base for ELs in STEM subjects and language as education research, policy, and practice converge to reimagine what is possible to both support and challenge ELs to learn academically rigorous content standards that are expected of all students.",Okhee Lee and Amy Stephens,10.3102/0013189X20923708,https://doi-org.crai.referencistas.com/10.3102/0013189X20923708,Educational Researcher,6,426–432,English Learners in STEM Subjects: Contemporary Views on STEM Subjects and Language With English Learners,https://doi-org.crai.referencistas.com/10.3102/0013189X20923708,49,2020c,
article,doi:10.1177/20427530211022964,"This article explores the use of modding as a formal tool for learning history. The article examines data from a formal analysis of Europa Universalis IV (EUIV), a survey of 331 EUIV forum participants and a case study of 18 university participants. Significant quantitative survey data indicated that 45% (149/331) of participants had modified EUIV, and of the 125 participants who responded with comments about modding, a significant number (86/125 responses or 68.8%) explained how they had learnt about history, geography or other subjects through the modding process. Closer analysis of survey and case study responses and mods reveals the variety of ways participants learnt and critiqued history through the modding process. The article discusses the data and the pedagogical affordance of modding in a few steps. First, the article briefly explores the evidence that indicates modding is popular within the EUIV gaming community. In this instance, it examines whether given the popularity of gaming practice, modding might also be seen as a new casual form of engagement with games. Second, the article reviews the modding process in EUIV and examines how both playing and creating mods may be beneficial for learning history. Modding is examined in terms of its pedagogical importance and the unique educational opportunities it may offer that are not otherwise accessible through other forms of game-based learning. Finally, the article explores how and what the case study participants learnt when they were tasked with creating and implementing playable mods to demonstrate their understanding of history. Overall, the article considers the growing importance of mods, how learners can create and represent history using mods and how mods can provide a platform for learners to develop their own critique and analysis of official history.",Rhett Loban,10.1177/20427530211022964,https://doi-org.crai.referencistas.com/10.1177/20427530211022964,E-Learning and Digital Media,6,530–556,Modding Europa Universalis IV: An informal gaming practice transposed into a formal learning setting,https://doi-org.crai.referencistas.com/10.1177/20427530211022964,18,2021d,
article,doi:10.3233/IA-2011-0017,"We describe recent work on the deployment of computational logic to support the formalisation and implementation of agents in multi-agent systems. Several forms of computational logic systems are needed in this setting, including abductive, argumentative and preference-based systems. We briefly sketch the agent model called KGP, and an ongoing extension of it which is needed to model agents in distributed settings such as the Grid and, more generally, Service-Oriented Architectures.",Paolo Mancarella and Francesca Toni,10.3233/IA-2011-0017,https://doi-org.crai.referencistas.com/10.3233/IA-2011-0017,Intelligenza Artificiale,1,139–143,Computational logic in agent based systems,https://doi-org.crai.referencistas.com/10.3233/IA-2011-0017,5,2011e,
article,doi:10.1177/0306419019876866,"Computational fluid dynamics is taught in many universities and is a trending elective option among engineering students. Although analyzing computational fluid dynamics simulations is exciting enough, the theory is equation intensive, sometimes very abstract and also difficult to visualize for the novice. A creative thinking based approach termed synectics, which involves analogies, was therefore applied in classroom teaching to increase student comfort with the equations. For this purpose six analogies encompassing basic computational fluid dynamics concepts were developed along with pictorial representations, and are presented in this work. These analogies were integrated into classroom teaching via synectics procedures. Student feedback was positive and reflected higher engagement with the course compared to when the metaphoric activity was not implemented. This work attempts to demonstrate the feasibility and value of applying creative techniques, even when teaching a highly structured and equation oriented course such as computational fluid dynamics.",PC Sande and S Sharma,10.1177/0306419019876866,https://doi-org.crai.referencistas.com/10.1177/0306419019876866,International Journal of Mechanical Engineering Education,2,171–191,Synectics model applied in basic theory of computational fluid dynamics,https://doi-org.crai.referencistas.com/10.1177/0306419019876866,49,2021f,
article,doi:10.1177/0735633117710860,,Robert H. Seidman,10.1177/0735633117710860,https://doi-org.crai.referencistas.com/10.1177/0735633117710860,Journal of Educational Computing Research,4,447–448,Tribute to Seymour Papert (1928–2016),https://doi-org.crai.referencistas.com/10.1177/0735633117710860,55,2017g,
article,doi:10.1177/10962506221145674,,Hsiu-Wen Yang and Philippa H. Campbell and Chih-Ing Lim,10.1177/10962506221145674,https://doi-org.crai.referencistas.com/10.1177/10962506221145674,Young Exceptional Children,4,220–232,Supporting STEM Learning Within Routines for Infants and Toddlers With Developmental Delays,https://doi-org.crai.referencistas.com/10.1177/10962506221145674,26,2023h,
article,doi:10.1177/0267323118799184d,,,10.1177/0267323118799184d,https://doi-org.crai.referencistas.com/10.1177/0267323118799184d,European Journal of Communication,5,578–579,"David E Berry and Anders Fagerjord, Digital Humanities",https://doi-org.crai.referencistas.com/10.1177/0267323118799184d,33,2018i,
article,doi:10.1177/2399808319885210,,,10.1177/2399808319885210,https://doi-org.crai.referencistas.com/10.1177/2399808319885210,Environment and Planning B: Urban Analytics and City Science,9,1603–1604,Winners of the Breheny Prize,https://doi-org.crai.referencistas.com/10.1177/2399808319885210,46,2019j,
article,doi:10.1177/0735633119845694,"This study aims to investigate problem-solving with dataset (PSWD) as a computational thinking learning implementation as reflected in academic publications. Specifically, the purpose is to specify the scope of PSWD, which overlaps with the data literacy, thinking with data, big data literacy, and data-based thinking concepts in the literature. Subaims of the study are to identify the conceptual structure of PSWD based on definitions in academic publications and to classify the reasons given in the literature to show the need for PSWD. For the purposes to investigate PSWD conceptually, to classify the reasons given for the need for PSWD, the obtained 54 publications were analyzed via content analysis. Moreover, this study investigates the most frequently suggested or used teaching strategies (in terms of instructional methods, instructional tools, and grade level) for PSWD in the literature. The frequencies of used words in selected publications referring instructional methods, instructional tools, and grade levels were shown in the findings of study. The importance of the study stems from its focus on a new approach to computational thinking instructional implementation.",Burcu Berikan and Selçuk Özdemir,10.1177/0735633119845694,https://doi-org.crai.referencistas.com/10.1177/0735633119845694,Journal of Educational Computing Research,2,502–534,Investigating “Problem-Solving With Datasets” as an Implementation of Computational Thinking: A Literature Review,https://doi-org.crai.referencistas.com/10.1177/0735633119845694,58,2020a,
article,doi:10.3102/0034654317710096,"Computational thinking (CT) uses concepts that are essential to computing and information science to solve problems, design and evaluate complex systems, and understand human reasoning and behavior. This way of thinking has important implications in computer sciences as well as in almost every other field. Therefore, we contend that CT should be taught in elementary schools and included in every university’s educational curriculum. Several studies that measure the impact of teaching programming, analytical thinking, and CT have been conducted. In this review, we analyze and discuss findings from these studies and highlight the importance of learning programming with a focus on the development of CT skills at a young age. We also describe the tools that are available to improve the teaching of CT and provide a state-of-the-art overview of how programming is being taught at schools and universities in Colombia and around the world.",Francisco Buitrago Flórez and Rubby Casallas and Marcela Hernández and Alejandro Reyes and Silvia Restrepo and Giovanna Danies,10.3102/0034654317710096,https://doi-org.crai.referencistas.com/10.3102/0034654317710096,Review of Educational Research,4,834–860,Changing a Generation’s Way of Thinking: Teaching Computational Thinking Through Programming,https://doi-org.crai.referencistas.com/10.3102/0034654317710096,87,2017b,
article,doi:10.1177/07356331211037757,"Computational thinking (CT) has attracted significant interest among many educators around the globe. Despite this growing interest, research on CT and programming education in elementary school remains at an initial stage. Many relevant studies have adopted only one type of method to assess students’ CT, which may lead to an incomplete view of student development on CT, while other studies employed small sample sizes, which may increase the chance of assuming a false premise to be true. Moreover, conventional programming courses typically have two limitations (e.g., limited student active learning and student low engagement). Given these gaps, this study investigates the effects of a theory-based (5E framework) flipped classroom model (FCM) on elementary school students’ understanding of CT concepts, computational problem-solving performance, and perceptions of flipped learning. To achieve this, a pretest-posttest quasi-experimental study was conducted in a rural elementary school, including 125 students in the experimental group and 122 students in the control group. The results showed that the 5E-based FCM significantly improved student understanding of CT concepts and computational problem-solving abilities. The results also revealed positive student perception toward the FCM. The benefits and challenges of the 5E-based FCM are discussed.",Xuemin Gao and Khe Foon Hew,10.1177/07356331211037757,https://doi-org.crai.referencistas.com/10.1177/07356331211037757,Journal of Educational Computing Research,2,512–543,Toward a 5E-Based Flipped Classroom Model for Teaching Computational Thinking in Elementary School: Effects on Student Computational Thinking and Problem-Solving Performance,https://doi-org.crai.referencistas.com/10.1177/07356331211037757,60,2022c,
article,doi:10.3102/0013189X12463051,"Jeannette Wing’s influential article on computational thinking 6 years ago argued for adding this new competency to every child’s analytical ability as a vital ingredient of science, technology, engineering, and mathematics (STEM) learning. What is computational thinking? Why did this article resonate with so many and serve as a rallying cry for educators, education researchers, and policy makers? How have they interpreted Wing’s definition, and what advances have been made since Wing’s article was published? This article frames the current state of discourse on computational thinking in K–12 education by examining mostly recently published academic literature that uses Wing’s article as a springboard, identifies gaps in research, and articulates priorities for future inquiries.",Shuchi Grover and Roy Pea,10.3102/0013189X12463051,https://doi-org.crai.referencistas.com/10.3102/0013189X12463051,Educational Researcher,1,38–43,Computational Thinking in K–12: A Review of the State of the Field,https://doi-org.crai.referencistas.com/10.3102/0013189X12463051,42,2013d,
article,doi:10.3102/0013189X211057904,"Over the past decade, initiatives around the world have introduced computing into K–12 education under the umbrella of computational thinking. While initial implementations focused on skills and knowledge for college and career readiness, more recent framings include situated computational thinking (identity, participation, creative expression) and critical computational thinking (political and ethical impacts of computing, justice). This expansion reflects a revaluation of what it means for learners to be computationally-literate in the 21st century. We review the current landscape of K–12 computing education, discuss interactions between different framings of computational thinking, and consider how an encompassing framework of computational literacies clarifies the importance of computing for broader K–12 educational priorities as well as key unresolved issues.",Yasmin B. Kafai and Chris Proctor,10.3102/0013189X211057904,https://doi-org.crai.referencistas.com/10.3102/0013189X211057904,Educational Researcher,2,146–151,A Revaluation of Computational Thinking in K–12 Education: Moving Toward Computational Literacies,https://doi-org.crai.referencistas.com/10.3102/0013189X211057904,51,2022e,
article,doi:10.1177/0735633120964402,"In this research, a scale was developed to determine the programming-oriented computational thinking skills of university students. The participants were 360 students studying in various departments at different universities in Turkey for computer programming. The scale consists of 33 items under conceptual knowledge, algorithmic thinking, and evaluation subscale. While there was no significant difference between the students’ conceptual knowledge and algorithmic thinking skills, the evaluation skills of male students differed significantly compared to females. Programming experience has a significant effect on conceptual knowledge, algorithmic thinking, and evaluation. The algorithmic thinking skills of the students who have low, middle, and high-level programming experience differed significantly. In terms of the development of conceptual knowledge and evaluation skills, it was observed that students should have at least one year of programming experience, but this experience will not make a significant difference if it is four years or more. It is thought that this scale, which is structured for different applications (e.g., web, game, robot) and learning environments (e.g., text, block) within the framework of its programming capabilities (conceptual, semantic, strategic knowledge), will contribute significantly to the evaluation of computational thinking as programming oriented.",Servet Kılıç and Seyfullah Gökoğlu and Mücahit Öztürk,10.1177/0735633120964402,https://doi-org.crai.referencistas.com/10.1177/0735633120964402,Journal of Educational Computing Research,2,257–286,A Valid and Reliable Scale for Developing Programming-Oriented Computational Thinking,https://doi-org.crai.referencistas.com/10.1177/0735633120964402,59,2021f,
article,doi:10.1177/18344909211010240,"Recent advances in artificial intelligence have brought attention to computational thinking (CT) in school education worldwide. However, little is known about the development of the literacy of CT in children, mainly because of the lack of proper psychometric assessments. We developed the first psychometrically validated assessment on the literacy of CT of children in Chinese elementary schools, coined as the Computational Thinking Assessment for Chinese Elementary Students (CTA-CES). Items were constructed to reflect key aspects of CT such as abstraction, algorithm thinking, decomposition, evaluation, and pattern recognition. To examine the test reliability and validity, we recruited two samples of 280 third- to sixth-grade students in total. Cronbach’s alpha provided evidence for the reliability of the test scores, item response theory analyses demonstrated psychometric appropriateness, whereas construct validity was verified by convergent validity, and criterion-related validity was confirmed by correlations between the CTA-CES and measures related to CT, namely reasoning, spatial ability, and verbal ability. In addition, an fMRI study further demonstrated similar neural activation patterns when students conducted the CTA-CES and programming tasks. Taken together, the CTA-CES is the first reliable and valid instrument for measuring the literacy of CT for Chinese children, and may be applicable to children worldwide.",Yan Li and Shan Xu and Jia Liu,10.1177/18344909211010240,https://doi-org.crai.referencistas.com/10.1177/18344909211010240,Journal of Pacific Rim Psychology, ,18344909211010240,Development and Validation of Computational Thinking Assessment of Chinese Elementary School Students,https://doi-org.crai.referencistas.com/10.1177/18344909211010240,15,2021g,
article,doi:10.1177/07356331231178948,"Computational thinking (CT) education has drawn increasing attention from educators and researchers. This study conducted a meta-analysis of 27 empirical studies to examine the effectiveness of game-based learning (GBL) for fostering students’ CT. The effects of various factors on the learning process for acquiring CT were also examined. The results showed that (a) conducting GBL can foster students’ CT, and the overall effect was at the upper-middle level (Hedges’ g = .600, 95% CI [.465, .735], p < .001). (b) Furthermore, conducting GBL can improve students’ CT concepts (Hedges’ g = .916, 95% CI [.410, 1.423], p < .001), CT skills (Hedges’ g = .494, 95% CI [.389, .600], p < .001), and CT perspectives (Hedges’ g = .927, 95% CI [.039, 1.816], p < .05). (c) Additionally, game mode, teaching context, and participant characteristics have positive effects on CT. Based on the findings, it is suggested that using more unplugged games and video games, designing collaborative game activities, and tailoring approaches according to gender difference and programming experience can effectively promote CT. The results have significance for fostering students’ CT in GBL; it is further suggested that instruction processes be rationally designed.",Jingsi Ma and Yi Zhang and Zhifang Zhu and Sunan Zhao and Qiyun Wang,10.1177/07356331231178948,https://doi-org.crai.referencistas.com/10.1177/07356331231178948,Journal of Educational Computing Research,7,1430–1463,Game-Based Learning for Students’ Computational Thinking: A Meta-Analysis,https://doi-org.crai.referencistas.com/10.1177/07356331231178948,61,2023h,
article,doi:10.1177/0735633121992479,"Recently educational robotics has expanded into curriculum beyond traditional STEM fields, and which can also be used to foster computational thinking (CT) skills. Prior research has shown numerous interdisciplinary benefits related to CT, however, these influential factors have often been investigated with relatively few variables. This study investigated factors that may lead to 4th and 5th grade elementary school students’ development of computational thinking skills in collaborative robotics activities by hypothesizing a model which proposed that a problem solving inventory, intrinsic motivation, and enjoyment were the main predictors of computational thinking skills. The model was then tested by surveying students with several psychometric inventories where a revised model was then constructed. The study found significant relationships between perceived competence and enjoyment, and learning motivation, and intrinsic motivation. Another important finding was that problem solving was a significant predictor of computational thinking skills. Results were interpreted with reference to implications for possible means of improving learning outcomes when using collaborative robotics in an educational setting.",William H. Stewart and Youngkyun Baek and Gina Kwid and Kellie Taylor,10.1177/0735633121992479,https://doi-org.crai.referencistas.com/10.1177/0735633121992479,Journal of Educational Computing Research,6,1208–1239,Exploring Factors That Influence Computational Thinking Skills in Elementary Students’ Collaborative Robotics,https://doi-org.crai.referencistas.com/10.1177/0735633121992479,59,2021i,
article,doi:10.1177/0735633117743918,"The Computer Science Teachers Association has asserted that computational thinking equips students with essential critical thinking which allows them to conceptualize, analyze, and solve more complex problems. These skills are applicable to all content area as students learn to use strategies, ideas, and technological practices more effectively as digital natives. This research examined over 200 elementary students’ pre- and posttest changes in computational thinking from a 10-week coding program using adapted lessons from code.org’s Blockly programming language and CSUnplugged that were delivered as part of the regular school day. Participants benefited from early access to computer science (CS) lessons with increases in computational thinking and applying coding concepts to the real world. Interviews from participants included examples of CS connections to everyday life and interdisciplinary studies at school. Thus, the study highlights the importance of leveraging CS access in diverse elementary classrooms to promote young students’ computational thinking; motivation in CS topics; and the learning of essential soft-skills such as collaboration, persistence, abstraction, and creativity to succeed in today’s digital world.",Yune Tran,10.1177/0735633117743918,https://doi-org.crai.referencistas.com/10.1177/0735633117743918,Journal of Educational Computing Research,1,3–31,Computational Thinking Equity in Elementary Classrooms: What Third-Grade Students Know and Can Do,https://doi-org.crai.referencistas.com/10.1177/0735633117743918,57,2019j,
article,doi:10.3233/IA-2011-0012,"In this paper, we briefly describe recent research directions of the Artificial Intelligence group of the University of L’Aquila, Italy. Research activities concern Computational Logic and Artificial Intelligence. About Intelligent Logical Agents, in the last years the group has developed the logical agent-oriented language DALI. Work is under way also in other areas, namely, Non-Monotonic Reasoning and Natural Language Processing. We particularly emphasize recent and future work directions.",Stefania Costantini and Alessio Paolucci and Arianna Tocchio and Panagiota Tsintza,10.3233/IA-2011-0012,https://doi-org.crai.referencistas.com/10.3233/IA-2011-0012,Intelligenza Artificiale,1,107–111,"DALI, RASP, mnemosine: Computational Logic at work",https://doi-org.crai.referencistas.com/10.3233/IA-2011-0012,5,2011a,
article,doi:10.1177/1094342017747692,"A significant fraction of computational software for scientific research grows through accretion. In a common scenario, a small group develops a code for a specific purpose. Others find the software useful, so they add to it for their own use. The software grows to the point where its management becomes intractable and scientific results obtained from it become unreliable. This is in stark contrast with a small number of scientific codes that have undergone a design process, be it due to an upfront investment, or when haphazardly grown codes have reset and started again. At a minimum, these codes reduce the time to obtain research results for the communities they serve because individual researchers do not have to develop their own codes. They provide further benefits; the results they produce are more reproducible due to greater scrutiny, leading to better science. One of the more overlooked benefits, which is perhaps of greater significance, is that a well-designed code can expand to serve communities beyond the ones it was designed for. Thus, research communities with similar computational requirements can symbiotically improve computation-based research for each other. In this article, we present a case study of FLASH, a code that was designed and developed for simulating thermonuclear runaways such as novae and type Ia supernovae in astrophysics. Designed to be modular and extensible, users from several diverse research areas have added capabilities to it and adapted it for their own communities. Examples include cosmology, high-energy density physics, core-collapse supernovae, star formation, fluid–structure interactions, and chemical combustion. We give a summary of design features that facilitated the expansion and quantify the effort needed to expand into some of the above-mentioned fields. We also quantify the impact on different communities by mining the database of publications using FLASH, collected by its developers.",Anshu Dubey and Petros Tzeferacos and Don Q Lamb,10.1177/1094342017747692,https://doi-org.crai.referencistas.com/10.1177/1094342017747692,The International Journal of High Performance Computing Applications,2,322–331,The dividends of investing in computational software design: A case study,https://doi-org.crai.referencistas.com/10.1177/1094342017747692,33,2019b,
article,doi:10.1177/07356331241240460,"Pair Programming is considered an effective approach to programming education, but the synchronous collaboration of two programmers involves complex coordination, making this method difficult to be widely adopted in educational settings. Artificial Intelligence (AI) code-generation tools have outstanding capabilities in program generation and natural language understanding, creating conducive conditions for pairing with humans in programming. Now some more mature tools are gradually being implemented. This review summarizes the current status of educational applications and research on AI-assisted programming technology. Through thematic coding of literature, existing research focuses on five aspects: underlying technology and tool introduction, performance evaluation, the potential impacts and coping strategies, exploration of behavioral patterns in technological application, and ethical and safety issues. A systematic analysis of current literature provides the following insights for future academic research related to the practice of “human-machine pairing” in programming: (1) Affirming the value of AI code-generation tools while also clearly defining their technical limitations and ethical risks; (2) Developing adaptive teaching ecosystems and educational models, conducting comprehensive empirical research to explore the efficiency mechanisms of AI-human paired programming; (3) Further enriching the application of research methods by integrating speculative research with empirical research, combining traditional methods with emerging technologies.",Jiangyue Liu and Siran Li,10.1177/07356331241240460,https://doi-org.crai.referencistas.com/10.1177/07356331241240460,Journal of Educational Computing Research,5,1385–1415,Toward Artificial Intelligence-Human Paired Programming: A Review of the Educational Applications and Research on Artificial Intelligence Code-Generation Tools,https://doi-org.crai.referencistas.com/10.1177/07356331241240460,62,2024c,
article,doi:10.1177/20427530211022964,"This article explores the use of modding as a formal tool for learning history. The article examines data from a formal analysis of Europa Universalis IV (EUIV), a survey of 331 EUIV forum participants and a case study of 18 university participants. Significant quantitative survey data indicated that 45% (149/331) of participants had modified EUIV, and of the 125 participants who responded with comments about modding, a significant number (86/125 responses or 68.8%) explained how they had learnt about history, geography or other subjects through the modding process. Closer analysis of survey and case study responses and mods reveals the variety of ways participants learnt and critiqued history through the modding process. The article discusses the data and the pedagogical affordance of modding in a few steps. First, the article briefly explores the evidence that indicates modding is popular within the EUIV gaming community. In this instance, it examines whether given the popularity of gaming practice, modding might also be seen as a new casual form of engagement with games. Second, the article reviews the modding process in EUIV and examines how both playing and creating mods may be beneficial for learning history. Modding is examined in terms of its pedagogical importance and the unique educational opportunities it may offer that are not otherwise accessible through other forms of game-based learning. Finally, the article explores how and what the case study participants learnt when they were tasked with creating and implementing playable mods to demonstrate their understanding of history. Overall, the article considers the growing importance of mods, how learners can create and represent history using mods and how mods can provide a platform for learners to develop their own critique and analysis of official history.",Rhett Loban,10.1177/20427530211022964,https://doi-org.crai.referencistas.com/10.1177/20427530211022964,E-Learning and Digital Media,6,530–556,Modding Europa Universalis IV: An informal gaming practice transposed into a formal learning setting,https://doi-org.crai.referencistas.com/10.1177/20427530211022964,18,2021d,
article,doi:10.3233/IA-2011-0018,"Computational Logic plays a very relevant role in engineering complex systems. It can be used to specify systems at different levels of abstraction. The specifications are executable, thus providing a working prototype for free. Thanks to its well-founded semantics it can be used to reason about the correctness of the specifications, a fundamental aspect when safety critical applications are developed. Researchers working in the Logic Programming Group at DISI, a Genova University Department, have applied methods and tools of Computational Logic for modelling, prototyping, and verifying complex systems. These three research lines are largely overlapping: the complex systems we take into account are often multiagent systems, for which we propose modelling languages as well as prototyping environments and verification techniques. In this paper we describe activities that, in the last decade, we carried out along these research lines.",Viviana Mascardi and Giorgio Delzanno and Maurizio Martelli,10.3233/IA-2011-0018,https://doi-org.crai.referencistas.com/10.3233/IA-2011-0018,Intelligenza Artificiale,1,145–149,Some applications of Computational Logic to the development of intelligent systems and verification methods,https://doi-org.crai.referencistas.com/10.3233/IA-2011-0018,5,2011e,
article,doi:10.1177/0049124117729703,"This article proposes a three-step methodological framework called computational grounded theory, which combines expert human knowledge and hermeneutic skills with the processing power and pattern recognition of computers, producing a more methodologically rigorous but interpretive approach to content analysis. The first, pattern detection step, involves inductive computational exploration of text, using techniques such as unsupervised machine learning and word scores to help researchers to see novel patterns in their data. The second, pattern refinement step, returns to an interpretive engagement with the data through qualitative deep reading or further exploration of the data. The third, pattern confirmation step, assesses the inductively identified patterns using further computational and natural language processing techniques. The result is an efficient, rigorous, and fully reproducible computational grounded theory. This framework can be applied to any qualitative text as data, including transcribed speeches, interviews, open-ended survey data, or ethnographic field notes, and can address many potential research questions.",Laura K. Nelson,10.1177/0049124117729703,https://doi-org.crai.referencistas.com/10.1177/0049124117729703,Sociological Methods & Research,1,3–42,Computational Grounded Theory: A Methodological Framework,https://doi-org.crai.referencistas.com/10.1177/0049124117729703,49,2020f,
article,doi:10.2190/EC.51.1.e,"Learning styles are increasingly being integrated into computational-enhanced earning environments and a great deal of recent research work is taking place in this area. The purpose of this study was to examine the impact of the computational experiment approach, learning styles, epistemic beliefs, and engagement with the inquiry process on the learning performance of pre-service engineering students. The study used the Felder-Silverman learning style model (FSLSM), in order to provide information for the relation of FSLSM with the learning environment in order to examine whether the strength of learning styles has an effect on the students’ learning performance in mismatched courses. Our objective was: a) to investigate whether students with a strong preference for a specific learning style have more difficulties in learning, if their learning style is not supported in the learning environment; b) if the methodology of the computational experiment has an impact on students independently of their learning style; and c) if the epistemological beliefs are related to different learning styles. The learning environment was based on the methodology of the computational experiment and applications were developed using the Easy Java Simulator software, while the inquiry based teaching and learning process was adopted. The questionnaire responses were gathered from 79 pre-service engineering students in a higher education institute in Greece. Results indicate that students with no preferred learning style have a better learning performance in mismatched courses.",Sarantos Psycharis and Evanthia Botsari and George Chatzarakis,10.2190/EC.51.1.e,https://doi-org.crai.referencistas.com/10.2190/EC.51.1.e,Journal of Educational Computing Research,1,91–118,"Examining the Effects of Learning Styles, Epistemic Beliefs and the Computational Experiment Methodology on Learners’ Performance Using the Easy Java Simulator Tool in Stem Disciplines",https://doi-org.crai.referencistas.com/10.2190/EC.51.1.e,51,2014g,
article,doi:10.1177/0306419019876866,"Computational fluid dynamics is taught in many universities and is a trending elective option among engineering students. Although analyzing computational fluid dynamics simulations is exciting enough, the theory is equation intensive, sometimes very abstract and also difficult to visualize for the novice. A creative thinking based approach termed synectics, which involves analogies, was therefore applied in classroom teaching to increase student comfort with the equations. For this purpose six analogies encompassing basic computational fluid dynamics concepts were developed along with pictorial representations, and are presented in this work. These analogies were integrated into classroom teaching via synectics procedures. Student feedback was positive and reflected higher engagement with the course compared to when the metaphoric activity was not implemented. This work attempts to demonstrate the feasibility and value of applying creative techniques, even when teaching a highly structured and equation oriented course such as computational fluid dynamics.",PC Sande and S Sharma,10.1177/0306419019876866,https://doi-org.crai.referencistas.com/10.1177/0306419019876866,International Journal of Mechanical Engineering Education,2,171–191,Synectics model applied in basic theory of computational fluid dynamics,https://doi-org.crai.referencistas.com/10.1177/0306419019876866,49,2021h,
article,doi:10.1177/07356331221115661,"Creativity, one of the cornerstones of students’ 21st-century skills, is regarded as an important learning outcome of science, technology, engineering, arts, and mathematics (STEAM) education. Meanwhile, problem-based digital making (DM), which combines the child-friendly programming activities of DM with problem-solving elements, is an emerging instructional design to facilitate STEAM learning. This qualitative case study examines the implementation of a problem-based DM instructional program that used the block-based programming tool Scratch to cultivate the participants’ creativity. Fifty-four middle school students (aged 10–14 years) in Hong Kong participated in the program, which totaled 10 contact hours over five consecutive weeks. Through triangulating students’ DM artifacts, video recordings, field notes, and interviews, the researchers characterized the students’ creative expression, examined the role of problem-based DM in encouraging creative work, and investigated the use of Scratch for mediating student creativity. The results showed that problem-based DM activities fostered students’ creative expressions in the dimensions of novelty, utility, aesthetics, and authenticity. While Scratch mediated the way the students presented their solutions, it had limitations that hindered the students’ digital artifact construction. The findings provide theoretical insights for framing creativity and offer practical implications for the implementation of problem-based DM in K–12 contexts.",Xiaojing Weng and Oi-Lam Ng and Zhihao Cui and Suzannie Leung,10.1177/07356331221115661,https://doi-org.crai.referencistas.com/10.1177/07356331221115661,Journal of Educational Computing Research,2,304–328,"Creativity Development With Problem-Based Digital Making and Block-Based Programming for Science, Technology, Engineering, Arts, and Mathematics Learning in Middle School Contexts",https://doi-org.crai.referencistas.com/10.1177/07356331221115661,61,2023i,
article,doi:10.1177/2399808319885210,,,10.1177/2399808319885210,https://doi-org.crai.referencistas.com/10.1177/2399808319885210,Environment and Planning B: Urban Analytics and City Science,9,1603–1604,Winners of the Breheny Prize,https://doi-org.crai.referencistas.com/10.1177/2399808319885210,46,2019j,
article,doi:10.1177/20552076221111941,The prevalent availability of high-performance computing coupled with validated computerized simulation platforms as open-source packages have motivated progress in the development of realistic anthropomorphic computational models of the human anatomy. The main application of these advanced tools focused on imaging physics and computational internal/external radiation dosimetry research. This paper provides an updated review of state-of-the-art developments and recent advances in the design of sophisticated computational models of the human anatomy with a particular focus on their use in radiation dosimetry calculations. The consolidation of flexible and realistic computational models with biological data and accurate radiation transport modeling tools enables the capability to produce dosimetric data reflecting actual setup in clinical setting. These simulation methodologies and results are helpful resources for the medical physics and medical imaging communities and are expected to impact the fields of medical imaging and dosimetry calculations profoundly.,Azadeh Akhavanallaf and Hadi Fayad and Yazdan Salimi and Antar Aly and Hassan Kharita and Huda Al Naemi and Habib Zaidi,10.1177/20552076221111941,https://doi-org.crai.referencistas.com/10.1177/20552076221111941,DIGITAL HEALTH, ,20552076221111940,An update on computational anthropomorphic anatomical models,https://doi-org.crai.referencistas.com/10.1177/20552076221111941,8,2022a,PMID:35847523
article,doi:10.1177/20570473231185996,"In this dialogue, Phillip Howard introduces “computational propaganda” as an emerging communication tool in political communication and a perspective for investigating misinformation and disinformation. By articulating the concepts, patterns, and mechanisms of computational propaganda, Howard proposes a socio-technical framework for studying computational propaganda. He calls for mixed methods to undertake computational research alongside qualitative investigation, thus addressing the computational as well as the political. Howard emphasizes the battle against algorithm bias, manipulation, and misinformation, and he advocates building an International Panel on the Information Environment (IPIE), an international scientific collaboration, to respond to the challenges. In addition, Howard offers advice on further research in computational propaganda.",Philip Howard and Fen Lin and Viktor Tuzov,10.1177/20570473231185996,https://doi-org.crai.referencistas.com/10.1177/20570473231185996,Communication and the Public,2,47–53,"Computational propaganda: Concepts, methods, and challenges",https://doi-org.crai.referencistas.com/10.1177/20570473231185996,8,2023b,
article,doi:10.1177/20438206221075714,"This intervention advances glitches as epistemological vectors for apprehending and engaging the significance of digitally-mediated spatialities that appear nonperformative against normative scripts of urban computational paradigms. Drawing on two strands of contemporary thinking about glitches as systemic design features of digital systems and as generative fissures within them, we mobilize a queer orientation that stays with the generative tensions of urban spatialities that present as idiosyncratic and as interrupting. We mobilize this epistemological approach through illustrative U.S. based examples of seemingly abandoned shared e-bikes, performatively ‘ugly’ homes, and wilful property dilapidation wrought through the registers of desire and aesthetics. In so doing, we show how glitch empistemologies render visible how the technocapitalist manufacturing of normative spatial desires for particular kinds of urban sociospatialities and aesthetic visual signatures are both secured and interrupted on digitally-mediated and -mediatized terrains. Glitch epistemologies establish the significance of small-scale disorientations in digital urban mediations, engaging these nonperformativities and non-computes as unexceptional openings onto everyday possibilities for politics in computational cities.",Agnieszka Leszczynski and Sarah Elwood,10.1177/20438206221075714,https://doi-org.crai.referencistas.com/10.1177/20438206221075714,Dialogues in Human Geography,3,361–378,Glitch epistemologies for computational cities,https://doi-org.crai.referencistas.com/10.1177/20438206221075714,12,2022c,
article,doi:10.1177/1478077120949033,"This paper documents a computational approach to the design, fabrication, and assembly of customizable space structures built entirely out of flat-cut interlocking elements without the need of nodes, fasteners, cement, or glue. Following a Research by Design (RbD) methodology, we establish a framework comprising geometric and parametric modeling, structural analysis, and digital fabrication stages to examine the following research question: how might the modularity of a construction kit be combined with the plasticity of parametric descriptions to facilitate the design and fabrication of flat-cut space structures? We find that an adaptive joint design that resolves local deformations at the node and element levels can facilitate the construction of flat-cut space structures by making modular components responsive to local geometric, material, and mechanical demands. The research centers on the design and construction of an architecture-scale installation based on the Weaire-Phelan structure—an aperiodic space-filling geometric structure that approximates the geometry of foam—entirely out of flat-cut interlocking elements. Documenting the process in technical detail, as well as some limitations, the paper contributes to recent efforts to develop digital materials suitable for architectural applications. In addition, it contributes to extend the formal and architectural possibilities of flat-cut space structure design by facilitating “bottom-up” design explorations in concert with the structure’s tectonic resolution.",Jingyang Liu and Yi-Chin Lee and Daniel Cardoso Llach,10.1177/1478077120949033,https://doi-org.crai.referencistas.com/10.1177/1478077120949033,International Journal of Architectural Computing,1,37–49,Computational design and fabrication of highly customizable architectural space frames: Making a flat-cut Weaire-Phelan structure,https://doi-org.crai.referencistas.com/10.1177/1478077120949033,19,2021d,
article,doi:10.1260/1475-472X.12.2.199,"Idea generation in the design production process often occurs within brainstorming sessions. Linking ideas is the key mechanism in the process of producing design. Through linking ideas, a graph-like knowledge is achieved in representing the individual memories, with the nodes and arcs being the ideas and the links between ideas respectively. The design process is similar to doing a jigsaw. Using the jigsaw metaphor, a cognitive study is applied to the design tool DIM (Dynamic Idea Map) to explore computational jigsaw mechanisms. Thereafter, a computational framework called Design Jigsaw is developed to support students in assembling vast ideas effectively and reveals the construction of meaning in the graph-like knowledge structure of design thinking",Chia-Hui Nico Lo and Ih-Cheng Lai and Teng-Wen Chang,10.1260/1475-472X.12.2.199,https://doi-org.crai.referencistas.com/10.1260/1475-472X.12.2.199,International Journal of Architectural Computing,2,199–212,Design Jigsaw: Exploring a Computational Approach to Assembling Ideas in the           Design Production Process,https://doi-org.crai.referencistas.com/10.1260/1475-472X.12.2.199,12,2014e,
article,doi:10.1177/2053951716670190,"Mapping a public discourse with the tools of computational text analysis comes with many contingencies in the areas of corpus curation, data processing and analysis, and visualisation. However, the complexity of algorithmic assemblies and the beauty of resulting images give the impression of ‘objectivity’. Instead of concealing uncertainties and artefacts in order to tell a coherent and all-encompassing story, retaining the variety of alternative assemblies may actually strengthen the method. By utilising the mobility of digital devices, we could create mutable mobiles that allow access to our laboratories and enable challenging rearrangements and interpretations.",Daniel Marciniak,10.1177/2053951716670190,https://doi-org.crai.referencistas.com/10.1177/2053951716670190,Big Data & Society,2,2053951716670190,Computational text analysis: Thoughts on the contingencies of an evolving method,https://doi-org.crai.referencistas.com/10.1177/2053951716670190,3,2016f,
article,doi:10.1177/13675494231164874,"Algorithmic media have adopted and adapted divinatory practices and vernaculars of prediction, prophecy, probability, fortune-telling and forecasting – suggesting a possible link between artificial intelligence and pre-scientific modes of speculation. Statistical thinking and magical thinking, too, can be recognised as closely correlated epistemological systems for governing societies and ways of life. In fact, primitive astrological practices of looking up at the stars may represent one of the earliest statistical projects involving sophisticated calculations and data sets. Such pattern-making techniques could even be considered precursory to machine learning. As a point of departure for exploring these eclectic relationships between stars and data, magic and machines, I use a media archaeological methodology to question the historical roles of both astrological and computational divination in mediating methods of control, surveillance and knowledge production across transforming societal contexts. This methodology is especially relevant for examining historical narratives in the field of cultural studies as it makes apparent the hyper-connectedness between objects, cultural representation and sites of hegemonic contention. My findings reveal relationships between celestial pattern recognition and efforts to exert control over and manipulate the natural environment and its populations, the historical impact of meteorological and climatological practices for predicting and influencing future events with artificial intelligence, and links between statistics and algorithmic data biases. This article suggests a speculative genealogy of astrology and artificial intelligence, as well as a genealogy of the theological, scientific and machinic unconscious.",Leona Nikolić,10.1177/13675494231164874,https://doi-org.crai.referencistas.com/10.1177/13675494231164874,European Journal of Cultural Studies,2,131–146,ECS-Ecrea Early Career Scholar Prize winner - An astrological genealogy of artificial intelligence: From ‘pseudo-sciences’ of divination to sciences of prediction,https://doi-org.crai.referencistas.com/10.1177/13675494231164874,26,2023g,
article,doi:10.1177/1478077115625516,"Since the publication in 1948 of Norbert Wiener’s Cybernetics, this thought model has exerted a profound influence in contemporary knowledge. Such influence has been decisive for a paradigm shift in the profession of architecture and particularly for the rise of a computational perspective in architectural design. This article explores the link between the cybernetic paradigm and the conception of architectural objects as performative, responsive, intelligent, and sentient artifacts—the visions of buildings that have been central to the development of digital architecture since its early stages. This connection shows that the dominant visions of design problems associated with the development of a computational perspective in architecture have not been exclusively the result of the introduction of computer pragmatics in architectural design. On the contrary, following such scholars as Bruno Latour and Katherine Hayles, these developments must be considered as the result of a particular feedback process that includes technical aspects as well as the definition of design problems around an informational ontology and epistemology. The understanding of the intellectual foundations of digital architecture is crucial not only to promote a critical regard of its productions but to imagine scenarios for a viable cybernetic practice of computer-mediated architectural design.",Camilo Andrés Cifuentes Quin,10.1177/1478077115625516,https://doi-org.crai.referencistas.com/10.1177/1478077115625516,International Journal of Architectural Computing,1,16–29,The cybernetic imagination of computational architecture,https://doi-org.crai.referencistas.com/10.1177/1478077115625516,14,2016h,
article,doi:10.1179/0308018812Z.0000000006,"In this study I examine the use of visualization within everyday research practices in computational physics. In doing so, I attempt to move from the well documented representational issues elicited by the concept of the image, to more microscale issues of the habitual structuring of the everyday that emerge when a specific example of science in the making is analysed. To this end, I focus on one specific example, of tracing a computational error through a fluid dynamics simulation of the ‘lock exchange’ experiment. This simulation is one small part of the research that goes on within one of Europe’s largest computational physics research groups, the Applied Modelling and Computation Group at Imperial College in London, where I am involved in ongoing ethnographic fieldwork research. Visualization is shown to play a central role, not just in daily routines of investigation and problem solving, but in the process of habituation through which scientists cultivate the dispositions through which everyday life gains its texture and form. Far from being a detachable representation of a part of a world, simulation is shown to come into being as a process within a world structured by the repetitions and improvizations that characterize research practice.",Matt Spencer,10.1179/0308018812Z.0000000006,https://doi-org.crai.referencistas.com/10.1179/0308018812Z.0000000006,Interdisciplinary Science Reviews,1,86–100,Image and Practice: Visualization in Computational Fluid Dynamics Research,https://doi-org.crai.referencistas.com/10.1179/0308018812Z.0000000006,37,2012i,
article,doi:10.1177/107621750703000403,,,10.1177/107621750703000403,https://doi-org.crai.referencistas.com/10.1177/107621750703000403,Gifted Child Today,4,6–9,News Briefs,https://doi-org.crai.referencistas.com/10.1177/107621750703000403,30,2007j,
article,doi:10.3233/FI-2020-1872,"Computational Intelligence (CI) is a computer science discipline encompassing the theory, design, development and application of biologically and linguistically derived computational paradigms. Traditionally, the main elements of CI are Evolutionary Computation, Swarm Intelligence, Fuzzy Logic, and Neural Networks. CI aims at proposing new algorithms able to solve complex computational problems by taking inspiration from natural phenomena. In an intriguing turn of events, these nature-inspired methods have been widely adopted to investigate a plethora of problems related to nature itself. In this paper we present a variety of CI methods applied to three problems in life sciences, highlighting their effectiveness: we describe how protein folding can be faced by exploiting Genetic Programming, the inference of haplotypes can be tackled using Genetic Algorithms, and the estimation of biochemical kinetic parameters can be performed by means of Swarm Intelligence. We show that CI methods can generate very high quality solutions, providing a sound methodology to solve complex optimization problems in life sciences.",Daniela Besozzi and Luca Manzoni and Marco S. Nobile and Simone Spolaor and Mauro Castelli and Leonardo Vanneschi and Paolo Cazzaniga and Stefano Ruberto and Leonardo Rundo and Andrea Tangherloni et al.,10.3233/FI-2020-1872,https://doi-org.crai.referencistas.com/10.3233/FI-2020-1872,Fundamenta Informaticae,1–4,57–80,Computational Intelligence for Life Sciences,https://doi-org.crai.referencistas.com/10.3233/FI-2020-1872,171,2019a,
article,doi:10.1177/0735633120945935,"Block-based visual programming tools, such as Scratch, Alice, and MIT App Inventor, provide an intuitive and easy-to-use editing interface through which to promote programming learning for novice students of various ages. However, very little attention has been paid to investigating these tools’ overall effects on students’ academic achievement and the study features that may moderate the effects of block-based visual programming from a comprehensive perspective. Thus, the present study carried out a meta-analysis to systemically examine 29 empirical studies (extracting 34 effect sizes) using experimental or quasi-experiments involving the programming learning effects of employing block-based visual programming tools to date (until the end of 2019). The results showed a small to medium significant positive overall mean effect size (fixed-effect model g = 0.37; random-effects model g = 0.47) of the use of these block-based visual programming tools with respect to students’ academic achievement. Furthermore, the overall mean effect size was significantly affected by the educational stage, programming tool used, experimental treatment, and school location. Discussions and implications based on the findings are provided.",Yue Hu and Cheng-Huan Chen and Chien-Yuan Su,10.1177/0735633120945935,https://doi-org.crai.referencistas.com/10.1177/0735633120945935,Journal of Educational Computing Research,8,1467–1493,Exploring the Effectiveness and Moderators of Block-Based Visual Programming on Student Learning: A Meta-Analysis,https://doi-org.crai.referencistas.com/10.1177/0735633120945935,58,2021b,
article,doi:10.1177/2378023119849803,"Reproducibility is fundamental to science, and an important component of reproducibility is computational reproducibility: the ability of a researcher to recreate the results of a published study using the original author’s raw data and code. Although most people agree that computational reproducibility is important, it is still difficult to achieve in practice. In this article, the authors describe their approach to enabling computational reproducibility for the 12 articles in this special issue of Socius about the Fragile Families Challenge. The approach draws on two tools commonly used by professional software engineers but not widely used by academic researchers: software containers (e.g., Docker) and cloud computing (e.g., Amazon Web Services). These tools made it possible to standardize the computing environment around each submission, which will ease computational reproducibility both today and in the future. Drawing on their successes and struggles, the authors conclude with recommendations to researchers and journals.",David M. Liu and Matthew J. Salganik,10.1177/2378023119849803,https://doi-org.crai.referencistas.com/10.1177/2378023119849803,Socius, ,2378023119849803,Successes and Struggles with Computational Reproducibility: Lessons from the Fragile Families Challenge,https://doi-org.crai.referencistas.com/10.1177/2378023119849803,5,2019c,
article,doi:10.1179/030801803225010340,"Much debate has taken place on Joseph Needham’s question regarding ‘the failure of China and India to give rise to distinctively modern science while being ahead of Europe for fourteen previous centuries’. It is argued in this paper that while there is probably some truth in many of the sociocultural explanations that have been offered for the failure in India, they are in the final analysis not entirely convincing. The proposal in this paper is in two parts. The first is that the scientific revolution, which was part of a European miracle, was triggered in part by the advent of a variety of technologies from China and the new numeral system and other mathematical inventions from India - both via creative West Asian intermediaries. India had experienced a mathematical (more specifically algoristic or computational) revolution heralded by Ārya-bhata in the fifth century CE. The new computational power unleashed by this revolution combined with the classical Greek penchant for axiomatised modelmaking and a technology empowered experimental philosophy, in what appears to have been a very creative and uniquely European cultural fusion that led to the scientific (and later the industrial) revolution. The second part of the proposal is that there was an epistemological reason why the Indian mathematical revolution did not lead to a corresponding ‘distinctively modern’ scientific one. The Indic approach was basically not that of modelmakers but of ingenious algorisers, and showed a deep and studied distrust of axioms and physical models. This led to an attitude described here as ‘computational positivism’, which considers observation and computation as the only things that matter. In retrospect, that distrust appears not unjustified, especially in the light of twentieth century developments in quantum and classical mechanics and in logic; but it was historically expensive for India, as Europe achieved unreasonably and unexpectedly spectacular successes in science. To the Indians, it was Newton who was the extraordinary epistemological revolutionary, not Heisenberg or Gödel. In summary, Indian science could not move forward without the modelmaking and technology enabled experimental abilities that grew in the West, just as European modelmaking had earlier been unable to progress without the advent of powerful technologies and computational tools whose roots can be traced to China and India.",Roddam Narasimha,10.1179/030801803225010340,https://doi-org.crai.referencistas.com/10.1179/030801803225010340,Interdisciplinary Science Reviews,1,54–66,"The Indian half of Needham’s question: some thoughts on axioms, models, algorithms, and computational positivism",https://doi-org.crai.referencistas.com/10.1179/030801803225010340,28,2003d,
article,doi:10.1177/0002716215569446,"Methods for analyzing neural and computational social science data are usually used by different types of scientists and generally seen as distinct, but they strongly complement one another. Computational social science methodologies can strengthen and contextualize individual-level analysis, specifically our understanding of the brain. Neuroscience can help to unpack the mechanisms that lead from micro- through meso- to macro-level observations. Integrating levels of analysis is essential to unified progress in social research. We present two example areas that illustrate this integration. First, combining egocentric social network data with neural variables from the “egos” provides insight about why and for whom certain types of antismoking messages may be more or less effective. Second, combining tools from natural language processing with neuroimaging reveals mechanisms involved in successful message propagation, and suggests links from microscopic to macroscopic scales.",Matthew Brook O’Donnell and Emily B. Falk,10.1177/0002716215569446,https://doi-org.crai.referencistas.com/10.1177/0002716215569446,The ANNALS of the American Academy of Political and Social Science,1,274–289,Big Data under the Microscope and Brains in Social Context: Integrating Methods from Computational Social Science and Neuroscience,https://doi-org.crai.referencistas.com/10.1177/0002716215569446,659,2015e,
article,doi:10.1177/1086296X231202722,"This study focused on the digital design practices of Raul, a 15-year-old participant at a summer video game design camp for adolescents. As Raul developed his original game, You Will Perish, I wondered what his design process might reveal about (a) the practice of affectively and procedurally literate video game design and (b) the literacy pedagogies that can support such design. Guided by the concept of serendipity, I describe Raul’s design practice as an open process characterized by bouts of failure, chance, and discovery, and I examine how such forces shaped the emergence of his game. Using transversal analysis, I trace Raul’s design through an account of frustration and failure, perseverance and pride, showing how the challenges of the game’s creator become those of the game’s players. The study highlights the generative potential of serendipitous literacies wherever and whenever literacy happens.",Bradley Robinson,10.1177/1086296X231202722,https://doi-org.crai.referencistas.com/10.1177/1086296X231202722,Journal of Literacy Research,3,275–301,You Will Perish: A Case Study of Serendipitous Literacies and Novice Video Game Design,https://doi-org.crai.referencistas.com/10.1177/1086296X231202722,55,2023f,
article,doi:10.1177/2167702614565359,"Psychiatric research is in crisis. We highlight efforts to overcome current challenges by focusing on the emerging field of computational psychiatry, which might enable the field to move from a symptom-based description of mental illness to descriptors based on objective computational multidimensional functional variables. We survey recent efforts toward this goal and describe a set of methods that together form a toolbox to aid this research program. We identify four levels in computational psychiatry: (a) behavioral tasks that index various psychological processes, (b) computational models that identify the generative psychological processes, (c) parameter-estimation methods concerned with quantitatively fitting these models to subject behavior by focusing on hierarchical Bayesian estimation as a rich framework with many desirable properties, and (d) machine-learning clustering methods that identify clinically significant conditions and subgroups of individuals. As a proof of principle, we apply these methods to two different data sets. Finally, we highlight challenges for future research.",Thomas V. Wiecki and Jeffrey Poland and Michael J. Frank,10.1177/2167702614565359,https://doi-org.crai.referencistas.com/10.1177/2167702614565359,Clinical Psychological Science,3,378–399,Model-Based Cognitive Neuroscience Approaches to Computational Psychiatry: Clustering and Classification,https://doi-org.crai.referencistas.com/10.1177/2167702614565359,3,2015g,
article,doi:10.1177/0002716215570576,"To deal with ever-larger datasets, media scholars are increasingly using computational analytic methods. This article focuses on how the traditional (manual) approach to conducting a content analysis—a primary method in the study of media messages—is being reconfigured, assesses what is gained and lost in turning to computational solutions, and builds on a “hybrid” approach to content analysis. We argue that computational methods are most fruitful when variables are readily identifiable in texts and when source material is easily parsed. Manual methods, though, are most appropriate for complex variables and when source material is not well digitized. These modes can be effectively combined throughout the process of content analysis to facilitate expansive and powerful analyses that are reliable and meaningful.",Rodrigo Zamith and Seth C. Lewis,10.1177/0002716215570576,https://doi-org.crai.referencistas.com/10.1177/0002716215570576,The ANNALS of the American Academy of Political and Social Science,1,307–318,Content Analysis and the Algorithmic Coder: What Computational Social Science Means for Traditional Modes of Media Analysis,https://doi-org.crai.referencistas.com/10.1177/0002716215570576,659,2015h,
article,doi:10.1177/15485129211073612,"Insurgency conflicts pose significant challenges to societies globally. The increase of insurgency conflicts creates a need to understand how insurgencies arise, and to identify societal drivers of insurgencies or effective strategies to counter them. In this paper, we analyze the contributions of computational modeling methods for the analysis of insurgent conflicts. We formalize a specific literature-based analysis framework using the identified key factors and drivers, which enables the evaluation of specific models in this domain. Through a systematic literature search, we identify 64 computational models to apply our framework. We highlight the development and contributions of various methodologies through an in-depth analysis of 13 high-quality models. The evaluation of these computational models revealed promising directions and future topics to design specific simulation models for all identified factors. In addition, our analysis revealed specific pitfalls concerning validity issues for each of the modeling methods.",Koen van der Zwet and Ana I Barros and Tom M van Engers and Peter M A Sloot,10.1177/15485129211073612,https://doi-org.crai.referencistas.com/10.1177/15485129211073612,The Journal of Defense Modeling and Simulation,3,333–350,Promises and pitfalls of computational modelling for insurgency conflicts,https://doi-org.crai.referencistas.com/10.1177/15485129211073612,20,2023i,
article,doi:10.2190/EC.49.4.g,,,10.2190/EC.49.4.g,https://doi-org.crai.referencistas.com/10.2190/EC.49.4.g,Journal of Educational Computing Research,4,543–545,"Journal of Educational Computing Research Index—Contents of Volume 49, 2013",https://doi-org.crai.referencistas.com/10.2190/EC.49.4.g,49,2013j,
article,doi:10.1177/1475725716673004,,Steve Charlton and Karen Ryder and Jacqui Taylor,10.1177/1475725716673004,https://doi-org.crai.referencistas.com/10.1177/1475725716673004,Psychology Learning & Teaching,3,211–213,Editorial,https://doi-org.crai.referencistas.com/10.1177/1475725716673004,15,2016a,
article,doi:10.1177/07356331231201342,"Artificial intelligence (AI) has emerged as a prominent topic in K-12 education recently. However, pedagogical design has remained a major challenge, especially among young learners. Guided by the Zone of Proximal Development theory and AI education research literature, this design-based study proposes an analogy-based pedagogical approach to support AI teaching and learning in upper primary education. This pedagogical approach is centered on human–AI comparison, where humans are gradually shifted from an analogue to a contrast to make visible the attributes, mechanisms, and processes of AI. To evaluate its effectiveness, a quasi-experimental study with mixed methods was conducted. The quantitative comparison shows that the participants in the experimental group learning with the analogy-based pedagogical approach significantly outperformed their peers with the conventional direct instructional approach in all three dimensions of AI knowledge, skills, and ethical awareness. Qualitative analyses further reveal its pedagogical benefits, including demystifying AI through relatable and engaging learning, supporting student comprehension and skill mastery, and nurturing critical thinking and attitudes. The analogy-based approach contributes to the field of K-12 AI education with an age-appropriate, child-friendly pedagogical approach. Notably, AI education should prioritize teaching for student understanding, and AI should be recognized as an independent subject with interdisciplinary applications.",Yun Dai and Ziyan Lin and Ang Liu and Dan Dai and Wenlan Wang,10.1177/07356331231201342,https://doi-org.crai.referencistas.com/10.1177/07356331231201342,Journal of Educational Computing Research,8,159–186,Effect of an Analogy-Based Approach of Artificial Intelligence Pedagogy in Upper Primary Schools,https://doi-org.crai.referencistas.com/10.1177/07356331231201342,61,2024b,
article,doi:10.1037/a0032947,"This article describes PSI theory, which is a formalized computational architecture of human psychological processes. In contrast to other existing theories, PSI theory not only models cognitive, but also motivational and emotional processes and their interactions. The article starts with a brief overview of the theory showing the connections between its different parts. We then discuss the theory’s components in greater detail. Key constructs and processes are the five basic human needs, the satisfaction of needs using the cognitive system, including perception, schemas in memory, planning, and action. Furthermore, emotions are defined and the role of emotions in cognitive and motivational processes is elaborated, referring to a specific example. The neural basis of the PSI theory is also highlighted referring to the “quad structure,” to specific brain areas, and to thinking as scanning in a neural network. Finally, some evidence for the validity of the theory is provided.",Dietrich Dörner and C. Dominik Güss,10.1037/a0032947,https://doi-org.crai.referencistas.com/10.1037/a0032947,Review of General Psychology,3,297–317,"PSI: A Computational Architecture of Cognition, Motivation, and Emotion",https://doi-org.crai.referencistas.com/10.1037/a0032947,17,2013c,
article,doi:10.1177/0036850419873799c,,Walid El-Sharoud,10.1177/0036850419873799c,https://doi-org.crai.referencistas.com/10.1177/0036850419873799c,Science Progress,3,279–279,"Book Review: Hector J. Levesque, Thinking as computation",https://doi-org.crai.referencistas.com/10.1177/0036850419873799c,102,2019d,
article,doi:10.1177/0954410016660873,"Mass capture ratio of a hypersonic air intake is one of the most important performance parameters. However, no a priori estimate of its value exists for use in initial design exercise of a hypersonic vehicle. In the present work, an air intake of a non-axisymmetric scramjet engine, designed using stream thrust methodology, is studied using computational fluid dynamic techniques. A large amount of air mass flow rate is observed to spill from the sides, which is not accounted for in the initial design phase. In absence of even an approximate estimate of this spillage, computational fluid dynamic studies become the only available tool to evaluate the mass capture ratio. Simulations are also carried out with a side wall at the intake to stop spillage. Although mass capture ratio and static pressure at combustor entry improve, deterioration in other flow parameters such as static temperature, Mach number and total pressure is observed.",Afroz Javed and Debasis Chakraborty,10.1177/0954410016660873,https://doi-org.crai.referencistas.com/10.1177/0954410016660873,"Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering",11,2111–2119,Evaluation of side spillage for a hypersonic air intake using computational fluid dynamic techniques,https://doi-org.crai.referencistas.com/10.1177/0954410016660873,231,2017e,
article,doi:10.1177/0306419019838880,"The University of Florida Department of Mechanical and Aerospace Engineering recently created a new senior technical elective in the field of computational fluid dynamics. The main objectives of the class are learning the process of computational fluid dynamics, skepticism, a course project that uses a popular commercial solver, and a course project that involves programming a simplified computational fluid dynamics code. The course covers introductory material, history, grid generation, numerics, equations of motion, boundary conditions, solvers, turbulence models, visualization, and a number of special topics. Skepticism is enforced throughout the course and forces students to justify the validity of their approach and question numerically generated results. Students in the class undertake a course project to predict a fundamental flow-field and compare predictions with excellent measurements from the open literature. They must also create a simplified computational fluid dynamics code to predict turbulent boundary layer flow. Students have integrated these lessons within student groups across the University of Florida. The emphasis of the course is on skepticism and increasing integration with the curriculum and student group activities. We present the class philosophy for teaching undergraduate computational fluid dynamics and the outcomes of the newly developed course.",Steven A E Miller,10.1177/0306419019838880,https://doi-org.crai.referencistas.com/10.1177/0306419019838880,International Journal of Mechanical Engineering Education,4,315–334,A contemporary course on the introduction to computational fluid dynamics,https://doi-org.crai.referencistas.com/10.1177/0306419019838880,48,2020f,
article,doi:10.1177/07356331241240047,"The use of a pedagogical approach mediated transfer with the bridging method has been successful in facilitating the transitions from block-based to text-based programming languages. Nevertheless, there is a lack of research addressing the impact of this transfer on programming misconceptions during the transition. The way programming concepts are taught to K-12 learners can later result in misconceptions for adult learners. The main objective was to examine the impact of mediated transfer using the bridging method pedagogical approach on the prevalence of programming misconceptions. We conducted a quasi-experimental study in school settings during informatics (computer science) classes among 163 sixth-grade students. The control group received traditional programming lectures using the text-based programming language, Python. Conversely, the experimental group utilized a mediated transfer pedagogical approach by starting with the block-based programming language MakeCode for micro:bit before transitioning to the text-based Python. Our findings indicate that the experimental group significantly reduced programming misconceptions in fundamental programming concepts: variables, sequencing, selection, and loops - compared to the control group. This suggests that the use of block-based programming language as an initial step in programming education, followed by a structured transition to text-based programming language, can effectively mitigate common misconceptions among K-12 learners.",Monika Mladenović and Žana Žanko and Goran Zaharija,10.1177/07356331241240047,https://doi-org.crai.referencistas.com/10.1177/07356331241240047,Journal of Educational Computing Research,5,1302–1326,From Blocks to Text: Bridging Programming Misconceptions,https://doi-org.crai.referencistas.com/10.1177/07356331241240047,62,2024g,
article,doi:10.1177/14780771221097685,"Computer-based design and fabrication systems in architecture contain modes of operation and preferences that often constrain tectonic possibilities in design and construction. These predispositions neglect architecture’s cultural and material dimensions, resulting in universalizing tectonics that erase nuances of place, culture, and expression in design. How may we celebrate local tectonic languages while also revisiting them through computer-based systems in architecture? The project examined here highlights novel possibilities for cultural expression and craftsmanship through computational design methods, retaining the expressive potential of a local craft while de-familiarizing its cultural context. I analyze how shape grammars and digital fabrication methods deployed in design, de-familiarizes the craft of wire-bending in costuming in the Trinidad Carnival. I present and apply new rules for the craft’s computational description based on material tests and an architectural application to expand discourses on critical regionalism. I adopt Tabbarah’s term “computational regionalism” to describe this process and elaborate it as a five-step sequence. Computational regionalism employs computational methods to translate local craft knowledge and tectonic languages into new interpretations and poetics of construction. Its process of creative de-familiarization raises critical questions about the local and the universal.",Vernelle AA Noel,10.1177/14780771221097685,https://doi-org.crai.referencistas.com/10.1177/14780771221097685,International Journal of Architectural Computing,2,277–296,Computational regionalism: De-familiarization of tectonics in the wire-bending craft,https://doi-org.crai.referencistas.com/10.1177/14780771221097685,20,2022h,
article,doi:10.1177/00375497221098417,"In this paper, we propose to use a computational method of chaos control to simulate complex experimental spectra. This computational chaos control technique is based on the Ott–Grebogi–York (OGY) method. We chose the logistic map as the base mathematical model for the development of our work. For the numeric part, we created arbitrary precision algorithms to generate the solutions. This way, we completely eliminated any degradation of chaos from our results. These algorithms were also necessary for the proper perturbation process that the computational chaos control method requires. We control the chaos of the logistic map in two cases of Period 1 and one case of Period 2 to demonstrate that our control method works. The behavior of a complex experimental spectrum was taken and numerically simulated. The simulated spectrum was obtained by controlling the chaos of the logistic map in a variable way with the methods proposed in this work. Our results show that it is possible to simulate very complicated experimental spectra by computationally controlling the chaos of an equation unrelated to the experimental system.",Jesús Manuel Rodríguez-Núñez and Aned de León and Martín E Molinar-Tabares and Mario Flores-Acosta and SJ Castillo,10.1177/00375497221098417,https://doi-org.crai.referencistas.com/10.1177/00375497221098417,SIMULATION,9,835–846,Computational chaos control based on small perturbations for complex spectra simulation,https://doi-org.crai.referencistas.com/10.1177/00375497221098417,98,2022i,
article,doi:10.3233/FI-2020-1888,"Computational Biology is a fast-growing field that is enriched by different data-driven methodological approaches and by findings and applications in a broad range of biological areas. Fundamental to these approaches are the mathematical and computational models used to describe the different states at microscopic (for example a biochemical reaction), mesoscopic (the signalling effects at tissue level), and macroscopic levels (physiological and pathological effects) of biological processes. In this paper we address the problem of combining two powerful classes of methodologies: Flux Balance Analysis (FBA) methods which are now producing a revolution in biotechnology and medicine, and Petri Nets (PNs) which allow system generalisation and are central to various mathematical treatments, for example Ordinary Differential Equation (ODE) specification of the biosystem under study. While the former is limited to modelling metabolic networks, i.e. does not account for intermittent dynamical signalling events, the latter is hampered by the need for a large amount of metabolic data. A first result presented in this paper is the identification of three types of cross-talks between PNs and FBA methods and their dependencies on available data. We exemplify our insights with the analysis of a pancreatic cancer model. We discuss how our reasoning framework provides a biologically and mathematically grounded decision making setting for the integration of regulatory, signalling, and metabolic networks and greatly increases model interpretability and reusability. We discuss how the parameters of PN and FBA models can be tuned and combined together so to highlight the computational effort needed to perform this task. We conclude with speculations and suggestions on this new promising research direction.",Pernice Simone and Follia Laura and Balbo Gianfranco and Milanesi Luciano and Sartini Giulia and Totis Niccoló and Lió Pietro and Merelli Ivan and Cordero Francesca and Beccuti Marco et al.,10.3233/FI-2020-1888,https://doi-org.crai.referencistas.com/10.3233/FI-2020-1888,Fundamenta Informaticae,1–4,367–392,Integrating Petri Nets and Flux Balance Methods in Computational Biology Models: a Methodological and Computational Practice,https://doi-org.crai.referencistas.com/10.3233/FI-2020-1888,171,2019j,
article,doi:10.1177/1094428121991230,"The substantial volume, continued growth, and resulting complexity of the scientific literature not only increases the need for systematic, replicable, and rigorous literature reviews, but also highlights the natural limits of human researchers’ information processing capabilities. In search of a solution to this dilemma, computational techniques are beginning to support human researchers in synthesizing large bodies of literature. However, actionable methodological guidance on how to design, conduct, and document such computationally augmented literature reviews is lacking to date. We respond by introducing and defining computational literature reviews (CLRs) as a new review method and put forward a six-step roadmap, covering the CLR process from identifying the review objectives to selecting algorithms and reporting findings. We make the CLR method accessible to novice and expert users alike by identifying critical design decisions and typical challenges for each step and provide practical guidelines for tailoring the CLR method to four conceptual review goals. As such, we present CLRs as a literature review method where the choice, design, and implementation of a CLR are guided by specific review objectives, methodological capabilities, and resource constraints of the human researcher.",David Antons and Christoph F. Breidbach and Amol M. Joshi and Torsten Oliver Salge,10.1177/1094428121991230,https://doi-org.crai.referencistas.com/10.1177/1094428121991230,Organizational Research Methods,1,107–138,"Computational Literature Reviews: Method, Algorithms, and Roadmap",https://doi-org.crai.referencistas.com/10.1177/1094428121991230,26,2023a,
article,doi:10.1177/09713557221097178,"The aim of this study was to investigate the correlational and causal relationship between middle school students’ entrepreneurial competencies and science, technology, engineering and mathematics (STEM) attitudes. A total of 648 middle school students (seventh and eighth grade) participated in this study. STEM attitude scale and two entrepreneurial competency scales that were developed in different studies in the literature were used as data collection tools. In addition, a simple regression, a multiple regression and a stepwise multiple regression analysis were executed to analyse the data. The correlational analysis showed that there was a moderate level, positive correlation between the STEM attitudes of students and their overall entrepreneurial competencies. Also, the multiple regression analysis showed that entrepreneurial competencies consisting of professionalism, risk-taking, creativity and tenacity explained 41% of the change in STEM attitude. The stepwise multiple regression analysis indicated that professionalism predicted the most the STEM attitude statistically more.",İsa Deveci and Fatma Zehra Konuş,10.1177/09713557221097178,https://doi-org.crai.referencistas.com/10.1177/09713557221097178,The Journal of Entrepreneurship,2,425–457,The Predictive Power of Turkish Middle School Students’ Entrepreneurial Competencies on STEM Attitudes,https://doi-org.crai.referencistas.com/10.1177/09713557221097178,31,2022b,
article,doi:10.1177/875697280703800102,"Building upon prior research on enterprise centralization and knowledge dynamics, this paper uses computational methods to assess the behavior and project performance of different organization-al designs in varying environments. The results reinforce contingency theory and suggest particular characteristics of different project environments that make one form relatively more or less appropriate than another. Practically, the answers to the research questions have direct and immediate application to project/portfolio managers and senior executives. Theoretically, broad classes of organizations are generalized and prescribe a novel set of organizational design guides.",John Dillard and Mark E. Nissen,10.1177/875697280703800102,https://doi-org.crai.referencistas.com/10.1177/875697280703800102,Project Management Journal,1,5–20,Computational Modeling of Project Organizations under Stress,https://doi-org.crai.referencistas.com/10.1177/875697280703800102,38,2007c,
article,doi:10.1177/0954410016660873,"Mass capture ratio of a hypersonic air intake is one of the most important performance parameters. However, no a priori estimate of its value exists for use in initial design exercise of a hypersonic vehicle. In the present work, an air intake of a non-axisymmetric scramjet engine, designed using stream thrust methodology, is studied using computational fluid dynamic techniques. A large amount of air mass flow rate is observed to spill from the sides, which is not accounted for in the initial design phase. In absence of even an approximate estimate of this spillage, computational fluid dynamic studies become the only available tool to evaluate the mass capture ratio. Simulations are also carried out with a side wall at the intake to stop spillage. Although mass capture ratio and static pressure at combustor entry improve, deterioration in other flow parameters such as static temperature, Mach number and total pressure is observed.",Afroz Javed and Debasis Chakraborty,10.1177/0954410016660873,https://doi-org.crai.referencistas.com/10.1177/0954410016660873,"Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering",11,2111–2119,Evaluation of side spillage for a hypersonic air intake using computational fluid dynamic techniques,https://doi-org.crai.referencistas.com/10.1177/0954410016660873,231,2017d,
article,doi:10.2310/JIM.0b013e318224d8cc,"Today, there is an ever-increasing amount of biological and clinical data available that could be used to enhance a systems-based understanding of disease progression through innovative computational analysis. In this article, we review a selection of published research regarding computational methods, primarily from systems biology, which support translational research from the molecular level to the bedside, with a focus on applications in trauma and critical care. Trauma is the leading cause of mortality in Americans younger than 45 years, and its rapid progression offers both opportunities and challenges for computational analysis of trends in molecular patterns associated with outcomes and therapeutic interventions. This review presents methods and domain-specific examples that may inspire the development of new algorithms and computational methods that use both molecular and clinical data for diagnosis, prognosis, and therapy in disease progression.",Mary F. McGuire and Madurai Sriram Iyengar and David W. Mercer,10.2310/JIM.0b013e318224d8cc,https://doi-org.crai.referencistas.com/10.2310/JIM.0b013e318224d8cc,Journal of Investigative Medicine,6,893–903,Computational Approaches for Translational Clinical Research in Disease Progression,https://doi-org.crai.referencistas.com/10.2310/JIM.0b013e318224d8cc,59,2011e,
article,doi:10.1177/14780771221097685,"Computer-based design and fabrication systems in architecture contain modes of operation and preferences that often constrain tectonic possibilities in design and construction. These predispositions neglect architecture’s cultural and material dimensions, resulting in universalizing tectonics that erase nuances of place, culture, and expression in design. How may we celebrate local tectonic languages while also revisiting them through computer-based systems in architecture? The project examined here highlights novel possibilities for cultural expression and craftsmanship through computational design methods, retaining the expressive potential of a local craft while de-familiarizing its cultural context. I analyze how shape grammars and digital fabrication methods deployed in design, de-familiarizes the craft of wire-bending in costuming in the Trinidad Carnival. I present and apply new rules for the craft’s computational description based on material tests and an architectural application to expand discourses on critical regionalism. I adopt Tabbarah’s term “computational regionalism” to describe this process and elaborate it as a five-step sequence. Computational regionalism employs computational methods to translate local craft knowledge and tectonic languages into new interpretations and poetics of construction. Its process of creative de-familiarization raises critical questions about the local and the universal.",Vernelle AA Noel,10.1177/14780771221097685,https://doi-org.crai.referencistas.com/10.1177/14780771221097685,International Journal of Architectural Computing,2,277–296,Computational regionalism: De-familiarization of tectonics in the wire-bending craft,https://doi-org.crai.referencistas.com/10.1177/14780771221097685,20,2022f,
article,doi:10.1177/1971400917740362,"Brain atlases have a wide range of use from education to research to clinical applications. Mathematical methods as well as computational methods and tools play a major role in the process of brain atlas building and developing atlas-based applications. Computational methods and tools cover three areas: dedicated editors for brain model creation, brain navigators supporting multiple platforms, and atlas-assisted specific applications. Mathematical methods in atlas building and developing atlas-aided applications deal with problems in image segmentation, geometric body modelling, physical modelling, atlas-to-scan registration, visualisation, interaction and virtual reality. Here I overview computational and mathematical methods in atlas building and developing atlas-assisted applications, and share my contribution to and experience in this field.",Wieslaw L Nowinski,10.1177/1971400917740362,https://doi-org.crai.referencistas.com/10.1177/1971400917740362,The Neuroradiology Journal,6,520–534,Computational and mathematical methods in brain atlasing,https://doi-org.crai.referencistas.com/10.1177/1971400917740362,30,2017g,PMID:29096578
article,doi:10.1177/20539517211047725,"The proliferation of digital data has been the impetus for the emergence of a new discipline for the study of social life: ‘computational social science’. Much research in this field is founded on the premise that society is a complex system with emergent structures that can be modeled or reconstructed through digital data. This paper suggests that computational social science serves practical and legitimizing functions for digital capitalism in much the same way that neoclassical economics does for neoliberalism. In recognition of this homology, this paper develops a critique of the complexity perspective of computational social science and argues for a heterodox computational social science founded on the meta-theory of critical realism that is critical, methodological pluralist, interpretative and explanative. This implies diverting computational social science’ computational methods and digital data so as to not be aimed at identifying invariant laws of social life, or optimizing state and corporate practices, but to instead be used as part of broader research strategies to identify contingent patterns, develop conjunctural explanations, and propose qualitatively different ways of organizing social life.",Petter Törnberg and Justus Uitermark,10.1177/20539517211047725,https://doi-org.crai.referencistas.com/10.1177/20539517211047725,Big Data & Society,2,20539517211047724,For a heterodox computational social science,https://doi-org.crai.referencistas.com/10.1177/20539517211047725,8,2021h,
article,doi:10.1177/0735633121992594,"Robotics education has gradually been emphasized in contemporary school curricula; however, assessment tools for robotics learning are still limited. Based on Bloom’s Taxonomy of educational objectives, this study aimed to develop the Robotics Learning Self-Efficacy Scale (RLSES) with a two-level construct of five dimensions for assessing students’ self-efficacy for learning robotics. A total of 181 elementary, junior high and senior high school students (5th–12th graders) with robotics learning experience were selected as the sample of this study. A questionnaire including 32 candidate items designed for the initial version of the RLSES was administered to the sample. An exploratory factor analysis was conducted and, finally, 16 items were drawn for the final RLSES under five subscales (Comprehension, Practice, Analysis, Application, and Collaboration), with a total explained variance of 85.28%. The Cronbach’s alpha reliability was .97 for the overall scale, ranging from .87 to .95 for the subscales. The inter-correlation analysis showed evidence of discriminant validity. Regression analysis results supported that Practice and Comprehension self-efficacy were significant predictors of Analysis, Application, and Collaboration self-efficacy, confirming the two-level (2 × 3) construct of the RLSES. Significant differences among school levels were found and are discussed.",Meng-Jung Tsai and Ching-Yeh Wang and An-Hsuan Wu and Chun-Ying Hsiao,10.1177/0735633121992594,https://doi-org.crai.referencistas.com/10.1177/0735633121992594,Journal of Educational Computing Research,6,1056–1074,The Development and Validation of the Robotics Learning Self-Efficacy Scale (RLSES),https://doi-org.crai.referencistas.com/10.1177/0735633121992594,59,2021i,
article,doi:10.1177/2096531120944929,"Purpose: This article aims to shed light on a latest education informatization policy blueprint in China, titled Education Informatization 2.0 Action Plan, which was promulgated by the Ministry of Education in China on April 18, 2018. Design/Approach/Methods: The study is an analytical policy review based on the policy documents, theoretical discussion, and development of practice. Findings: This new Chinese education informatization policy was driven by three factors: the promotion of education informatization 1.0 in China, the requirement of education modernization toward 2035, and the response to “Wisdom Education.” The framework for action can be summarized as “One Goal, Three Tasks, and Eight Actions.” The main features involve innovation-driven development rather than technology-driven development, committing to the expansion of digital educational resources rather than the digital presentation of textbooks, and aiming at improving teachers and students’ information literacy rather than the applied skills of information technology. The future vision of the plan involves building new models on talent cultivation, education service, and education governance. The new models on talent cultivation involve establishing “Wisdom Teaching” mode, learning mode, and intelligent learning environment supported by artificial intelligence technology. The new education service models entail building the admission and sharing mechanism of quality educational resources based on National Network for Education and the public service platform and system for educational resources by means of the cloud computing and artificial intelligence. The new education governance models involve achieving precise, flat, and humanized education governance. Originality/Value: This article entails expounding the motivation, framework for action, main features, and vision of the education informatization 2.0 in China, which will be helpful for learning and understanding the current background, stage, and future path of China’s education informatization.",Shouxuan Yan (闫守轩) and Yun Yang (杨运),10.1177/2096531120944929,https://doi-org.crai.referencistas.com/10.1177/2096531120944929,ECNU Review of Education,2,410–428,"Education Informatization 2.0 in China: Motivation, Framework, and Vision",https://doi-org.crai.referencistas.com/10.1177/2096531120944929,4,2021j,
article,doi:10.1177/20965311231206148,"Highlights We live in a technology-driven age, so the education field must rationally consider chatbots powered by artificial intelligence (AI). Faced with increasing application of AI in education, teachers should be reflective educators, and students should be self-educators. AI chatbots will evolve into a new prosthesis before being institutionalized into the fabric of school education. Reflective educators, institutionalized educators, self-educators foreshadow the future rise of hybrid educators.",Youchao Deng (邓友超),10.1177/20965311231206148,https://doi-org.crai.referencistas.com/10.1177/20965311231206148,ECNU Review of Education,3,677–680,The Rise of Hybrid Educators,https://doi-org.crai.referencistas.com/10.1177/20965311231206148,7,2024a,
article,doi:10.1177/0036850419850431,"Pregnancy can be accompanied by serious health risks to mother and child, such as pre-eclampsia, premature birth and postpartum haemorrhage. Understanding of the normal physiology of uterine function is essential to an improved management of such risks. Here we focus on the physiology of the smooth muscle fibres which make up the bulk of the uterine wall and which generate the forceful contractions that accompany parturition. We survey computational methods that integrate mathematical modelling with data analysis and thereby aid the discovery of new therapeutic targets that, according to clinical needs, can be manipulated to either stop contractions or cause the uterine wall muscle to become active.",Joseph R Dunford and E Josiah Lutton and Jolene Atia and Andrew M Blanks and Hugo A van den Berg,10.1177/0036850419850431,https://doi-org.crai.referencistas.com/10.1177/0036850419850431,Science Progress,2,103–126,Computational physiology of uterine smooth muscle,https://doi-org.crai.referencistas.com/10.1177/0036850419850431,102,2019b,PMID:31829844
article,doi:10.1177/13524585211059308,"Background: Multiple sclerosis (MS) is commonly associated with decision-making, neurocognitive impairments, and mood and motivational symptoms. However, their relationship may be obscured by traditional scoring methods. Objectives: To study the computational basis underlying decision-making impairments in MS and their interaction with neurocognitive and neuropsychiatric measures. Methods: Twenty-nine MS patients and 26 matched control subjects completed a computer version of the Iowa Gambling Task (IGT). Participants underwent neurocognitive evaluation using an expanded version of the Brief Repeatable Battery. Hierarchical Bayesian Analysis was used to estimate three established computational models to compare parameters between groups. Results: Patients showed increased learning rate and reduced loss-aversion during decision-making relative to control subjects. These alterations were associated with: (1) reduced net gains in the IGT; (2) processing speed, executive functioning and memory impairments; and (3) higher levels of depression and current apathy. Conclusion: Decision-making deficits in MS patients could be described by the interplay between latent computational processes, neurocognitive impairments, and mood/motivational symptoms.",Rodrigo S Fernández and Lucia Crivelli and María E Pedreira and Ricardo F Allegri and Jorge Correale,10.1177/13524585211059308,https://doi-org.crai.referencistas.com/10.1177/13524585211059308,Multiple Sclerosis Journal,8,1267–1276,Computational basis of decision-making impairment in multiple sclerosis,https://doi-org.crai.referencistas.com/10.1177/13524585211059308,28,2022c,PMID:34931933
article,doi:10.3233/AAC-170032,"Persuasion is an activity that involves one party trying to induce another party to believe something or to do something. It is an important and multifaceted human facility. Obviously, sales and marketing is heavily dependent on persuasion. But many other activities involve persuasion such as a doctor persuading a patient to drink less alcohol, a road safety expert persuading drivers to not text while driving, or an online safety expert persuading users of social media sites to not reveal too much personal information online. As computing becomes involved in every sphere of life, so too is persuasion a target for applying computer-based solutions. An automated persuasion system (APS) is a system that can engage in a dialogue with a user (the persuadee) in order to persuade the persuadee to do (or not do) some action or to believe (or not believe) something. To do this, an APS aims to use convincing arguments in order to persuade the persuadee. Computational persuasion is the study of formal models of dialogues involving arguments and counterarguments, of user models, and strategies, for APSs. A promising application area for computational persuasion is in behaviour change. Within healthcare organizations, government agencies, and non-governmental agencies, there is much interest in changing behaviour of particular groups of people away from actions that are harmful to themselves and/or to others around them.",Anthony Hunter,10.3233/AAC-170032,https://doi-org.crai.referencistas.com/10.3233/AAC-170032,Argument & Computation,1,15–40,Towards a framework for computational persuasion with applications in behaviour change,https://doi-org.crai.referencistas.com/10.3233/AAC-170032,9,2018d,
article,doi:10.1177/10464964241279164,"Small group researchers are increasingly called to engage the computational sciences. One challenge in answering this call is the lack of information concerning what the study of small groups looks like in these domains. This paper addresses this challenge through a prospecting review of research that computationally models or trains computers to learn small group and team behavior and is published in computing disciplines from 2016 to 2023. This review investigated how groups were modeled, for what purpose, what group elements were modeled, and whether social science informed the model design. Qualitative methods were used to analyze 119 published articles. Suggestions are presented for increasing the influence of small group research on the computational modeling of groups and teams, particularly for researchers with limited access to large research teams or resources. This review helps bridge the gap between small group research and computational sciences to advance the understanding of small groups and teams.",Michele H. Jackson,10.1177/10464964241279164,https://doi-org.crai.referencistas.com/10.1177/10464964241279164,Small Group Research,0,10464964241279164,Modeling of Small Groups in Computational Sciences: A Prospecting Review,https://doi-org.crai.referencistas.com/10.1177/10464964241279164,0,2024e,
article,doi:10.1177/0042098020986300,"This commentary advances the ‘hack’ as an urban concept. While the hack transcends existing literatures on the digital and informality, it is a distinctive concept and is being used systematically in new domains. I situate the hack conceptually, outline its empirical and methodological value and propose a framework to research the urban hack. Importantly, it is not just the technologies of hacking but the translation of computational logics to the urban that underpins the importance of the hack, as well as the critical need to set out a research agenda surrounding the hack within urban studies.",Sophia Maalsen,10.1177/0042098020986300,https://doi-org.crai.referencistas.com/10.1177/0042098020986300,Urban Studies,2,453–465,The hack: What it is and why it matters to urban studies,https://doi-org.crai.referencistas.com/10.1177/0042098020986300,59,2022f,
article,doi:10.1260/0266-3511.25.2.75,"Computational morphogenesis is the word generally used for expressing those techniques or ways of thought by which the configuration or the system of structures is generated mainly through the usage of computers, which is realized on the firm foundation of both FEM as a tool of numerical analysis and various methods based on relatively newly-developed algorithms for structural optimization. Recently, it has been gaining a considerable number of users such as structural engineers or architects for the structural design of actual buildings as well as proposals for architectural competitions. Here we present the state of the art in computational morphogenesis especially in Japan as well as the future prospects for computational morphogenesis.",Hiroshi Ohmori,10.1260/0266-3511.25.2.75,https://doi-org.crai.referencistas.com/10.1260/0266-3511.25.2.75,International Journal of Space Structures,2,75–82,Computational Morphogenesis: Its Current State and Possibility for the Future,https://doi-org.crai.referencistas.com/10.1260/0266-3511.25.2.75,25,2010g,
article,doi:10.1260/0266-3511.26.3.269,"Computational morphogenesis is the word generally used for expressing those techniques or ways of thought by which the configuration or the system of structures is generated mainly through the usage of computers, which is realized on the firm foundation of both FEM as a tool of numerical analysis and various methods based on relatively newly-developed algorithms for structural optimization. Recently, it has been gaining a considerable number of users such as structural engineers or architects for the structural design of actual buildings as well as proposals for architectural competitions. Here we present the state of the art in computational morphogenesis especially in Japan as well as the future prospects for computational morphogenesis.",Hiroshi Ohmori,10.1260/0266-3511.26.3.269,https://doi-org.crai.referencistas.com/10.1260/0266-3511.26.3.269,International Journal of Space Structures,3,269–276,Computational Morphogenesis: Its Current State and Possibility for the Future,https://doi-org.crai.referencistas.com/10.1260/0266-3511.26.3.269,26,2011h,
article,doi:10.1177/1475090217726884,"The wave loads and the resulting motions of floating wave energy converters are traditionally computed using linear radiation–diffraction methods. Yet for certain cases such as survival conditions, phase control and wave energy converters operating in the resonance region, more complete mathematical models such as computational fluid dynamics are preferred and over the last 5 years, computational fluid dynamics has become more frequently used in the wave energy field. However, rigorous estimation of numerical errors, convergence rates and uncertainties associated with computational fluid dynamics simulations have largely been overlooked in the wave energy sector. In this article, we apply formal verification and validation techniques to computational fluid dynamics simulations of a passively controlled point absorber. The phase control causes the motion response to be highly nonlinear even for almost linear incident waves. First, we show that the computational fluid dynamics simulations have acceptable agreement to experimental data. We then present a verification and validation study focusing on the solution verification covering spatial and temporal discretization, iterative and domain modelling errors. It is shown that the dominating source of errors is, as expected, the spatial discretization, but temporal and iterative errors cannot be neglected. Using hexahedral cells with low aspect ratio and 30 cells per wave height, we obtain results with less than 5% uncertainty in motion response (except for surge) and restraining forces for the buoy without phase control. The amplified nonlinear response due to phase control caused a large increase in numerical uncertainty, illustrating the difficulty to obtain reliable solutions for highly nonlinear responses, and that much denser meshes are required for such cases.",Weizhi Wang and Minghao Wu and Johannes Palm and Claes Eskilsson,10.1177/1475090217726884,https://doi-org.crai.referencistas.com/10.1177/1475090217726884,"Proceedings of the Institution of Mechanical Engineers, Part M: Journal of Engineering for the Maritime Environment",1,71–84,Estimation of numerical uncertainty in computational fluid dynamics simulations of a passively controlled wave energy converter,https://doi-org.crai.referencistas.com/10.1177/1475090217726884,232,2018i,
article,doi:10.1177/2096531120944929,"Purpose: This article aims to shed light on a latest education informatization policy blueprint in China, titled Education Informatization 2.0 Action Plan, which was promulgated by the Ministry of Education in China on April 18, 2018. Design/Approach/Methods: The study is an analytical policy review based on the policy documents, theoretical discussion, and development of practice. Findings: This new Chinese education informatization policy was driven by three factors: the promotion of education informatization 1.0 in China, the requirement of education modernization toward 2035, and the response to “Wisdom Education.” The framework for action can be summarized as “One Goal, Three Tasks, and Eight Actions.” The main features involve innovation-driven development rather than technology-driven development, committing to the expansion of digital educational resources rather than the digital presentation of textbooks, and aiming at improving teachers and students’ information literacy rather than the applied skills of information technology. The future vision of the plan involves building new models on talent cultivation, education service, and education governance. The new models on talent cultivation involve establishing “Wisdom Teaching” mode, learning mode, and intelligent learning environment supported by artificial intelligence technology. The new education service models entail building the admission and sharing mechanism of quality educational resources based on National Network for Education and the public service platform and system for educational resources by means of the cloud computing and artificial intelligence. The new education governance models involve achieving precise, flat, and humanized education governance. Originality/Value: This article entails expounding the motivation, framework for action, main features, and vision of the education informatization 2.0 in China, which will be helpful for learning and understanding the current background, stage, and future path of China’s education informatization.",Shouxuan Yan (闫守轩) and Yun Yang (杨运),10.1177/2096531120944929,https://doi-org.crai.referencistas.com/10.1177/2096531120944929,ECNU Review of Education,2,410–428,"Education Informatization 2.0 in China: Motivation, Framework, and Vision",https://doi-org.crai.referencistas.com/10.1177/2096531120944929,4,2021j,
article,doi:10.1177/0306419015591325,"The teaching of computational fluid dynamics at the undergraduate level usually focuses on giving students an understanding of the numerical methods and details involved, supported by what are little more than code fragments, followed by learning an abstract form of computational fluid dynamics skills and processes, without any real interaction with the complex core computer coding behind what is often just ‘easy-to-use’ or ‘push button’ commercial interfaces. Quite often, as the student progresses in his/her use of computational fluid dynamics, especially in the research area, it becomes clear that an ‘off-the-shelf’ commercial computational fluid dynamics package is not able to satisfy all requirements to simulate a given problem fully, nor to obtain accurate results. The purpose of this paper is to outline what must be taught to add computer coding to what usually is a well-protected, though capable of being compiled and linked, core computer code so that the complexity of interacting is lessened and better understood.",Desmond Adair and Martin Jaeger,10.1177/0306419015591325,https://doi-org.crai.referencistas.com/10.1177/0306419015591325,International Journal of Mechanical Engineering Education,3,153–167,Incorporating computational fluid dynamics code development into an undergraduate engineering course,https://doi-org.crai.referencistas.com/10.1177/0306419015591325,43,2015a,
article,doi:10.1177/1932202X241244881,"Promoting the education of talented and gifted students is a crucial aspect of establishing a strong society focused on scientific knowledge. This praxis article delves into the implementation of strategies in the Syrian Arab Republic to support and identify gifted students, focusing on initiatives such as the Syrian Scientific Olympiad, the National Centre for Distinguished Students, and Academic Programs for Distinguished Students. Data collection methods utilized in this study shed light on the outcomes of these initiatives and measures taken to promote gifted education in Syria. The analysis of this data provides insights into the impact of these programs on gifted students in crisis-stricken regions. The study emphasizes the significant role played by the Distinction and Creativity Agency in nurturing exceptional talents and fostering personal growth. Overall, the support provided to gifted students contributes to cognitive advancement, psychological well-being, and skill development, enhancing their overall well-being and paving the way for successful futures. The government’s commitment to supporting gifted education in the Syrian Arab Republic reflects its dedication to promoting talent and creativity in the Arab region.",Marwan Al-Raeei and Chadi Azmeh and Hala AlDakak,10.1177/1932202X241244881,https://doi-org.crai.referencistas.com/10.1177/1932202X241244881,Journal of Advanced Academics,0,1932202X241244881,Enriching Minds: The Gifted Education Landscape in the Syrian Arab Republic,https://doi-org.crai.referencistas.com/10.1177/1932202X241244881,0,2024b,
article,doi:10.1177/1464884917693864,"This article outlines a general epistemological framework of data journalism in the devolved nations of the United Kingdom. By using an original model based on three conceptual lenses – materiality, performativity and reflexivity – this study examines the development of this form of journalism, the challenges it faces and its particularities in the context of Scotland, Wales and Northern Ireland. This research, therefore, offers unique insights from semi-structured interviews with data journalists and data editors based at, or working as freelancers for, the mainstream news organisations of these regions. The results suggest that data journalism in these devolved nations displays a distinctive character just as much as it reinforces the norms and rituals of the legacy organisations that pioneered this practice. While various models of data exploitation are tested, regional data journalists creatively circumvent generalised organisational struggles to lay the groundwork for their trade and professional community.",Eddy Borges-Rey,10.1177/1464884917693864,https://doi-org.crai.referencistas.com/10.1177/1464884917693864,Journalism,7,915–932,"Towards an epistemology of data journalism in the devolved nations of the United Kingdom: Changes and continuities in materiality, performativity and reflexivity",https://doi-org.crai.referencistas.com/10.1177/1464884917693864,21,2020c,
article,doi:10.1177/1463949119846541,"This article presents steps that can be used to expose children to concrete experiences of practicing coding using unplugged activities, including using directional words or directional arrows, using sequential words, combining both directional and sequential words, and connecting with grids.",Joohi Lee,10.1177/1463949119846541,https://doi-org.crai.referencistas.com/10.1177/1463949119846541,Contemporary Issues in Early Childhood,3,266–269,Coding in early childhood,https://doi-org.crai.referencistas.com/10.1177/1463949119846541,21,2020d,
article,doi:10.1177/117762500700100010,"In recent years it has become clear that carcinogenesis is a complex process, both at the molecular and cellular levels. Understanding the origins, growth and spread of cancer, therefore requires an integrated or system-wide approach. Computational systems biology is an emerging sub-discipline in systems biology that utilizes the wealth of data from genomic, proteomic and metabolomic studies to build computer simulations of intra and intercellular processes. Several useful descriptive and predictive models of the origin, growth and spread of cancers have been developed in an effort to better understand the disease and potential therapeutic approaches. In this review we describe and assess the practical and theoretical underpinnings of commonly-used modeling approaches, including ordinary and partial differential equations, petri nets, cellular automata, agent based models and hybrid systems. A number of computer-based formalisms have been implemented to improve the accessibility of the various approaches to researchers whose primary interest lies outside of model development. We discuss several of these and describe how they have led to novel insights into tumor genesis, growth, apoptosis, vascularization and therapy.",Wayne Materi and David S. Wishart,10.1177/117762500700100010,https://doi-org.crai.referencistas.com/10.1177/117762500700100010,Gene Regulation and Systems Biology, ,117762500700100020,Computational Systems Biology in Cancer: Modeling Methods and Applications,https://doi-org.crai.referencistas.com/10.1177/117762500700100010,1,2007e,
article,doi:10.1177/1478077120947990,"Building with additive manufacturing is an increasingly relevant research topic in the field of Construction 4.0, where designers are seeking higher levels of automation, complexity and precision compared to conventional construction methods. As an answer to the increasing problem of scarcity of resources, the presented research exploits the potential of Fused Deposition Modelling in the production of a lightweight load-responsive cellular lattice structure at the architectural scale. The article offers an extensive insight into the computational processes involved in the design, engineering, analysis, optimization and fabrication of a material-efficient, fully 3D printed, lattice structure. Material, structure and manufacturing features are integrated within the design development in a comprehensive computational workflow. The article presents methods and results while discussing the project as a material-efficient approach to complex structures.",Roberto Naboni and Anja Kunic and Luca Breseghello,10.1177/1478077120947990,https://doi-org.crai.referencistas.com/10.1177/1478077120947990,International Journal of Architectural Computing,4,404–423,"Computational design, engineering and manufacturing of a material-efficient 3D printed lattice structure",https://doi-org.crai.referencistas.com/10.1177/1478077120947990,18,2020f,
article,doi:10.1177/0951629812473007,"Representative democracy translates the preferences of the electorate into policy outcomes. Individual voters do not directly vote on policy; rather, their elected representatives create and establish policy. How well do the institutions of representative democracy translate the preferences of the electorate into policy? Is there any systematic bias in a representative democracy system? After formulating a series of computational models it appears that the degree to which legislative districts are ‘gerrymandered’ with respect to preferences about the policy is a source of policy bias. To illustrate the phenomenon, household income is used as a proxy for voters’ preferences with respect to redistribution. Even when the majority of voters are in favor of redistribution, if districts are constructed with a sufficient level of conservative gerrymandering, the policy outcome under representative democracy will favor far less redistribution than the policy outcome under direct democracy.",Robi Ragan,10.1177/0951629812473007,https://doi-org.crai.referencistas.com/10.1177/0951629812473007,Journal of Theoretical Politics,4,467–491,Institutional sources of policy bias: A computational investigation,https://doi-org.crai.referencistas.com/10.1177/0951629812473007,25,2013g,
article,doi:10.3233/AAC-190467,"In informal argument, an essential step is to ask what will “resonate” with a particular audience and hence persuade. Marketers, for example, may recommend a certain colour for a new soda can because it “pops” on Instagram; politicians may “fine-tune” diction for different social demographics. This paper engages the need to strategise for such resonance by offering a method for automating opposition analysis (OA), a technique from semiotics used in marketing and literary analysis to plot objects of interest on oppositional axes. Central to our computational approach is a reframing of texts as proxies for thought and opposition as the product of oscillation in thought in response to those proxies, a model to which the contextual similarity information contained in word embeddings is relevant. We illustrate our approach with an analysis of texts on gun control from ProCon.org, implementing a three-step method to: 1) identify relatively prominent signifiers; 2) rank possible opposition pairs on prominence and contextual similarity scores; and 3) derive plot values for proxies on opposition pair axes. The results are discussed in terms of strategies for informal argument that might be derived by those on each side of gun control.",Cameron Shackell and Laurianne Sitbon,10.3233/AAC-190467,https://doi-org.crai.referencistas.com/10.3233/AAC-190467,Argument & Computation,3,301–317,Computational opposition analysis using word embeddings: A method for strategising resonant informal argument,https://doi-org.crai.referencistas.com/10.3233/AAC-190467,10,2019h,
article,doi:10.1177/0954407020915104,"The computational aero-acoustic study of an isolated passenger car tire is carried out to understand the effect of dimensions of longitudinal tire grooves and operational parameters (velocity and temperature) on tire noise. The computational fluid dynamics and acoustic models are used to obtain aero-acoustic tire noise at near-field and far-field receivers around the tire and artificial neural networks-based regression are used to study the highly non-linear and interactive causal relationships in the system. Unsteady Reynolds-Averaged Navier-Stokes based realizable k-epsilon model is used to solve the flow field in the computational domain. The Ffowcs Williams and Hawkings model is used to obtain aero-acoustic tire noise at far-field positions. Spectral analysis is used to convert the output time domain to frequency domain and to obtain A-weighted sound pressure level. Artificial neural network–based response surface regression is conducted to understand casual relationships between A-weighted sound pressure level and control variables (Groove depth, Groove width, Temperature and velocity). Maximum A-weighted sound pressure level is observed in the wake region of the tire model. The interaction study indicates that ∼10% reduction in the aero-acoustic emissions is possible by selecting appropriate combinations of groove width and groove depth. The interaction of velocity with width is found to be most significant with respect to A-weighted sound pressure level at all receivers surrounding the tire. The interaction of operational parameters, that is, velocity and temperature are found to be significant with respect to A-weighted sound pressure level at wake and front receivers. Therefore, the regional speed limits and seasonal temperatures need to be considered while designing the tire to achieve minimum aero-acoustic emissions.",Ghulam Moeen Uddin and Sajawal Gul Niazi and Syed Muhammad Arafat and Muhammad Sajid Kamran and Muhammad Farooq and Nasir Hayat and Sher Afghan Malik and Abe Zeid and Sagar Kamarthi and Sania Saqib et al.,10.1177/0954407020915104,https://doi-org.crai.referencistas.com/10.1177/0954407020915104,"Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering",10–11,2561–2577,Neural networks assisted computational aero-acoustic analysis of an isolated tire,https://doi-org.crai.referencistas.com/10.1177/0954407020915104,234,2020i,
article,doi:10.1177/1094342006074857,"Detailed experimental measurements of a compressor (pressure, temperature, speed) are not easily available because of size, cost, and access difficulties. A comprehensive computer model is necessary to obtain pressure-volume diagrams for the compressor. The valve is a key component of a compressor as it determines both the efficiency and reliability of the compressor. The valves operate as a result of pressure differences between the ports and the gas chamber. Undesired vibrations and fatigue fracture of thin valves (0.2 mm steel sheet) have not been well understood and experimental difficulties do not allow a thorough analysis of the causes. Initial investigations and modifications to KIVA-3V showed this code can be used to model both gas and suction valve motion. Since the code was written for internal combustion engines, its adaptation to compressors proved to be a difficult task, particularly because of the orientation and complexity of valves. Extensive modifications were made to model an angularly moving valve system, however as we moved down from engine scale (10 cm) to compressor scale (1 cm), grid resolution became a challenge from time to time. Preliminary results showed that the design of the suction valve and the chamber impacts the pressure difference between the input port and the gas chamber. The higher the piston speed, the lower the pressure of the gas, making it perhaps more plausible to avoid premature valve closings at higher speeds. Even though it is still under investigation, valve location and the orientation of its loose end makes a difference to the pressure, suggesting that new designs may be necessary by manufacturers. Experimental data will be needed to validate our model and verify our observations. Future steps include adding a discharge valve and a fluid-solid interface (FSI) module to the modified KIVA-3V code in order to predict the motion of the valves as a result of their interaction with the chamber gas.",O. Yaşar and M. Koçaş,10.1177/1094342006074857,https://doi-org.crai.referencistas.com/10.1177/1094342006074857,The International Journal of High Performance Computing Applications,1,30–41,Computational Modeling of Hermetic Reciprocating Compressors,https://doi-org.crai.referencistas.com/10.1177/1094342006074857,21,2007j,
article,doi:10.1177/1932202X241244881,"Promoting the education of talented and gifted students is a crucial aspect of establishing a strong society focused on scientific knowledge. This praxis article delves into the implementation of strategies in the Syrian Arab Republic to support and identify gifted students, focusing on initiatives such as the Syrian Scientific Olympiad, the National Centre for Distinguished Students, and Academic Programs for Distinguished Students. Data collection methods utilized in this study shed light on the outcomes of these initiatives and measures taken to promote gifted education in Syria. The analysis of this data provides insights into the impact of these programs on gifted students in crisis-stricken regions. The study emphasizes the significant role played by the Distinction and Creativity Agency in nurturing exceptional talents and fostering personal growth. Overall, the support provided to gifted students contributes to cognitive advancement, psychological well-being, and skill development, enhancing their overall well-being and paving the way for successful futures. The government’s commitment to supporting gifted education in the Syrian Arab Republic reflects its dedication to promoting talent and creativity in the Arab region.",Marwan Al-Raeei and Chadi Azmeh and Hala AlDakak,10.1177/1932202X241244881,https://doi-org.crai.referencistas.com/10.1177/1932202X241244881,Journal of Advanced Academics,0,1932202X241244881,Enriching Minds: The Gifted Education Landscape in the Syrian Arab Republic,https://doi-org.crai.referencistas.com/10.1177/1932202X241244881,0,2024a,
article,doi:10.1177/0954411916683222,"Cement augmentation in vertebrae (vertebroplasty) is usually used to restore mechanical strength after spinal fracture but could also be used as a prophylactic treatment. So far, the mechanical competence has been determined immediately post-treatment, without considering long-term effects of bone adaptation. In this work, we investigated such long-term effects of vertebroplasty on the stiffness of the augmented bone by means of computational simulation of bone adaptation. Using micro-finite element analysis, we determined sites of increased mechanical stress (stress raisers) and stress shielding and, based on the simulations, regions with increased or decreased bone loss due to augmentation. Cement volumes connecting the end plates led to increased stress shielding and bone loss. The increased stiffness due to the augmentation, however, remained constant over the simulation time of 30 years. If the intervention was performed at an earlier time point, it did lead to more bone loss, but again, it did not affect long-term stability as this loss was compensated by bone gains in other areas. In particular, around the augmentation cement, bone structures were preserved, suggesting a long-term integration of the cement in the augmented bone. We conclude that, from a biomechanical perspective, the impact of vertebroplasty on the bone at the microstructural level is less detrimental than previously thought.",Sandro D Badilatti and Patrik Christen and Stephen J Ferguson and Ralph Müller,10.1177/0954411916683222,https://doi-org.crai.referencistas.com/10.1177/0954411916683222,"Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine",5,423–431,Computational modeling of long-term effects of prophylactic vertebroplasty on bone adaptation,https://doi-org.crai.referencistas.com/10.1177/0954411916683222,231,2017b,PMID:28427315
article,doi:10.4137/CMC.S39708,"Image-based computational modeling is becoming an increasingly used clinical tool to provide insight into the mechanisms of reentrant arrhythmias. In the context of ischemic heart disease, faithful representation of the electrophysiological properties of the infarct region within models is essential, due to the scars known for arrhythmic properties. Here, we review the different computational representations of the infarcted region, summarizing the experimental measurements upon which they are based. We then focus on the two most common representations of the scar core (complete insulator or electrically passive tissue) and perform simulations of electrical propagation around idealized infarct geometries. Our simulations highlight significant differences in action potential duration and focal effective refractory period (ERP) around the scar, driven by differences in electrotonic loading, depending on the choice of scar representation. Finally, a novel mechanism for arrhythmia induction, following a focal ectopic beat, is demonstrated, which relies on localized gradients in ERP directly caused by the electrotonic sink effects of the neighboring passive scar.",Adam J. Connolly and Martin J. Bishop,10.4137/CMC.S39708,https://doi-org.crai.referencistas.com/10.4137/CMC.S39708,Clinical Medicine Insights: Cardiology, ,CMC.S39708,Computational Representations of Myocardial Infarct Scars and Implications for Arrhythmogenesis,https://doi-org.crai.referencistas.com/10.4137/CMC.S39708,10s1,2016c,PMID:27486348
article,doi:10.1243/0957650001538353,"Abstract This paper describes a study of the use of computational fluid dynamics (CFD) to investigate the performance of a precalciner vessel at a cement works, In this vessel, limestone, held in suspension, is calcined to calcium oxide and the endothermic reaction is supported by the combustion of coal. Results are presented from a CFD model that contains all the essential features of the precalciner as operated when burning coal. The model fully represents the reactions and fluid dynamics of the precalciner. Previously unidentified features are illustrated. Certain key features at points in the precalciner, where some limited measurements can be made, are compared with the parameters indicated by the computational model. The measurements are consistent with the results calculated by the model indicating fair validation. The CFD data show the following 1 The gases undergo distinct recirculation. 2 The coal particles entering at one inlet have significantly different trajectories and temperature histories from those entering at the second diametrically opposed inlet. 3 There is 90 per cent completion of coal combustion at the exit. 4 73 per cent limestone in the raw meal is calcined to calcined to calcium oxide at the exit from the precalciner. 5 The highest reaction rate of the raw meal is closer to one side of the vessel due to interaction with the gas flows. Future work is proposed which, firstly, will provide further validation of the results so far attained by selective measurements on the precalciner and, secondly, will model the combustion and aerodynamic behaviour of waste-derived fuels in the precalciner vessel, commencing with shredded car tyre chips.",D Giddings and C N Eastwick and S J Pickering and K Simmons,10.1243/0957650001538353,https://doi-org.crai.referencistas.com/10.1243/0957650001538353,"Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy",3,269–280,Computational fluid dynamics applied to a cement precalciner,https://doi-org.crai.referencistas.com/10.1243/0957650001538353,214,2000d,
article,doi:10.1177/1464420712470356,"Advanced non-linear dynamics, finite element computational methods and tools are utilized in order to assess the blast wave mitigation potential of the fluid–structure interaction phenomena involving rigid and deformable structures. The employed computational methods and tools are verified and validated by first demonstrating that they can quite accurately reproduce analytical solutions for a couple of well-defined blast wave propagation and interaction problems. Then the methods/tools are used to investigate the fluid–structure interaction phenomena involving deformable structures while accounting for both the interaction of the incident blast wave with the structure and for the structure-motion induced blast wave (at the back-face of the structure). To assess the role of the structure deformability, i.e. the role of the shock waves generated within the structure, the results obtained are compared with their rigid structure counterparts. This comparison established that no additional structure-deformability-related blast-mitigation effects are observed in the case of fully supported blast wave loading while, under exponentially decaying blast wave loading, such effects are observed but only under conditions when the shock wave propagation time within the structure is comparable with the incident wave decay time.",M Grujicic and JS Snipes and N Chandrasekharan,10.1177/1464420712470356,https://doi-org.crai.referencistas.com/10.1177/1464420712470356,"Proceedings of the Institution of Mechanical Engineers, Part L: Journal of Materials: Design and Applications",2,124–142,Computational analysis of fluid–structure interaction based blast-mitigation effects,https://doi-org.crai.referencistas.com/10.1177/1464420712470356,227,2013e,
article,doi:10.1177/0003489419842217,"Objectives: Competent velopharyngeal (VP) function is the basis for normal speech. Understanding how VP structure influences the airflow during speech details is essential to the surgical improvement of pharyngoplasty. In this study, we aimed to illuminate the airflow features corresponding to various VP closure states using computed dynamic simulations. Methods: Three-dimensional models of the upper airways were established based on computed tomography of 8 volunteers. The velopharyngeal port was simulated by a cylinder. Computational fluid dynamics simulations were applied to illustrate the correlation between the VP port size and the airflow parameters, including the flow velocity, pressure in the velopharyngeal port, as well as the pressure in oral and nasal cavity. Results: The airflow dynamics at the velopharynx were maintained in the same velopharyngeal pattern as the area of the velopharyngeal port increased from 0 to 25 mm2. A total of 5 airflow patterns with distinct features were captured, corresponding to adequate closure, adequate/borderline closure (Class I and II), borderline/inadequate closure, and inadequate closure. The maximal orifice area that could be tolerated for adequate VP closure was determined to be 2.01 mm2. Conclusion: Different VP functions are of characteristic airflow dynamic features. Computational fluid dynamic simulation is of application potential in individualized VP surgery planning.",Hanyao Huang and Xu Cheng and Yang Wang and Dantong Huang and Yuhao Wei and Heng Yin and Bing Shi and Jingtao Li,10.1177/0003489419842217,https://doi-org.crai.referencistas.com/10.1177/0003489419842217,"Annals of Otology, Rhinology & Laryngology",8,742–748,Analysis of Velopharyngeal Functions Using Computational Fluid Dynamics Simulations,https://doi-org.crai.referencistas.com/10.1177/0003489419842217,128,2019f,PMID:30957524
article,doi:10.1177/117762500700100010,"In recent years it has become clear that carcinogenesis is a complex process, both at the molecular and cellular levels. Understanding the origins, growth and spread of cancer, therefore requires an integrated or system-wide approach. Computational systems biology is an emerging sub-discipline in systems biology that utilizes the wealth of data from genomic, proteomic and metabolomic studies to build computer simulations of intra and intercellular processes. Several useful descriptive and predictive models of the origin, growth and spread of cancers have been developed in an effort to better understand the disease and potential therapeutic approaches. In this review we describe and assess the practical and theoretical underpinnings of commonly-used modeling approaches, including ordinary and partial differential equations, petri nets, cellular automata, agent based models and hybrid systems. A number of computer-based formalisms have been implemented to improve the accessibility of the various approaches to researchers whose primary interest lies outside of model development. We discuss several of these and describe how they have led to novel insights into tumor genesis, growth, apoptosis, vascularization and therapy.",Wayne Materi and David S. Wishart,10.1177/117762500700100010,https://doi-org.crai.referencistas.com/10.1177/117762500700100010,Gene Regulation and Systems Biology, ,117762500700100020,Computational Systems Biology in Cancer: Modeling Methods and Applications,https://doi-org.crai.referencistas.com/10.1177/117762500700100010,1,2007g,
article,doi:10.1177/1478077120947990,"Building with additive manufacturing is an increasingly relevant research topic in the field of Construction 4.0, where designers are seeking higher levels of automation, complexity and precision compared to conventional construction methods. As an answer to the increasing problem of scarcity of resources, the presented research exploits the potential of Fused Deposition Modelling in the production of a lightweight load-responsive cellular lattice structure at the architectural scale. The article offers an extensive insight into the computational processes involved in the design, engineering, analysis, optimization and fabrication of a material-efficient, fully 3D printed, lattice structure. Material, structure and manufacturing features are integrated within the design development in a comprehensive computational workflow. The article presents methods and results while discussing the project as a material-efficient approach to complex structures.",Roberto Naboni and Anja Kunic and Luca Breseghello,10.1177/1478077120947990,https://doi-org.crai.referencistas.com/10.1177/1478077120947990,International Journal of Architectural Computing,4,404–423,"Computational design, engineering and manufacturing of a material-efficient 3D printed lattice structure",https://doi-org.crai.referencistas.com/10.1177/1478077120947990,18,2020h,
article,doi:10.1177/1744259120901840,"Building energy simulations coupled with computational fluid dynamics tools have emerged, recently, as an accurate and effective tool to improve the estimation of energy requirements and thermal comfort in buildings. Building modelers and researchers usually implement this coupling in the boundary conditions of both tools (e.g. surface temperature, ambient temperature, and conductive and convective fluxes). This work reviews how the building energy simulation–computational fluid dynamics coupling has evolved since its first implementation to the present day. Moreover, this article also summarizes and discusses the research studies in which the building energy simulation–computational fluid dynamics coupling has been used to analyze building systems, building components, and building urban configurations. Implementing a building energy simulation–computational fluid dynamics coupling brings a series of benefits when compared with the conventional building energy simulation methodology, a building energy simulation–computational fluid dynamics coupling provides an improvement that ranges between 10% and 50% for estimating the building energy requirements. Moreover, the computation time to implement computational fluid dynamics with information obtained from the building energy simulation could be reduced by as well.",Martin Rodríguez-Vázquez and Iván Hernández-Pérez and Jesus Xamán and Yvonne Chávez and Miguel Gijón-Rivera and Juan M Belman-Flores,10.1177/1744259120901840,https://doi-org.crai.referencistas.com/10.1177/1744259120901840,Journal of Building Physics,2,137–180,Coupling building energy simulation and computational fluid dynamics: An overview,https://doi-org.crai.referencistas.com/10.1177/1744259120901840,44,2020i,
article,doi:10.3233/AAC-190467,"In informal argument, an essential step is to ask what will “resonate” with a particular audience and hence persuade. Marketers, for example, may recommend a certain colour for a new soda can because it “pops” on Instagram; politicians may “fine-tune” diction for different social demographics. This paper engages the need to strategise for such resonance by offering a method for automating opposition analysis (OA), a technique from semiotics used in marketing and literary analysis to plot objects of interest on oppositional axes. Central to our computational approach is a reframing of texts as proxies for thought and opposition as the product of oscillation in thought in response to those proxies, a model to which the contextual similarity information contained in word embeddings is relevant. We illustrate our approach with an analysis of texts on gun control from ProCon.org, implementing a three-step method to: 1) identify relatively prominent signifiers; 2) rank possible opposition pairs on prominence and contextual similarity scores; and 3) derive plot values for proxies on opposition pair axes. The results are discussed in terms of strategies for informal argument that might be derived by those on each side of gun control.",Cameron Shackell and Laurianne Sitbon,10.3233/AAC-190467,https://doi-org.crai.referencistas.com/10.3233/AAC-190467,Argument & Computation,3,301–317,Computational opposition analysis using word embeddings: A method for strategising resonant informal argument,https://doi-org.crai.referencistas.com/10.3233/AAC-190467,10,2019j,
article,doi:10.1177/09544100241234374,"The capability for solving compressible fluid flows in the rotating frame of reference is added to an existed open-source CFD solver, namely, HiSA solver. The new implementation is explained and validated using the experimental data of the Sikorsky S-76 rotor. A comparison is presented between the moving mesh results obtained from the original HiSA code and the single rotating frame results achieved through the new implementation. The comparison includes an analysis of torque and thrust values, as well as computational costs. The results imply that, for evaluating the performance of an isolated rotor or for shape optimization purposes at the transonic regime, the single rotating frame method, like the one introduced in the current work, can provide accurate results within an acceptable computational budget. Furthermore, the results show that, at least 25 revolutions are required for the transient analysis to reach an acceptable steady-state converged solution like the one obtained by the single rotating frame method.",Saleh Abuhanieh,10.1177/09544100241234374,https://doi-org.crai.referencistas.com/10.1177/09544100241234374,"Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering",6,582–595,Development of a steady-state computational fluid dynamics solver for transonic rotorcraft flows,https://doi-org.crai.referencistas.com/10.1177/09544100241234374,238,2024a,
article,doi:10.1177/1478077120919850,"Computational design affords agency: the ability to orchestrate the material, spatial, and technical architectural system. In this specific case, it occurs through enhanced, authored means to facilitate making and performance—typically driven by concerns of structural optimization, material use, and responsivity to environmental factors—of an atmospheric rather than social nature. At issue is the positioning of this particular manner of agency solely with the architect auteur. This abruptly halts—at the moment in which fabrication commences—the ability to amend, redefine, or newly introduce fundamentally transformational constituents and their interrelationships and, most importantly, to explore the possibility for extraordinary outcomes. When the architecture becomes a functional, social, and cultural entity, in the hands of the idealized abled-bodied user, agency—especially for one of an otherly body or mind—is long gone. Even an empathetic auteur may not be able to access the motivations of the differently-abled body and neuro-divergent mind, effectively locking the constraints of the design process, which creates an exclusionary system to those beyond the purview of said auteur. It can therefore be deduced that the mechanisms or authors of a conventional computational design process cannot eradicate the exclusionary reality of an architectural system. Agency is critical, yet a more expansive terminology for agent and agency is needed. The burden to conceive of capacities that will always be highly temporal, social, unpredictable, and purposefully unknown must be shifted far from the scope of the traditional directors of the architectural system. Agency, and who it is conferred upon, must function in a manner that dissolves the distinctions between the design, the action of designing, the author of design, and those subjected to it.",Sean Ahlquist,10.1177/1478077120919850,https://doi-org.crai.referencistas.com/10.1177/1478077120919850,International Journal of Architectural Computing,2,174–193,Negotiating human engagement and the fixity of computational design: Toward a performative design space for the differently-abled bodymind,https://doi-org.crai.referencistas.com/10.1177/1478077120919850,18,2020b,
article,doi:10.1177/1461444812465137,"This article advances a sociological approach to computational journalism. By “computational journalism” the article refers to the increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork adopted by many 21st-century newsrooms and touted by many educational institutions as “the future of news.” By “sociological approach,” the article endorses a research model that brackets, at least temporarily, many of the current industry concerns with the practical usability of newsroom analysis. The bulk of the article outlines a series of six lenses through which such an approach to computational journalism might be carried out. Four of these lenses are drawn from Schudson’s classic typology of the sociology of news—economic, political, cultural, and organizational approaches. In addition, the author adds Bordieuean field approaches and technological lenses to the mix. In each instance, the author discusses how particular approaches might need to be modified in order to study computational journalism in the digital age.",CW Anderson,10.1177/1461444812465137,https://doi-org.crai.referencistas.com/10.1177/1461444812465137,New Media & Society,7,1005–1021,Towards a sociology of computational and algorithmic journalism,https://doi-org.crai.referencistas.com/10.1177/1461444812465137,15,2013c,
article,doi:10.1177/2167702614562041,"Schizophrenia is an illness with a remarkably complex symptom presentation that has thus far been out of reach of neuroscientific explanation. This presents a fundamental problem for developing better treatments that target specific symptoms or root causes. One promising path forward is the incorporation of computational neuroscience, which provides a way to formalize experimental observations and, in turn, make theoretical predictions for subsequent studies. We review three complementary approaches: (a) biophysically based models developed to test cellular-level and synaptic hypotheses, (b) connectionist models that give insight into large-scale neural-system-level disturbances in schizophrenia, and (c) models that provide a formalism for observations of complex behavioral deficits, such as negative symptoms. We argue that harnessing all of these modeling approaches represents a productive approach for better understanding schizophrenia. We discuss how blending these approaches can allow the field to progress toward a more comprehensive understanding of schizophrenia and its treatment.",Alan Anticevic and John D. Murray and Deanna M. Barch,10.1177/2167702614562041,https://doi-org.crai.referencistas.com/10.1177/2167702614562041,Clinical Psychological Science,3,433–459,Bridging Levels of Understanding in Schizophrenia Through Computational Modeling,https://doi-org.crai.referencistas.com/10.1177/2167702614562041,3,2015d,PMID:25960938
article,doi:10.1177/089443902237317,"There has been significant recent interest in Agent Based Modeling in many social sciences including economics, sociology, anthropology, political science, and game theory. This article describes three problems that need to be addressed in order for such models to become effective tools for formulating new social theory and informing policy debates and suggests approaches to meeting them. These issues are computational epistemology, research methodology, and software technology. These innovations augment Agent Based Modeling to create an effective new tool base to help better understand complex social systems.",Steven Bankes and Robert Lempert and Steven Popper,10.1177/089443902237317,https://doi-org.crai.referencistas.com/10.1177/089443902237317,Social Science Computer Review,4,377–388,"Making Computational Social Science Effective: Epistemology, Methodology, and Technology",https://doi-org.crai.referencistas.com/10.1177/089443902237317,20,2002e,
article,doi:10.1177/1326365X18769395,"This commentary draws on a decade’s experience of teaching data journalism within a variety of contexts to describe the lessons learned regarding different pedagogical techniques and choices about the aspects of data journalism to teach. What emerges is a difference between classes aimed at a general audience, who might be sceptical and/or ignorant of the diversity of data journalism practice and those aimed at a more specialist audience aiming to go into the increasing numbers of roles dedicated to data-driven techniques.",Paul Bradshaw,10.1177/1326365X18769395,https://doi-org.crai.referencistas.com/10.1177/1326365X18769395,Asia Pacific Media Educator,1,55–66,"Data Journalism Teaching, Fast and Slow",https://doi-org.crai.referencistas.com/10.1177/1326365X18769395,28,2018f,
article,doi:10.1177/20539517211069892,"This commentary elaborates on the ideas and projects outlined in this special issue, from a specifically sociological perspective. Much recent work in sociology proposes ‘methods mashups’ of ethnography and digital data/computational tools in different and diverse ways. However, typically, these have taken the form of applying (with or without tweaks) the principles of ethnography to new domains and data types, as if ethnography itself is stable and immutable; that it has a universal set of methodological principles that unify ethnographic practice. Returning to anthropology (whence, arguably, ethnography originally came) is, therefore, a useful way to extend our methodological thinking to (re)consider what ethnography is and how it operates, and from there think more clearly about how it may be effectively combined with digital data/computational tools in an emerging ‘Computational Anthropology’.",Phillip Brooker,10.1177/20539517211069892,https://doi-org.crai.referencistas.com/10.1177/20539517211069892,Big Data & Society,1,20539517211069892,Computational ethnography:  A view from sociology,https://doi-org.crai.referencistas.com/10.1177/20539517211069892,9,2022g,
article,doi:10.1177/0309524X17709724,"In this article, the implementation of the pitch-control option is described within the OpenFOAM computational fluid dynamics library supported by the preliminary results for a few representative test cases. The proposed pitch-control logic represents a simplified version of the typically model available for the load simulation based on blade element momentum theory codes. The control variable for the blade pitch regulation is the rotor rotational speed, for which an additional torque-speed controller determining the equilibrium between the aerodynamic and the electrical torque is required. The simulations are performed on the 80-m-diameter turbine used as a reference design within the SmartBlades project. The unsteady test cases are based on the assumption of rigid, not pre-bend blade, and refer to an emergency stop and an extreme operating gust. Results verified the correctness of the implemented control logic and its sensitivity to the control parameters, that is, the key factors for a successful regulation of power production and load mitigation in wind turbine design. The implemented simulation methodology constitutes the first step toward the reproduction of very complex operating conditions for wind turbines by means of accurate computations.",Elia Daniele,10.1177/0309524X17709724,https://doi-org.crai.referencistas.com/10.1177/0309524X17709724,Wind Engineering,4,213–225,Wind turbine control in computational fluid dynamics with OpenFOAM,https://doi-org.crai.referencistas.com/10.1177/0309524X17709724,41,2017h,
article,doi:10.5301/jva.5000241,"Background The creation and management of an autologous arteriovenous fistula (AVF) as vascular access (VA) for hemodialysis patients is still a critical procedure. The placement of a functional and long-lasting VA derives from adequate planning of the surgical procedure based on physical examination, vascular mapping and selection of the best modality for arteriovenous anastomosis. The risk of AVF non-maturation and early failure is high, even when all precautions are taken to minimize these events. In addition, AVF surgery may develop very high blood flow exposing the patient to the risk of heart failure or hand ischemia. Methods The choices of the surgeons on the modalities to perform a surgical intervention for AVF should take into consideration several factors including patient clinical condition, arterial and venous vessel sizes and elasticity. However, these evaluations cannot give direct indication on VA outcome in terms of blood flow after AVF maturation. We then took advantage of theoretical models of vascular network hemodynamics and of computational fluid dynamics to develop a numerical tool for the prediction of potential blood flow of a planned VA surgery on the basis of preoperative ultrasound evaluation of arterial and venous sizes and blood flow. Results Here we present the numerical model, previously developed and tested, and we describe the web-based application that has been developed to help during surgical planning. Conclusions The use of this tool in the clinical setting should allow to reduce the incidence of AVF non-maturation as well as incidence of VA complications.",Andrea Remuzzi and Simone Manini,10.5301/jva.5000241,https://doi-org.crai.referencistas.com/10.5301/jva.5000241,The Journal of Vascular Access,7_suppl,64–69,Computational Model for Prediction of Fistula Outcome,https://doi-org.crai.referencistas.com/10.5301/jva.5000241,15,2014i,
article,doi:10.1177/1046878119872797,"Background. Learning programming is a cognitively demanding field of study accompanied with various difficulties. Although there is a high demand in the market for programmers, software analysts and engineers, a high dropout rate is recorded in relevant fields of study. Serious games are a promising means of engaging students in learning programming by giving them more incentives and making the process of learning programming concepts and languages more entertaining. Aim. This article introduces a new serious game called PY-RATE ADVENTURES, which aims to assist young students in their introduction to the basic programming concepts using Python. The game does not have any prerequisites and is suitable for players with no previous knowledge of programming. This article aims to present important information regarding the analysis, design and pilot evaluation of PY-RATE ADVENTURES. Method. The game was evaluated by 31 people that had recently graduated or were students of an Interdepartmental Programme of Postgraduate Studies in Information Systems. The participants voluntarily played the game and answered a questionnaire based on the MEEGA+ model, after their hands on experience with the game. This questionnaire’s purpose was to evaluate PY-RATE ADVENTURES in terms of perceived player experience and short-term learning. Results. The participants positively evaluated the game almost in all the elements of player experience. Furthermore, the majority of the users consider that the game helped them to learn basic programming concepts in Python and stated that they would prefer to learn programming with this game rather than other teaching methods. Conclusion. The positive results of the pilot evaluation give us the motivation to proceed and evaluate the game with students in secondary education, in order to extract stronger and generalisable conclusions regarding the impact of the game as an educational tool for learning programming concepts.",Grigorios Sideris and Stelios Xinogalos,10.1177/1046878119872797,https://doi-org.crai.referencistas.com/10.1177/1046878119872797,Simulation & Gaming,6,754–770,PY-RATE ADVENTURES: A 2D Platform Serious Game for Learning the Basic Concepts of Programming With Python,https://doi-org.crai.referencistas.com/10.1177/1046878119872797,50,2019j,
article,doi:10.1177/0266382120968057,"With the development of the 4th Industrial Revolution (4th IR), its emerging technologies and skills; there is a mismatch between 4th IR, and the skills needed by information professionals to survive. This paper bridges the gap based on the skills needed to survive and provide possible solutions to challenges faced by information professionals, which will in turn help to reduce the number of unemployed, semi-employed, non-employed, and provide economic empowerment among information professionals in this new revolution. Information professionals should adopt the missing middle model/techniques in organization which asserts that robots, by and large, will not be taking our jobs; instead, human Machine collaboration will reconfigure some of our work, making and make human skills more unique and important than ever.",Lateef Ayinde and Hal Kirkwood,10.1177/0266382120968057,https://doi-org.crai.referencistas.com/10.1177/0266382120968057,Business Information Review,4,142–153,Rethinking the roles and skills of information professionals in the 4th Industrial Revolution,https://doi-org.crai.referencistas.com/10.1177/0266382120968057,37,2020a,
article,doi:10.1177/089443902237317,"There has been significant recent interest in Agent Based Modeling in many social sciences including economics, sociology, anthropology, political science, and game theory. This article describes three problems that need to be addressed in order for such models to become effective tools for formulating new social theory and informing policy debates and suggests approaches to meeting them. These issues are computational epistemology, research methodology, and software technology. These innovations augment Agent Based Modeling to create an effective new tool base to help better understand complex social systems.",Steven Bankes and Robert Lempert and Steven Popper,10.1177/089443902237317,https://doi-org.crai.referencistas.com/10.1177/089443902237317,Social Science Computer Review,4,377–388,"Making Computational Social Science Effective: Epistemology, Methodology, and Technology",https://doi-org.crai.referencistas.com/10.1177/089443902237317,20,2002b,
article,doi:10.1080/02103702.2019.1604022,"The purpose of the present study was to examine the structure and development of algebraic thinking across multiple dimensions. An algebraic thinking test was administered to 803 students aged 10–13 years old. One hundred and one students of different performance outcomes in the algebraic thinking test participated in semi-structured clinical interviews in order to develop further insights into students’ strategies and difficulties. The results confirmed the multifaceted nature of algebraic thinking and showed that algebraic thinking consists of three aspects: reasoning about covariation, generalization of arithmetic properties and abilities directly related to algebraic syntax. Each one of these aspects is composed of specific algebraic thinking abilities, such as modelling relations using algebraic symbols. Four groups of students of different algebraic thinking profiles were identified: ‘pre-algebraic’, ‘protoalgebraic-procedural’, ‘relational-symbolic algebraic thinking’ and ‘structural-global algebraic thinking’. The results also supported the presence of a consistent trend in the difficulty level across the algebraic thinking abilities, which suggests a specific developmental trend from a more procedural perspective of algebraic thinking to a more structural one.",Marilena-Barbara Chrysostomou and Constantinos Christou,10.1080/02103702.2019.1604022,https://doi-org.crai.referencistas.com/10.1080/02103702.2019.1604022,Journal for the Study of Education and Development,3,721–781,Analysing the notion of algebraic thinking based on empirical evidence / Un análisis del concepto de pensamiento algebraico basado en evidencia empírica,https://doi-org.crai.referencistas.com/10.1080/02103702.2019.1604022,42,2019c,
article,doi:10.1177/14780771221120576,"The space layout problem encompasses challenges that rely on a diverse range of contexts regarding urban planning and architectural design, during the traditional design phases which require immense effort and time for the evaluation of the spatial elements’ characteristic needs. In order to eliminate the burden of considering all multidimensional design aspects at the same time, this research presents a three-bodied computational method for locating the spaces of the given architectural design program in a project site, according to the defined list of design objectives and criteria. Besides the determination of the layout according to the requirements of the spatial elements, this research proposes an integration of the space syntax theory’s analytical compounds in terms of Justified Graph Analysis and Integration Values as the fitness criteria for the multi-objective evolutionary optimization in the computational model. To satisfy the integrity levels of each various characterized element within site organization, that are implied inherently by the architectural design program and generate a sustainable space network layout for the project site.",Selen Cicek and Gozde Damla Turhan,10.1177/14780771221120576,https://doi-org.crai.referencistas.com/10.1177/14780771221120576,International Journal of Architectural Computing,3,610–629,Computational generation of a spatial layout through syntactical evaluation and multi-objective evolutionary optimization,https://doi-org.crai.referencistas.com/10.1177/14780771221120576,20,2022d,
article,doi:10.1177/0959354319867392,"We compare three theoretical frameworks for pursuing explanatory integration in psychiatry: a new dimensional framework grounded in the notion of computational phenotype, a mechanistic framework, and a network of symptoms framework. Considering the phenomenon of alcoholism, we argue that the dimensional framework is the best for effectively integrating computational and mechanistic explanations with phenomenological analyses.",Matteo Colombo and Andreas Heinz,10.1177/0959354319867392,https://doi-org.crai.referencistas.com/10.1177/0959354319867392,Theory & Psychology,5,697–718,"Explanatory integration, computational phenotypes, and dimensional psychiatry: The case of alcohol use disorder",https://doi-org.crai.referencistas.com/10.1177/0959354319867392,29,2019e,
article,doi:10.1177/1075547014556540,"Parallel advances in communication and visualization technologies have enabled the study and visualization of human behavior at a scale and level of detail never before possible. Nowhere are these advances more evident than within the emerging field of computational social science. Using Adamic and Glance’s image of the political blogosphere as an example and social representations theory as a guiding framework, we explore how computational social science visualizations may aid and complicate public understanding of this new science. We conclude with a discussion of best practices for the production and reuse of computational social science images for public consumption.",Brooke Foucault Welles and Isabel Meirelles,10.1177/1075547014556540,https://doi-org.crai.referencistas.com/10.1177/1075547014556540,Science Communication,1,34–58,Visualizing Computational Social Science: The Multiple Lives of a Complex Image,https://doi-org.crai.referencistas.com/10.1177/1075547014556540,37,2015f,
article,doi:10.1177/0018720819829949,"Objective: We developed a computational model of the effects of sleep deprivation on the vigilance decrement by employing the methods of system dynamics modeling. Background: Situations that require sustained attention for a prolonged duration can cause a decline in cognitive performance, the so-called vigilance decrement. One factor that should influence the vigilance decrement is fatigue in the form of sleep deprivation. Method: We employed the methods of system dynamics modeling (numerical-integration techniques for modeling complex feedback systems) to create a computational model of the vigilance decrement. We then simulated the computational effects of sleep deprivation on the behavior of that model, using empirical data obtained from the literature for calibrating such effects. Results: Sleep deprivation of 2 hr over a 14-day period should produce an additional decline of 9% in detection performance over that found with the typical vigilance decrement, whereas 4 hr of sleep deprivation over 14 days should produce an additional decline of 14% in detection performance. Conclusion: With respect to dual-process theory, it is through its deleterious effects on analytical cognition that sleep deprivation should impact the vigilance decrement. Application: Such computational modeling may be advantageous for human-machine teaming by theoretically allowing a future autonomous software agent to anticipate the decline of human performance and compensate accordingly.",Robert Earl Patterson and Darrell Lochtefeld and Kathleen G. Larson and Amanda Christensen-Salem,10.1177/0018720819829949,https://doi-org.crai.referencistas.com/10.1177/0018720819829949,Human Factors,7,1099–1111,Computational Modeling of the Effects of Sleep Deprivation on the Vigilance Decrement,https://doi-org.crai.referencistas.com/10.1177/0018720819829949,61,2019g,PMID:30908091
article,doi:10.1177/1475921707081975,"Corrosion greatly affects the integrity of many engineering structures, such as bridges, pipelines, nuclear reactors, and aircraft. This study provides an overview of the computational intelligence methods developed for the corrosion damage assessment of aerospace materials and structures. Specifically, cellular automata modeling of corrosion pit initiation and growth, wavelet based image processing methods for corrosion damage assessment, and artificial neural networks (ANNs) for material loss and residual strength predictions. In addition, ANN based prediction of life due to corrosion-fatigue conditions are considered and presented. Results obtained from selected computational intelligence methods are compared to the existing alternate solutions and experimental data. The results presented illustrate the feasibility of computational intelligence methods for modeling and assessing the corrosion health of aging aircraft structures and materials.",Ramana M. Pidaparti,10.1177/1475921707081975,https://doi-org.crai.referencistas.com/10.1177/1475921707081975,Structural Health Monitoring,3,245–259,Structural Corrosion Health Assessment using Computational Intelligence Methods,https://doi-org.crai.referencistas.com/10.1177/1475921707081975,6,2007h,
article,doi:10.1177/14614448221122212,"Digital trace data and computational methods are increasingly being used by researchers to study mental health phenomena (i.e. psychopathology and well-being) in social media. Computer-assisted mental health research is not simply a continuation of previous studies, but rather raises ethical, conceptual and methodological issues that are critical to behavioural science but have not yet been systematically explored. Based on a systematic review of n = 147 studies, we reveal a multidisciplinary field of research that has grown immensely since 2010, spanning the humanities, social sciences, and engineering. We find that a substantial majority of studies in our sample lack a standardized form of ethical consideration, focus on specific constructs and have a rather narrow focus on specific social media platforms. Based on our findings, we discuss how computational elements have influenced mental health research, highlight academic gaps and suggest promising directions for future studies.",Max Schindler and Emese Domahidi,10.1177/14614448221122212,https://doi-org.crai.referencistas.com/10.1177/14614448221122212,New Media & Society,10,2781–2799,The computational turn in online mental health research: A systematic review,https://doi-org.crai.referencistas.com/10.1177/14614448221122212,25,2023i,
article,doi:10.1177/1046878119872797,"Background. Learning programming is a cognitively demanding field of study accompanied with various difficulties. Although there is a high demand in the market for programmers, software analysts and engineers, a high dropout rate is recorded in relevant fields of study. Serious games are a promising means of engaging students in learning programming by giving them more incentives and making the process of learning programming concepts and languages more entertaining. Aim. This article introduces a new serious game called PY-RATE ADVENTURES, which aims to assist young students in their introduction to the basic programming concepts using Python. The game does not have any prerequisites and is suitable for players with no previous knowledge of programming. This article aims to present important information regarding the analysis, design and pilot evaluation of PY-RATE ADVENTURES. Method. The game was evaluated by 31 people that had recently graduated or were students of an Interdepartmental Programme of Postgraduate Studies in Information Systems. The participants voluntarily played the game and answered a questionnaire based on the MEEGA+ model, after their hands on experience with the game. This questionnaire’s purpose was to evaluate PY-RATE ADVENTURES in terms of perceived player experience and short-term learning. Results. The participants positively evaluated the game almost in all the elements of player experience. Furthermore, the majority of the users consider that the game helped them to learn basic programming concepts in Python and stated that they would prefer to learn programming with this game rather than other teaching methods. Conclusion. The positive results of the pilot evaluation give us the motivation to proceed and evaluate the game with students in secondary education, in order to extract stronger and generalisable conclusions regarding the impact of the game as an educational tool for learning programming concepts.",Grigorios Sideris and Stelios Xinogalos,10.1177/1046878119872797,https://doi-org.crai.referencistas.com/10.1177/1046878119872797,Simulation & Gaming,6,754–770,PY-RATE ADVENTURES: A 2D Platform Serious Game for Learning the Basic Concepts of Programming With Python,https://doi-org.crai.referencistas.com/10.1177/1046878119872797,50,2019j,
article,doi:10.1177/0735633120940954,"Computational Thinking (CT) and creativity are considered two vital skills for the 21st century that should be incorporated into future curricula around the world. We studied the relationship between these two constructs while focusing on learners’ personal characteristics. Two types of creativity were examined: creative thinking and computational creativity. The research was conducted among 174 middle school students from Spain. Data collected using a standardized creativity test (Torrance’s TTCT) were triangulated with data drawn from students’ log files that documented their activity in a game-based learning environment for CT (Kodetu). We found some interesting associations between CT and the two constructs of creativity. These associations shed light on positive associations between each of the two creativity constructs and CT acquisition, as well as between the two creativity constructs themselves. Additionally, we highlight differences between boys and girls, as girls were found to be more creative on both creativity measures. Other differences associated with school affiliation, prior coding knowledge, and technology affinity are also discussed.",Rotem Israel-Fishelson and Arnon Hershkovitz and Andoni Eguíluz and Pablo Garaizar and Mariluz Guenaga,10.1177/0735633120940954,https://doi-org.crai.referencistas.com/10.1177/0735633120940954,Journal of Educational Computing Research,8,1415–1447,The Associations Between Computational Thinking and Creativity: The Role of Personal Characteristics,https://doi-org.crai.referencistas.com/10.1177/0735633120940954,58,2021a,
article,doi:10.1177/0735633120973429,"Creativity and Computational Thinking (CT) have been both extensively researched in recent years. However, the associations between them are still not fully understood despite their recognition as essential competencies for the digital age. This study looks to bridge this gap by examining the association between CT and two types of creativity, i.e., Creative Thinking and Computational Creativity. The research was conducted among 124 middle school students from Spain, who were divided into control and experimental groups; the intervention included an explicit encouragement to be as creative as possible (i.e., to submit multiple correct solutions) in a given learning task. Data were analyzed from a standardized creativity test (Torrance’s TTCT) and cross-referenced with log files that documented the students’ activities in the Kodetu game-based learning environment. Our research findings indicate some interesting associations between CT and Creativity. First, we found that creativity contributes to CT. Second, we found that CT is transferable across different domains. Finally, we found that Computational Creativity can develop and improve over time.",Rotem Israel-Fishelson and Arnon Hershkovitz and Andoni Eguíluz and Pablo Garaizar and Mariluz Guenaga,10.1177/0735633120973429,https://doi-org.crai.referencistas.com/10.1177/0735633120973429,Journal of Educational Computing Research,5,926–959,A Log-Based Analysis of the Associations Between Creativity and Computational Thinking,https://doi-org.crai.referencistas.com/10.1177/0735633120973429,59,2021b,
article,doi:10.1177/07356331211027387,"There are increasing calls to introduce computational thinking in schools; the arguments in favor call upon research suggesting that even kindergarten children can successfully engage in coding. This contribution presents a cross-sectional study examining the coding practices and computational thinking of fifty-one primary school children using the ScratchJr software; children were organized in two cohorts (Cohort 1: 6–9 years old; Cohort 2: 10–12 years old). Each cohort participated in a six-hour intervention, as part of a four-day summer club. During the intervention children were introduced to ScratchJr and were asked to collaboratively design a digital story about environmental waste management actions, thus adopting a disciplinary perspective to computational thinking. Data analyses examined children’s final artifacts, in terms of coding practices and the level of computational thinking demonstrated by each cohort. Furthermore, analysis of selected groups’ storyboard interviews was used to shed light on differences between the two cohorts. Results are presented and contrasted across the two age cohorts via a developmental perspective. The findings of this study can be useful in considering the instructional support that is necessary to scaffold the development of primary school children’s coding practices and computational thinking.",Eleni A. Kyza and Yiannis Georgiou and Andria Agesilaou and Markos Souropetsis,10.1177/07356331211027387,https://doi-org.crai.referencistas.com/10.1177/07356331211027387,Journal of Educational Computing Research,1,220–257,A Cross-Sectional Study Investigating Primary School Children’s Coding Practices and Computational Thinking Using ScratchJr,https://doi-org.crai.referencistas.com/10.1177/07356331211027387,60,2022c,
article,doi:10.1177/07356331211043547,"As a dynamic and multifaceted construct, computational thinking (CT) has proven to be challenging to conceptualize and assess, which impedes the development of a workable ontology framework. To address this issue, the current article describes a novel approach towards understanding the ontological aspects of CT by using text mining and graph-theoretic techniques to elucidate teachers’ perspectives collected in an online survey (N = 105). In particular, a hierarchical cluster analysis, a knowledge representation method, was applied to identify sub-groups in CT conceptualization and assessment amongst teachers. Five clusters in conceptualization and two clusters in assessment were identified; several relevant and distinct themes were also extracted. The results suggested that teachers attributed CT as a competence domain, relevant in the problem- solving context, as well as applicable and transferrable to various disciplines. The results also shed light on the importance of using multiple approaches to assess the diversity of CT. Overall, the findings collectively contributed to a comprehensive and multi-perspective representation of CT that refine both theory and practice. The methodology employed in this article has suggested a minor but significant step towards addressing the quintessential questions of “what is CT?” and “how is it evidenced?”.",Rina P.Y. Lai,10.1177/07356331211043547,https://doi-org.crai.referencistas.com/10.1177/07356331211043547,Journal of Educational Computing Research,3,661–695,Teachers’ Ontological Perspectives of Computational Thinking and Assessment: A Text Mining Approach,https://doi-org.crai.referencistas.com/10.1177/07356331211043547,60,2022d,
article,doi:10.1177/07356331241254575,"In the context of digital technologies, computational thinking (CT) is considered a key competence of primary school teachers. However, assessment tools to measure in-service teachers’ CT competence are rare. The current study explains the design, development, and validation of a scale to determine the in-service teachers’ mastery level of their Computational Thinking Competence (CTC) in the Chinese context. The validity and reliability of the scale have been studied by conducting exploratory factor analysis (EFA), confirmatory factor analysis (CFA) and calculating internal consistency coefficients. The sample of this study consisted of 631 in-service teachers from different Chinese primary schools (EFA N = 189; CFA N = 442). The 31-item scale mirrors five factors: cognitive knowledge of CT, practices and skills of CT, attitudes and perspectives of CT, CT teaching design, and CT teaching implementation. The discussion of the results looks at the future use of the CT scale in Chinese educational settings that mirror a specific national education policy, talent demand, and educational culture.",Xinlei Li and Guoyuan Sang and Martin Valcke and Johan van Braak,10.1177/07356331241254575,https://doi-org.crai.referencistas.com/10.1177/07356331241254575,Journal of Educational Computing Research,6,1538–1567,The Development of an Assessment Scale for Computational Thinking Competence of In-Service Primary School Teachers,https://doi-org.crai.referencistas.com/10.1177/07356331241254575,62,2024e,
article,doi:10.1177/07356331221100740,"This meta-analysis determined game-based learning’s (GBL) overall effect on students’ computational thinking (CT) and tested for moderators, using 28 effect sizes from 24 studies of 2,134 participants. The random effects model results showed that GBL had a significant positive overall effect on students’ CT (g = 0.677, 95% confidence interval 0.532–0.821) with significant heterogeneity among effect sizes. Among game types, role-playing yielded the largest GBL effect size, followed by action, puzzles, and adventures. Moreover, the effect of GBL on CT was weaker among students in countries that were more individualistic than others. Lastly, interventions between four hours and one week showed the largest GBL effect size, followed by those over four weeks, up to four hours, and between one week and four weeks.",Zhuotao Lu and Ming M. Chiu and Yunhuo Cui and Weijie Mao and Hao Lei,10.1177/07356331221100740,https://doi-org.crai.referencistas.com/10.1177/07356331221100740,Journal of Educational Computing Research,1,235–256,Effects of Game-Based Learning on Students’ Computational Thinking: A Meta-Analysis,https://doi-org.crai.referencistas.com/10.1177/07356331221100740,61,2023f,
article,doi:10.1177/0735633120967315,"This paper examines a method which can be used by instructors pursuing innovative methods for language teaching, which expands learners’ motivation in second language learning. Computational thinking (CT) is a problem-solving skill which can motivate students’ English language learning. Designing a learning activity which integrates CT into English language learning has been considered in only a few academic studies. This study aimed to explore whether integrating CT into English language learning can be useful for improving learners’ motivation and performance. The method of “present, practice, and produce” was applied as a method of presenting computational thinking in the English language learning classroom. Fifty-two elementary school students (52) participated in the experimental study. Following an experimental design, data were collected and analyzed from a combination of knowledge test scores, storytelling, motivation, and anxiety surveys. The experimental results indicate that the CT strategy improves students’ language learning and raises their motivation in the two dimensions of extrinsic and intrinsic goal orientation. These results imply the positive effect of CT strategy on strengthening problem-solving skills of students participating in digital storytelling and increases their motivation and performance in English language learning.",Nadia Parsazadeh and Pei-Yu Cheng and Ting-Ting Wu and Yueh-Min Huang,10.1177/0735633120967315,https://doi-org.crai.referencistas.com/10.1177/0735633120967315,Journal of Educational Computing Research,3,470–495,Integrating Computational Thinking Concept Into Digital Storytelling to Improve Learners’ Motivation and Performance,https://doi-org.crai.referencistas.com/10.1177/0735633120967315,59,2021g,
article,doi:10.1177/07356331241249956,"In the past decade, Computational Thinking (CT) education has received growing attention from researchers. Although many reviews have provided synthesized information on CT teaching and learning, few have paid particular attention to collaborative learning (CL) strategies. CL has been widely implemented in CT classes and has become the most popular pedagogy among educators. Therefore, a systematic review of CL in CT classes would provide practical guidance on teaching strategies to enhance CT interventions and improve the quality of teaching and learning, ultimately benefiting students’ CT skills development. To address this gap, this study examined 43 empirical studies that have applied CL strategies, ranging from 2006 to 2022. Several findings were revealed in the analysis. First, a wide range of theories and frameworks were applied to inform research questions, pedagogical design, and research methodologies. Second, despite the acknowledged importance of group composition in effective CL, a large number of studies did not provide details on how the students were grouped. Third, six types of CL activities and instructional designs have been identified in CT classrooms. The synthesized information provides valuable insights that can inform future research directions and guide the design and implementation of CL activities in future CT classes.",Stella Xin Yin and Dion Hoe-Lian Goh and Choon Lang Quek,10.1177/07356331241249956,https://doi-org.crai.referencistas.com/10.1177/07356331241249956,Journal of Educational Computing Research,6,1440–1474,Collaborative Learning in K-12 Computational Thinking Education: A Systematic Review,https://doi-org.crai.referencistas.com/10.1177/07356331241249956,62,2024h,
article,doi:10.1177/0735633121994070,"Due to the interdisciplinary nature of robotics, more and more attention has been paid to its effectiveness in the field of education in recent years. This systematic review evaluated existing studies in improving K-12 students’ computational thinking and STEM attitudes. Research articles published between 2010 and 2019 were collated from major databases according to six criteria, and 17 studies were eligible. A meta-analysis was conducted to evaluate the effectiveness of educational robots in terms of standardized mean differences (SMD) or mean differences (MD) of test scores as outcome measures. The overall effect size was medium (SMD = 0.46, 95% CI: 0.23–0.69). Subgroup analysis found that some groups to have better effectiveness. Specifically, the effect of STEM attitudes (SMD = 0.01) was smaller than computational thinking (SMD = 0.48). Educational robots had more significant effect on boys (MD = 0.39) than girls (MD = 0.27). The effect in primary school (SMD = 0.27) was higher than in middle school (SMD = 0.04), and the effect was great on short-term instruction with educational robots (SMD = 0.35). Based on these results, the study makes some recommendations for educators about strengthening the influence of educational robots on STEM attitudes, improving the persistence of their learning effects, and further exploring their application models.",Yanjun Zhang and Ronghua Luo and Yijin Zhu and Yuan Yin,10.1177/0735633121994070,https://doi-org.crai.referencistas.com/10.1177/0735633121994070,Journal of Educational Computing Research,7,1450–1481,Educational Robots Improve K-12 Students’ Computational Thinking and STEM Attitudes: Systematic Review,https://doi-org.crai.referencistas.com/10.1177/0735633121994070,59,2021i,
article,doi:10.1177/0735633115608444,"Computational thinking (CT) is a fundamental skill for students, and assessment is a critical factor in education. However, there is a lack of effective approaches to CT assessment. Therefore, we designed the Three-Dimensional Integrated Assessment (TDIA) framework in this article. The TDIA has two aims: one was to integrate three dimensions (directionality, openness, and process) into the design of effective assessment tasks; and the other was to assess comprehensively the three dimensions of CT including computational concepts, practices, and perspectives. Guided by the TDIA framework, we designed three pairs of tasks: closed forward tasks and closed reverse tasks, semiopen forward tasks and semiopen reverse tasks, and open tasks with a creative design report and open tasks without a creative design report. To further confirm each task’s applicability and its advantages and disadvantages, we conducted a test experiment at the end of the autumn semester in 2014 in a primary school for 3 weeks. The results indicated that (a) the reverse tasks were not more superior than the forward tasks; (b) the semiopen tasks and the open tasks were more effective than the closed tasks, and the semiopen tasks had higher difficulty and discrimination than the others; (c) the self-reports provided a helpful function for learning diagnosis and guidance; (d) the scores had no significant difference between the schoolboys and the schoolgirls in all six tasks; and (e) the six tasks’ difficulty and discrimination were all acceptable, and the semiopen tasks had higher difficulty and discrimination than the others. To effectively apply them, the following suggestions for teachers to design computational tasks are proposed: motivating students’ interest and enthusiasm, incorporating semifinished artifacts, involving learning diagnosis and guidance, and including multiple types of tasks in an assessment.",Baichang Zhong and Qiyun Wang and Jie Chen and Yi Li,10.1177/0735633115608444,https://doi-org.crai.referencistas.com/10.1177/0735633115608444,Journal of Educational Computing Research,4,562–590,An Exploration of Three-Dimensional Integrated Assessment for Computational Thinking,https://doi-org.crai.referencistas.com/10.1177/0735633115608444,53,2016j,
article,doi:10.1177/2053951715622512,"This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm.",Jenna Burrell,10.1177/2053951715622512,https://doi-org.crai.referencistas.com/10.1177/2053951715622512,Big Data & Society,1,2053951715622512,How the machine ‘thinks’: Understanding opacity in machine learning algorithms,https://doi-org.crai.referencistas.com/10.1177/2053951715622512,3,2016a,
article,doi:10.1177/1069397110393894,"Mel Ember was co-Principal Investigator in the Mason-HRAF Joint Project on Eastern Africa, a multiyear project aimed at developing and analyzing advanced computational agent-based models of human societies across 10 countries and 12 ecosystems. A major unsolved challenge in this kind of social science research is to devise a systematic way to compare, contrast, and communicate different models of social dynamics along relevant dimensions and characteristics, given the inherent complexity of most computational agent-based models. This article proposes a viable systematic framework for comparing models and illustrates its application using some of the models that Mel helped inspire and develop as senior project participant.",Claudio Cioffi-Revilla,10.1177/1069397110393894,https://doi-org.crai.referencistas.com/10.1177/1069397110393894,Cross-Cultural Research,2,208–230,Comparing Agent-Based Computational Simulation Models in Cross-Cultural Research,https://doi-org.crai.referencistas.com/10.1177/1069397110393894,45,2011b,
article,doi:10.1177/14614448110130031102,,Adam Fish,10.1177/14614448110130031102,https://doi-org.crai.referencistas.com/10.1177/14614448110130031102,New Media & Society,3,510–513,"Book review: Jaron Lanier, You Are Not a Gadget: A Manifesto. New York: Alfred Knopf, 2010. ix + 224 pp. $24.95 (hbk) ISBN 9780307269645",https://doi-org.crai.referencistas.com/10.1177/14614448110130031102,13,2011c,
article,doi:10.1177/14782103231183485,"The Computer Science (CS) for All national movement is increasingly relying on state-level change to broaden participation in computing. To foster an environment in which all students have opportunities to thrive in CS education, policy action is necessary to help create the learning conditions for success. CS education in California has grown substantially in the last decade, yet opportunity gaps remain for young women and Black, Latinx, and Native American students. Early grassroots efforts to advance equity in computing evolved into the Computer Science for California coalition of K–16 educators, industry leaders, and other equity advocates to promote the growth of equity-minded teaching and learning opportunities in K–12 CS education. New policies at the state level reflect an increasing commitment among Sacramento policymakers to expand CS education. Yet troubling disparities in CS access and success continue to exist between traditionally advantaged students and their historically underserved peers. By drawing on interviews with 20 individuals involved in CS education policy, this study illuminates the contributing factors to recent policy successes and considerations for achieving further progress. Interviewees described the importance of tapping into the values of influential decision makers, educating policymakers about the benefits of CS education, and identifying the problems and solutions that require policy attention. To build the capacity of key policy actors in making informed decisions, this research demonstrates the continued value of providing useful information, developing relationships with policymakers, and creating resources that are easy to consume and understand. The interviews also suggest that attention to funding, disruptions from the COVID-19 pandemic, equity, and ongoing stakeholder support will shape prospects for CS education policy success moving forward.",Julie Flapan and Joel Knudson and Candice Handjojo and Ashley Sunde and Roxana Hadad,10.1177/14782103231183485,https://doi-org.crai.referencistas.com/10.1177/14782103231183485,Policy Futures in Education,0,14782103231183484,Power surge: How a multistakeholder coalition promotes equity in computer science education policy,https://doi-org.crai.referencistas.com/10.1177/14782103231183485,0,2023d,
article,doi:10.1177/1077546318788405,"The complex nature of the tire/road noise generation process makes it difficult to isolate and study each mechanism individually. This paper presents an experimental and numerical investigation of air-borne tire noise generation mechanisms for a realistic tire. Experimentally, a single slot is cut into the tire and the noise data are measured and studied. Air-borne noise is isolated by filling the slot with foam and comparing the resulting frequency spectra. Numerically, a previously developed computational fluid dynamics tire noise prediction model is employed to predict the air-borne noise for the same tire, under similar operating conditions. A direct comparison between the experimental and computational results is also presented in terms of pressure time traces and spectral characteristics. Comparisons indicate that the computational model is capable of predicting the noise generated by the air pockets in the tire. While providing a deeper understanding of the causes of air-borne noise, this paper also aims to demonstrate the use of a computational tool that can be used to obtain a reasonably accurate prediction of air-borne tire noise.",Prashanta Gautam and Yousof Azizi and Abhilash J. Chandy,10.1177/1077546318788405,https://doi-org.crai.referencistas.com/10.1177/1077546318788405,Journal of Vibration and Control,3,529–537,An experimental and computational investigation of air-borne noise generation mechanisms in tires,https://doi-org.crai.referencistas.com/10.1177/1077546318788405,25,2019e,
article,doi:10.1177/0040517515586162,"A three-dimensional computational model is established to simulate the air flow patterns in the rotor spinning unit of a rotor spinning machine. The effects of rotor speed, rotor diameter and rotor slide wall angle on air flow characteristics and hence yarn properties are investigated. The airstream accelerates from the transfer channel inlet to the outlet. There are velocity differences in both the cross-section and along the transfer channel, causing hooked fibers to straighten. The airstream swirls around the rotor at a high speed. However, vortices that can cause fiber curving and buckling are formed inside the rotor. The effect of rotor speed is significant. There are more vortices near the wall at a lower rotor speed, while too large a rotor speed can lead to an excessive centrifugal force, thus increasing yarn breakages. The rotor diameter affects the flow characteristics in a way similar to that of rotor speed. As a smaller slide wall angle generates higher velocities in the transfer channel and more stable velocities in the rotor groove, a small angle is preferable. Computational modeling has provided a useful insight into the rotor spinning flow pattern, thus it can be used to optimize the rotor design to produce better rotor spun yarn.",HT Lin and YC Zeng and J Wang,10.1177/0040517515586162,https://doi-org.crai.referencistas.com/10.1177/0040517515586162,Textile Research Journal,2,115–126,Computational simulation of air flow in the rotor spinning unit,https://doi-org.crai.referencistas.com/10.1177/0040517515586162,86,2016f,
article,doi:10.1177/0731948719865499,"The purpose of the study was to compare the deficit profiles of two important types of mathematics difficulties. Three cognitive measures (working memory, processing speed, and reasoning), two mathematics measures (numerical facts retrieval and mathematics vocabulary), and reading comprehension were assessed among 237 Chinese fourth-grade students, among whom 28 were classified as students with only computational difficulties (CD), 34 were classified as having only word problem-solving difficulties (WPD), 20 were classified as students with computational and word problem-solving difficulties (CD + WPD), and 43 typically developing (TD) peers. Multivariate analysis showed that, compared with TD, CD was associated with weakness in numerical working memory; WPD was associated with weakness in reading comprehension; both CD and WPD were associated with weakness in mathematics vocabulary. However, CD and WPD did not differ from each other on any of those profiling measures. Implications for understanding mathematics competence and identification of mathematics difficulties are discussed.",Xin Lin and Peng Peng and Hongjing Luo,10.1177/0731948719865499,https://doi-org.crai.referencistas.com/10.1177/0731948719865499,Learning Disability Quarterly,2,110–122,The Deficit Profile of Elementary Students With Computational Difficulties Versus Word Problem-Solving Difficulties,https://doi-org.crai.referencistas.com/10.1177/0731948719865499,44,2021g,
article,doi:10.1177/0954410016671343,"A fluid–structure interaction numerical simulation was performed to investigate the flow field around a flexible flapping wing using an in-house developed computational fluid dynamics/computational structural dynamics solver. The three-dimensional (3D) fluid–structure interaction of the flapping locomotion was predicted by loosely coupling preconditioned Navier–Stokes solutions and non-linear co-rotational structural solutions. The computational structural dynamic solver was specifically developed for highly flexible flapping wings by considering large geometric non-linear characteristics. The high fidelity of the developed methodology was validated by benchmark tests. Then, an analysis of flexible flapping wings was carried out with a specific focus on the unsteady aerodynamic mechanisms and effects of flexion on flexible flapping wings. Results demonstrate that the flexion will introduce different flow fields, and thus vary thrust generation and pressure distribution significantly. In the meanwhile, relationship between flapping frequency and flexion plays an important role on efficiency. Therefore, appropriate combination of frequency and flexion of flexible flapping wings provides higher efficiency. This study may give instruction for further design of flexible flapping wings.",Long Liu and Hongda Li and Haisong Ang and Tianhang Xiao,10.1177/0954410016671343,https://doi-org.crai.referencistas.com/10.1177/0954410016671343,"Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering",1,85–95,Numerical investigation of flexible flapping wings using computational fluid dynamics/computational structural dynamics method,https://doi-org.crai.referencistas.com/10.1177/0954410016671343,232,2018h,
article,doi:10.1177/1059712309342757,"In this article we propose a computational model that describes how observed behavior can influence an observer’s own behavior, including the acquisition of new task descriptions. The sources of influence on our model’s behavior are: beliefs about the world’s possible states and actions causing transitions between them; baseline preferences for certain actions; a variable tendency to infer and share goals in observed behavior; and a variable tendency to act efficiently to reach rewarding states. Acting on these premises, our model is able to replicate key empirical studies of social learning in children and chimpanzees. We demonstrate how a simple artificial system can account for a variety of biological social transfer phenomena, such as goal-inference and over-imitation, by taking into account action constraints and incomplete knowledge about the world dynamics.",Manuel Lopes and Francisco S. Melo and Ben Kenward and José Santos-Victor,10.1177/1059712309342757,https://doi-org.crai.referencistas.com/10.1177/1059712309342757,Adaptive Behavior,6,467–483,A Computational Model of Social-Learning Mechanisms,https://doi-org.crai.referencistas.com/10.1177/1059712309342757,17,2009i,
article,doi:10.1243/095441005X30306,"Abstract Computational fluid dynamics (CFD) simulations of ship airwakes are discussed in this article. CFD is used to simulate the airwakes of landing helicopter assault (LHA) and landing platform dock-17 (LPD-17) classes of ships. The focus is on capturing the massively separated flow from sharp edges of blunt bodies, while ignoring the viscous effects. A parallel, finite-volume flow solver is used with unstructured grids on full-scale ship models for the CFD calculations. Both steady-state and time-accurate results are presented for a wind speed of 15.43 m/s (30 knot) and for six different wind-over-deck angles. The article also reviews other computational and experimental ship airwake research.",N Sezer-Uzol and A Sharma and L N Long,10.1243/095441005X30306,https://doi-org.crai.referencistas.com/10.1243/095441005X30306,"Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering",5,369–392,Computational Fluid Dynamics Simulations of Ship Airwake,https://doi-org.crai.referencistas.com/10.1243/095441005X30306,219,2005j,
article,doi:10.1177/2053951715622512,"This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm.",Jenna Burrell,10.1177/2053951715622512,https://doi-org.crai.referencistas.com/10.1177/2053951715622512,Big Data & Society,1,2053951715622512,How the machine ‘thinks’: Understanding opacity in machine learning algorithms,https://doi-org.crai.referencistas.com/10.1177/2053951715622512,3,2016a,
article,doi:10.1177/20539517221080146,"The size and variation in both meaning-making and populations that characterize much contemporary text data demand research processes that support both discovery, interpretation and measurement. We assess one dominant strategy within the social sciences that takes a computer-led approach to text analysis. The approach is coined computational grounded theory. This strategy, we argue, relies on a set of unwarranted assumptions, namely, that unsupervised models return natural clusters of meaning, that the researcher can understand text with limited immersion and that indirect validation is sufficient for ensuring unbiased and precise measurement. In response to this criticism, we develop a framework that is computer assisted. We argue that our reformulation of computational grounded theory better aligns with the principles within grounded theory, anthropological theory generation and ethnography.",Hjalmar Bang Carlsen and Snorre Ralund,10.1177/20539517221080146,https://doi-org.crai.referencistas.com/10.1177/20539517221080146,Big Data & Society,1,20539517221080144,Computational grounded theory revisited: From computer-led to computer-assisted text analysis,https://doi-org.crai.referencistas.com/10.1177/20539517221080146,9,2022b,
article,doi:10.1177/1069397110393894,"Mel Ember was co-Principal Investigator in the Mason-HRAF Joint Project on Eastern Africa, a multiyear project aimed at developing and analyzing advanced computational agent-based models of human societies across 10 countries and 12 ecosystems. A major unsolved challenge in this kind of social science research is to devise a systematic way to compare, contrast, and communicate different models of social dynamics along relevant dimensions and characteristics, given the inherent complexity of most computational agent-based models. This article proposes a viable systematic framework for comparing models and illustrates its application using some of the models that Mel helped inspire and develop as senior project participant.",Claudio Cioffi-Revilla,10.1177/1069397110393894,https://doi-org.crai.referencistas.com/10.1177/1069397110393894,Cross-Cultural Research,2,208–230,Comparing Agent-Based Computational Simulation Models in Cross-Cultural Research,https://doi-org.crai.referencistas.com/10.1177/1069397110393894,45,2011c,
article,doi:10.1177/20570473241284759,"This article proposes and tests a reproducible framework for a computational method to measure social media-based deliberative discourse by analyzing commentary surrounding the Canadian convoy protests of COVID-19 vaccine mandates and restrictions. Employing a combination of analytic calculations, alongside tools such as Google Perspective and Linguistic Inquiry and Word Count (LIWC), this article assesses the quality of online deliberative discourse using established measures of deliberation including the variables rationality, interactivity, equality, and civility. We propose computational approaches to measuring these variables, and work toward validating our approach by observing correlations between an established computational measure of online deliberation-cognitive complexity. This computational approach is tested using Twitter and Reddit commentary related to the convoy protests that took place in Ottawa, Canada, during February 2022, which influenced the emergence of similar protests around the world. In addition to testing our proposed online deliberative discourse measurement framework, this case study provides insight into the deliberative characteristics of the Twitter and Reddit social media platforms.",Stuart Duncan and Lauren Dwyer and Hanako Smith and Davis Vallesi and Frauke Zeller and Charles Davis,10.1177/20570473241284759,https://doi-org.crai.referencistas.com/10.1177/20570473241284759,Communication and the Public,0,20570473241284760,Toward a computational mixed methods framework to measure online deliberative discourse,https://doi-org.crai.referencistas.com/10.1177/20570473241284759,0,2024d,
article,doi:10.1177/14614448110130031102,,Adam Fish,10.1177/14614448110130031102,https://doi-org.crai.referencistas.com/10.1177/14614448110130031102,New Media & Society,3,510–513,"Book review: Jaron Lanier, You Are Not a Gadget: A Manifesto. New York: Alfred Knopf, 2010. ix + 224 pp. $24.95 (hbk) ISBN 9780307269645",https://doi-org.crai.referencistas.com/10.1177/14614448110130031102,13,2011e,
article,doi:10.1177/14782103231183485,"The Computer Science (CS) for All national movement is increasingly relying on state-level change to broaden participation in computing. To foster an environment in which all students have opportunities to thrive in CS education, policy action is necessary to help create the learning conditions for success. CS education in California has grown substantially in the last decade, yet opportunity gaps remain for young women and Black, Latinx, and Native American students. Early grassroots efforts to advance equity in computing evolved into the Computer Science for California coalition of K–16 educators, industry leaders, and other equity advocates to promote the growth of equity-minded teaching and learning opportunities in K–12 CS education. New policies at the state level reflect an increasing commitment among Sacramento policymakers to expand CS education. Yet troubling disparities in CS access and success continue to exist between traditionally advantaged students and their historically underserved peers. By drawing on interviews with 20 individuals involved in CS education policy, this study illuminates the contributing factors to recent policy successes and considerations for achieving further progress. Interviewees described the importance of tapping into the values of influential decision makers, educating policymakers about the benefits of CS education, and identifying the problems and solutions that require policy attention. To build the capacity of key policy actors in making informed decisions, this research demonstrates the continued value of providing useful information, developing relationships with policymakers, and creating resources that are easy to consume and understand. The interviews also suggest that attention to funding, disruptions from the COVID-19 pandemic, equity, and ongoing stakeholder support will shape prospects for CS education policy success moving forward.",Julie Flapan and Joel Knudson and Candice Handjojo and Ashley Sunde and Roxana Hadad,10.1177/14782103231183485,https://doi-org.crai.referencistas.com/10.1177/14782103231183485,Policy Futures in Education,0,14782103231183484,Power surge: How a multistakeholder coalition promotes equity in computer science education policy,https://doi-org.crai.referencistas.com/10.1177/14782103231183485,0,2023f,
article,doi:10.1177/1077546318788405,"The complex nature of the tire/road noise generation process makes it difficult to isolate and study each mechanism individually. This paper presents an experimental and numerical investigation of air-borne tire noise generation mechanisms for a realistic tire. Experimentally, a single slot is cut into the tire and the noise data are measured and studied. Air-borne noise is isolated by filling the slot with foam and comparing the resulting frequency spectra. Numerically, a previously developed computational fluid dynamics tire noise prediction model is employed to predict the air-borne noise for the same tire, under similar operating conditions. A direct comparison between the experimental and computational results is also presented in terms of pressure time traces and spectral characteristics. Comparisons indicate that the computational model is capable of predicting the noise generated by the air pockets in the tire. While providing a deeper understanding of the causes of air-borne noise, this paper also aims to demonstrate the use of a computational tool that can be used to obtain a reasonably accurate prediction of air-borne tire noise.",Prashanta Gautam and Yousof Azizi and Abhilash J. Chandy,10.1177/1077546318788405,https://doi-org.crai.referencistas.com/10.1177/1077546318788405,Journal of Vibration and Control,3,529–537,An experimental and computational investigation of air-borne noise generation mechanisms in tires,https://doi-org.crai.referencistas.com/10.1177/1077546318788405,25,2019g,
article,doi:10.1177/1059712312445902,"Recent neuroscientific evidence in human and non-human primates indicates that the regions that become active during motor execution and motor observation overlap extensively in the cerebral cortex. This suggests that to observe an action, these primates employ their motor and somatosensation areas in order to simulate it internally. In line with this finding, in the current paper, we examine relevant neuroscientific evidence in order to design a computational agent that can facilitate observational learning of reaching movements. For this reason, we develop a novel motor control system, inspired from contemporary theories of motor control, and demonstrate how it can be used during observation to facilitate learning, without the active involvement of the agent’s body. Our results show that novel motor skills can be acquired only by observation, by optimizing the peripheral components of the agent’s motion.",Emmanouil Hourdakis and Panos Trahanias,10.1177/1059712312445902,https://doi-org.crai.referencistas.com/10.1177/1059712312445902,Adaptive Behavior,4,237–256,Computational modeling of observational learning inspired by the cortical underpinnings of human primates,https://doi-org.crai.referencistas.com/10.1177/1059712312445902,20,2012h,
article,doi:10.1177/0731948719865499,"The purpose of the study was to compare the deficit profiles of two important types of mathematics difficulties. Three cognitive measures (working memory, processing speed, and reasoning), two mathematics measures (numerical facts retrieval and mathematics vocabulary), and reading comprehension were assessed among 237 Chinese fourth-grade students, among whom 28 were classified as students with only computational difficulties (CD), 34 were classified as having only word problem-solving difficulties (WPD), 20 were classified as students with computational and word problem-solving difficulties (CD + WPD), and 43 typically developing (TD) peers. Multivariate analysis showed that, compared with TD, CD was associated with weakness in numerical working memory; WPD was associated with weakness in reading comprehension; both CD and WPD were associated with weakness in mathematics vocabulary. However, CD and WPD did not differ from each other on any of those profiling measures. Implications for understanding mathematics competence and identification of mathematics difficulties are discussed.",Xin Lin and Peng Peng and Hongjing Luo,10.1177/0731948719865499,https://doi-org.crai.referencistas.com/10.1177/0731948719865499,Learning Disability Quarterly,2,110–122,The Deficit Profile of Elementary Students With Computational Difficulties Versus Word Problem-Solving Difficulties,https://doi-org.crai.referencistas.com/10.1177/0731948719865499,44,2021i,
article,doi:10.4137/BBI.S16803,"RNA-binding proteins (RBPs) are at the core of post-transcriptional regulation and thus of gene expression control at the RNA level. One of the principal challenges in the field of gene expression regulation is to understand RBPs mechanism of action. As a result of recent evolution of experimental techniques, it is now possible to obtain the RNA regions recognized by RBPs on a transcriptome-wide scale. In fact, CLIP-seq protocols use the joint action of CLIP, crosslinking immunoprecipitation, and high-throughput sequencing to recover the transcriptome-wide set of interaction regions for a particular protein. Nevertheless, computational methods are necessary to process CLIP-seq experimental data and are a key to advancement in the understanding of gene regulatory mechanisms. Considering the importance of computational methods in this area, we present a review of the current status of computational approaches used and proposed for CLIP-seq data.",Paula H. Reyes-Herrera and Elisa Ficarra,10.4137/BBI.S16803,https://doi-org.crai.referencistas.com/10.4137/BBI.S16803,Bioinformatics and Biology Insights, ,BBI.S16803,Computational Methods for CLIP-Seq Data Processing,https://doi-org.crai.referencistas.com/10.4137/BBI.S16803,8,2014j,PMID:25336930
article,doi:10.1243/1350650981542236,"Abstract This paper demonstrates the suitability of using computational fluid dynamics software for solving steady state hydrodynamic lubrication problems pertaining to slider bearings, step bearings, journal bearings and squeeze-film dampers under conditions of constant unidirectional or rotating loading. The relevance of the inertia and viscous terms which are neglected in the derivation of the Reynolds equation are briefly investigated for the above bearing and damper configurations and it is shown that the neglected viscous terms have negligible effect whereas the inertia effect predictions agree reasonably well with those reported in the literature.",P. Y. P. Chen and E. J. Hahn,10.1243/1350650981542236,https://doi-org.crai.referencistas.com/10.1243/1350650981542236,"Proceedings of the Institution of Mechanical Engineers, Part J: Journal of Engineering Tribology",6,427–436,Use of computational fluid dynamics in hydrodynamic lubrication,https://doi-org.crai.referencistas.com/10.1243/1350650981542236,212,1998a,
article,doi:10.1177/0894439320914505,"Anxiety is a pervasive emotional state that tends to arise in situations involving uncertainty due partly to social and contextual issues including competition, economic disparity, and social insecurity. Thus, distribution of aggregate emotions, such as in anxiety, may reveal an important picture of otherwise invisible social processes in which individuals interact with local and global opportunities, constraints, and potential threats. The aim of this study is to present a computational approach to the dynamic distribution of anxiety extracted from natural language expressions of users of Twitter, a popular global social media platform. We develop an unsupervised machine learning procedure based on a naive Bayes model to classify contents of anxiety, estimate the degree of anxiety, and construct a geographic map of spatiotemporal distribution of anxiety. To validate our mapping results, a multilevel statistical analysis was performed to examine how anxiety distribution is correlated with other district-level sociodemographic statistics such as rates of birth and early divorce. Implications for further research and extension are discussed.",Yong Suk Choi and Hansung Kim and Dongyoung Sohn,10.1177/0894439320914505,https://doi-org.crai.referencistas.com/10.1177/0894439320914505,Social Science Computer Review,3,598–617,Mapping Social Distress: A Computational Approach to Spatiotemporal Distribution of Anxiety,https://doi-org.crai.referencistas.com/10.1177/0894439320914505,40,2022b,
article,doi:10.1177/1046878117748175,"Background. Educational games are nowadays used for facilitating the teaching and learning process of various subjects. History is one of the subjects that simulations and games are used for promoting active learning and supporting students in comprehending various history-related subjects. Aim. This article reports on a new educational game on Greek mythology, called MYTH TROUBLES, designed and developed from scratch with the aim of supporting primary school students in studying Greek mythology and raising their interest on the subject of history. Method. The article presents the educational rationale and design of MYTH TROUBLES in the context of an educational games design model proposed in the literature. Since the game was implemented with the platform of Scratch and it is available online both for students (or anyone interested in Greek Mythology) and game developers, some information for its implementation is also provided. The results of a pilot evaluation of MYTH TROUBLES with the help of 21 experienced school teachers are presented, along with proposals for improvement and extension of the game. Results. Teachers evaluated positively MYTH TROUBLES in terms of acceptability, usability, utility as an educational tool, as well as its interface and game play and expressed their willingness to use it in the classroom. Conclusions. MYTH TROUBLES is considered appropriate by teachers for supporting the teaching and learning of Greek mythology and assessing its educational value in class is the next step. Scratch is appropriate for implementing such educational games and sharing them with interested players and game developers.",Olympia Evangelopoulou and Stelios Xinogalos,10.1177/1046878117748175,https://doi-org.crai.referencistas.com/10.1177/1046878117748175,Simulation & Gaming,1,71–91,MYTH TROUBLES: An Open-Source Educational Game in Scratch for Greek Mythology,https://doi-org.crai.referencistas.com/10.1177/1046878117748175,49,2018c,
article,doi:10.3233/FI-2013-813,"We study the complexity of Bongartz’s algorithm for determining a maximal common direct summand of a pair of modules M, N over k-algebra Λ; in particular, we estimate its pessimistic computational complexity 𝒪(rm6n2(n + m log n)), where m = dimkM ≤ n = dimkN and r is a number of common indecomposable direct summands of M and N. We improve the algorithm to another one of complexity 𝒪(rm4n2(n+m log m)) and we show that it applies to the isomorphism problem (having at least an exponential complexity in a direct approach). Moreover, we discuss a performance of both algorithms in practice and show that the “average” complexity is much lower, especially for the improved one (which becomes a part of QPA package for GAP computer algebra system).",Andrzej Mróz,10.3233/FI-2013-813,https://doi-org.crai.referencistas.com/10.3233/FI-2013-813,Fundamenta Informaticae,3,317–329,On the Computational Complexity of Bongartz’s Algorithm,https://doi-org.crai.referencistas.com/10.3233/FI-2013-813,123,2013d,
article,doi:10.1177/1478077116638924,"In the current computer-aided architectural design education, students do not necessarily need to be taught to use more digital tools, but need to be introduced to the possibilities of designing their own digital tools. Designing the original tools with the assistance of educational-use environment for computational fluid dynamics programming improves the capability of the students to estimate the flows around architectures based on the mathematical background and the actual program. The authors have developed Educational Library for Fluid as an educational-use environment for computational fluid dynamics programming and ran the workshop where the students majoring in computer-aided architectural design tried to design computational fluid dynamics tools with Educational Library for Fluid. In this article, the details of Educational Library for Fluid and the results of the workshop are being reported. In addition, the key points of computational fluid dynamics education that the authors learned through the experience of the workshop are shared.",Akito Nakano and John N Bohn and Akira Wakita,10.1177/1478077116638924,https://doi-org.crai.referencistas.com/10.1177/1478077116638924,International Journal of Architectural Computing,2,119–130,Development of educational-use computational fluid dynamics programming environment and workshop,https://doi-org.crai.referencistas.com/10.1177/1478077116638924,14,2016e,
article,doi:10.1260/147807707783600771,"In historic design conventions geometry has traditionally promoted descriptive manifestations of form. Beyond the realm of geometry, the concept of performance which may inform such manifestations also carries important potential for design generation. This work explores the relation between geometry and performance from a computational-geometry perspective. It does so by revisiting certain analytical tools offered in most of today’s 3-D modelers which support the evaluation of any generated surface geometry specifically curvature and draft angle analysis. It is demonstrated that these tools can be reconstructed with added functionality assigning 3-D geometrical features informed by structural and environmental performance respectively. In the examples illustrated surface thickness (as a function of structural performance) is assigned to curvature values, and transparency (as a function of light performance) is assigned to light analysis values. In a broader scope this work promotes a methodology of performance-informed form generation by means of computational geometry. Vector and tensor math was exploited to reconstruct existing analytical tools adapted to function as design generators.",Neri Oxman,10.1260/147807707783600771,https://doi-org.crai.referencistas.com/10.1260/147807707783600771,International Journal of Architectural Computing,4,663–684,Get Real towards Performance-Driven Computational Geometry,https://doi-org.crai.referencistas.com/10.1260/147807707783600771,5,2007f,
article,doi:10.1177/1094342006074849,"In the economic-based computational grids we need effective schedulers not only to minimize the makespan but also to minimize the costs that are spent for the execution of the jobs. In this work, a novel economy driven job scheduling heuristic is proposed and a simulation application is developed by using GridSim toolkit to investigate the performance of the heuristic. The simulation-based experiments demonstrate the effectiveness of the proposed heuristic both in terms of parameter sweep and sequential workflow type of applications.",Omer Ozan Sonmez and Attila Gursoy,10.1177/1094342006074849,https://doi-org.crai.referencistas.com/10.1177/1094342006074849,The International Journal of High Performance Computing Applications,1,21–29,A Novel Economic-Based Scheduling Heuristic for Computational Grids,https://doi-org.crai.referencistas.com/10.1177/1094342006074849,21,2007g,
article,doi:10.1177/00491241221122596,"This article presents a computational approach to examining immigrant incorporation through shifts in the social “mainstream.” Analyzing a historical corpus of American etiquette books, texts from 1922–2017 describing social norms, we identify mainstream shifts related to long-standing groups which once were and may currently still be seen as immigrant outsiders in the United States: Catholic, Chinese, Irish, Italian, Jewish, Mexican, and Muslim groups. The analysis takes a computational grounded theory approach, combining qualitative readings and computational text analyses. Using word embeddings, we operationalize the chosen groups as focal group concepts. We extract sections of text that are salient to the focal group concepts to create group-specific text corpora. Two computational approaches make it possible to examine mainstream shifts in these corpora. First, we use sentiment analysis to observe the positive sentiment in each corpus and its change over time. Second, we observe changes in each corpus’s position on a semantic dimension represented by the poles of “strange” and “normal.” The results indicate mainstream shifts through increases in positive sentiment and movement from strange to normal over time for most of the group-specific corpora. These research techniques can be adapted to other studies of social sentiment and symbolic inclusion.",Andrea Voyer and Zachary D. Kline and Madison Danton and Tatiana Volkova,10.1177/00491241221122596,https://doi-org.crai.referencistas.com/10.1177/00491241221122596,Sociological Methods & Research,4,1540–1579,From Strange to Normal: Computational Approaches to Examining Immigrant Incorporation Through Shifts in the Mainstream,https://doi-org.crai.referencistas.com/10.1177/00491241221122596,51,2022h,
article,doi:10.1177/026119290903700509,"For over a decade, the United States Food and Drug Administration (US FDA) has been engaged in the applied research, development, and evaluation of computational toxicology methods used to support the safety evaluation of a diverse set of regulated products. The basis for evaluating computational toxicology methods is multi-factorial, including the potential for increased efficiency, reduction in the numbers of animals used, lower costs, and the need to explore emerging technologies that support the goals of the US FDA’s Critical Path Initiative (e.g. to make decision support information available early in the drug review process). The US FDA’s efforts have been facilitated by agency-approved data-sharing agreements between government and commercial software developers. This commentary review describes former and current scientific initiatives at the agency, in the area of computational toxicology methods. In particular, toxicology-based QSAR models, ToxML databases and knowledgebases will be addressed. Notably, many of the computational toxicology tools available are commercial products — however, several are emerging as non-commercial products, which are freely-available to the public, and which will facilitate the understanding of how these programs work and avoid the “black box” paradigm. Through productive collaborations, the US FDA Center for Drug Evaluation and Research, and the Center for Food Safety and Applied Nutrition, have worked together to evaluate, develop and apply these methods to chemical toxicity endpoints of regulatory interest.",Chihae Yang and Luis G. Valerio and Kirk B. Arvidson,10.1177/026119290903700509,https://doi-org.crai.referencistas.com/10.1177/026119290903700509,Alternatives to Laboratory Animals,5,523–531,Computational Toxicology Approaches at the US Food and Drug Administration,https://doi-org.crai.referencistas.com/10.1177/026119290903700509,37,2009i,PMID:20017581
article,doi:10.1177/0959354317722867,"Two options fuel the debate on the cognitive processes underlying the perception of affordances. On the one hand, the ecological theory of affordance fits with the methodological assumptions of the dynamical systems theory of cognition. On the other hand, it is nowadays common to conceive the perception of affordances within a computational framework. This article defends the explanatory power of a computational approach and aims to extend the concept of affordance beyond the boundaries of the dynamical systems theory of cognition. For that purpose, I consider the case of patients suffering from optic ataxia, a condition in which some aspects of visual guidance over reaching with the hand are lost following a lesion in the left parietal cortex. Etiological considerations, indeed, reveal that a computational approach to the perception of affordances allows for an explanation of ataxic behavior that is not available to the dynamical systems theory.",Silvano Zipoli Caiani,10.1177/0959354317722867,https://doi-org.crai.referencistas.com/10.1177/0959354317722867,Theory & Psychology,5,663–682,When the affordances disappear: Dynamical and computational explanations of optic ataxia,https://doi-org.crai.referencistas.com/10.1177/0959354317722867,27,2017j,
article,doi:10.1177/20563051231196880,"Social media, in general, and Facebook in particular, have been clearly identified as important platforms for the dissemination of mis- and disinformation and related problematic content. However, the patterns and processes of such dissemination are still not sufficiently understood. We detail a novel computational methodology that focusses on the identification of high-profile vectors of “fake news” and other problematic information in public Facebook spaces. The method enables examination of networks of content sharing that emerge between public pages and groups, and external sources, and the study of longitudinal dynamics of these networks as interests and allegiances shift and new developments (such as the COVID-19 pandemic or the US presidential elections) drive the emergence or decline of dominant themes. Through a case study of content captured between 2016 and 2021, we demonstrate how this methodology allows the development of a new and more comprehensive picture of the overall impact of “fake news,” in all its forms, on contemporary societies.",Daniel Angus and Axel Bruns and Edward Hurcombe and Stephen Harrington and Xue Ying (Jane) Tan,10.1177/20563051231196880,https://doi-org.crai.referencistas.com/10.1177/20563051231196880,Social Media + Society,3,20563051231196880,Computational Communication Methods for Examining Problematic News-Sharing Practices on Facebook at Scale,https://doi-org.crai.referencistas.com/10.1177/20563051231196880,9,2023a,
article,doi:10.1177/0894439320914505,"Anxiety is a pervasive emotional state that tends to arise in situations involving uncertainty due partly to social and contextual issues including competition, economic disparity, and social insecurity. Thus, distribution of aggregate emotions, such as in anxiety, may reveal an important picture of otherwise invisible social processes in which individuals interact with local and global opportunities, constraints, and potential threats. The aim of this study is to present a computational approach to the dynamic distribution of anxiety extracted from natural language expressions of users of Twitter, a popular global social media platform. We develop an unsupervised machine learning procedure based on a naive Bayes model to classify contents of anxiety, estimate the degree of anxiety, and construct a geographic map of spatiotemporal distribution of anxiety. To validate our mapping results, a multilevel statistical analysis was performed to examine how anxiety distribution is correlated with other district-level sociodemographic statistics such as rates of birth and early divorce. Implications for further research and extension are discussed.",Yong Suk Choi and Hansung Kim and Dongyoung Sohn,10.1177/0894439320914505,https://doi-org.crai.referencistas.com/10.1177/0894439320914505,Social Science Computer Review,3,598–617,Mapping Social Distress: A Computational Approach to Spatiotemporal Distribution of Anxiety,https://doi-org.crai.referencistas.com/10.1177/0894439320914505,40,2022b,
article,doi:10.1177/1046878117748175,"Background. Educational games are nowadays used for facilitating the teaching and learning process of various subjects. History is one of the subjects that simulations and games are used for promoting active learning and supporting students in comprehending various history-related subjects. Aim. This article reports on a new educational game on Greek mythology, called MYTH TROUBLES, designed and developed from scratch with the aim of supporting primary school students in studying Greek mythology and raising their interest on the subject of history. Method. The article presents the educational rationale and design of MYTH TROUBLES in the context of an educational games design model proposed in the literature. Since the game was implemented with the platform of Scratch and it is available online both for students (or anyone interested in Greek Mythology) and game developers, some information for its implementation is also provided. The results of a pilot evaluation of MYTH TROUBLES with the help of 21 experienced school teachers are presented, along with proposals for improvement and extension of the game. Results. Teachers evaluated positively MYTH TROUBLES in terms of acceptability, usability, utility as an educational tool, as well as its interface and game play and expressed their willingness to use it in the classroom. Conclusions. MYTH TROUBLES is considered appropriate by teachers for supporting the teaching and learning of Greek mythology and assessing its educational value in class is the next step. Scratch is appropriate for implementing such educational games and sharing them with interested players and game developers.",Olympia Evangelopoulou and Stelios Xinogalos,10.1177/1046878117748175,https://doi-org.crai.referencistas.com/10.1177/1046878117748175,Simulation & Gaming,1,71–91,MYTH TROUBLES: An Open-Source Educational Game in Scratch for Greek Mythology,https://doi-org.crai.referencistas.com/10.1177/1046878117748175,49,2018c,
article,doi:10.3233/FI-2013-813,"We study the complexity of Bongartz’s algorithm for determining a maximal common direct summand of a pair of modules M, N over k-algebra Λ; in particular, we estimate its pessimistic computational complexity 𝒪(rm6n2(n + m log n)), where m = dimkM ≤ n = dimkN and r is a number of common indecomposable direct summands of M and N. We improve the algorithm to another one of complexity 𝒪(rm4n2(n+m log m)) and we show that it applies to the isomorphism problem (having at least an exponential complexity in a direct approach). Moreover, we discuss a performance of both algorithms in practice and show that the “average” complexity is much lower, especially for the improved one (which becomes a part of QPA package for GAP computer algebra system).",Andrzej Mróz,10.3233/FI-2013-813,https://doi-org.crai.referencistas.com/10.3233/FI-2013-813,Fundamenta Informaticae,3,317–329,On the Computational Complexity of Bongartz’s Algorithm,https://doi-org.crai.referencistas.com/10.3233/FI-2013-813,123,2013d,
article,doi:10.1177/1478077116638924,"In the current computer-aided architectural design education, students do not necessarily need to be taught to use more digital tools, but need to be introduced to the possibilities of designing their own digital tools. Designing the original tools with the assistance of educational-use environment for computational fluid dynamics programming improves the capability of the students to estimate the flows around architectures based on the mathematical background and the actual program. The authors have developed Educational Library for Fluid as an educational-use environment for computational fluid dynamics programming and ran the workshop where the students majoring in computer-aided architectural design tried to design computational fluid dynamics tools with Educational Library for Fluid. In this article, the details of Educational Library for Fluid and the results of the workshop are being reported. In addition, the key points of computational fluid dynamics education that the authors learned through the experience of the workshop are shared.",Akito Nakano and John N Bohn and Akira Wakita,10.1177/1478077116638924,https://doi-org.crai.referencistas.com/10.1177/1478077116638924,International Journal of Architectural Computing,2,119–130,Development of educational-use computational fluid dynamics programming environment and workshop,https://doi-org.crai.referencistas.com/10.1177/1478077116638924,14,2016e,
article,doi:10.1177/02632764211048548,What is algorithmic thought? It is not possible to address this question without first reflecting on how the Universal Turing Machine transformed symbolic logic and brought to a halt the universality of mathematical formalism and the biocentric speciation of thought. The article draws on Sylvia Wynter’s discussion of the sociogenic principle to argue that both neurocognitive and formal models of automated cognition constitute the epistemological explanations of the origin of the human and of human sapience. Wynter’s argument will be related to Gilbert Simondon’s reflections on ‘technical mentality’ to consider how socio-techno-genic assemblages can challenge the biocentricism and the formalism of modern epistemology. This article turns to ludic logic as one possible example of techno-semiotic languages as a speculative overturning of sociogenic programming. Algorithmic rules become technique-signs coinciding not with classic formalism but with interactive localities without re-originating the universality of colonial and patriarchal cosmogony.,Luciana Parisi,10.1177/02632764211048548,https://doi-org.crai.referencistas.com/10.1177/02632764211048548,"Theory, Culture & Society",7–8,33–53,Interactive Computation and Artificial Epistemologies,https://doi-org.crai.referencistas.com/10.1177/02632764211048548,38,2021f,
article,doi:10.1177/1094342006074849,"In the economic-based computational grids we need effective schedulers not only to minimize the makespan but also to minimize the costs that are spent for the execution of the jobs. In this work, a novel economy driven job scheduling heuristic is proposed and a simulation application is developed by using GridSim toolkit to investigate the performance of the heuristic. The simulation-based experiments demonstrate the effectiveness of the proposed heuristic both in terms of parameter sweep and sequential workflow type of applications.",Omer Ozan Sonmez and Attila Gursoy,10.1177/1094342006074849,https://doi-org.crai.referencistas.com/10.1177/1094342006074849,The International Journal of High Performance Computing Applications,1,21–29,A Novel Economic-Based Scheduling Heuristic for Computational Grids,https://doi-org.crai.referencistas.com/10.1177/1094342006074849,21,2007g,
article,doi:10.1177/00491241221122596,"This article presents a computational approach to examining immigrant incorporation through shifts in the social “mainstream.” Analyzing a historical corpus of American etiquette books, texts from 1922–2017 describing social norms, we identify mainstream shifts related to long-standing groups which once were and may currently still be seen as immigrant outsiders in the United States: Catholic, Chinese, Irish, Italian, Jewish, Mexican, and Muslim groups. The analysis takes a computational grounded theory approach, combining qualitative readings and computational text analyses. Using word embeddings, we operationalize the chosen groups as focal group concepts. We extract sections of text that are salient to the focal group concepts to create group-specific text corpora. Two computational approaches make it possible to examine mainstream shifts in these corpora. First, we use sentiment analysis to observe the positive sentiment in each corpus and its change over time. Second, we observe changes in each corpus’s position on a semantic dimension represented by the poles of “strange” and “normal.” The results indicate mainstream shifts through increases in positive sentiment and movement from strange to normal over time for most of the group-specific corpora. These research techniques can be adapted to other studies of social sentiment and symbolic inclusion.",Andrea Voyer and Zachary D. Kline and Madison Danton and Tatiana Volkova,10.1177/00491241221122596,https://doi-org.crai.referencistas.com/10.1177/00491241221122596,Sociological Methods & Research,4,1540–1579,From Strange to Normal: Computational Approaches to Examining Immigrant Incorporation Through Shifts in the Mainstream,https://doi-org.crai.referencistas.com/10.1177/00491241221122596,51,2022h,
article,doi:10.1177/026119290903700509,"For over a decade, the United States Food and Drug Administration (US FDA) has been engaged in the applied research, development, and evaluation of computational toxicology methods used to support the safety evaluation of a diverse set of regulated products. The basis for evaluating computational toxicology methods is multi-factorial, including the potential for increased efficiency, reduction in the numbers of animals used, lower costs, and the need to explore emerging technologies that support the goals of the US FDA’s Critical Path Initiative (e.g. to make decision support information available early in the drug review process). The US FDA’s efforts have been facilitated by agency-approved data-sharing agreements between government and commercial software developers. This commentary review describes former and current scientific initiatives at the agency, in the area of computational toxicology methods. In particular, toxicology-based QSAR models, ToxML databases and knowledgebases will be addressed. Notably, many of the computational toxicology tools available are commercial products — however, several are emerging as non-commercial products, which are freely-available to the public, and which will facilitate the understanding of how these programs work and avoid the “black box” paradigm. Through productive collaborations, the US FDA Center for Drug Evaluation and Research, and the Center for Food Safety and Applied Nutrition, have worked together to evaluate, develop and apply these methods to chemical toxicity endpoints of regulatory interest.",Chihae Yang and Luis G. Valerio and Kirk B. Arvidson,10.1177/026119290903700509,https://doi-org.crai.referencistas.com/10.1177/026119290903700509,Alternatives to Laboratory Animals,5,523–531,Computational Toxicology Approaches at the US Food and Drug Administration,https://doi-org.crai.referencistas.com/10.1177/026119290903700509,37,2009i,PMID:20017581
article,doi:10.1177/0959354317722867,"Two options fuel the debate on the cognitive processes underlying the perception of affordances. On the one hand, the ecological theory of affordance fits with the methodological assumptions of the dynamical systems theory of cognition. On the other hand, it is nowadays common to conceive the perception of affordances within a computational framework. This article defends the explanatory power of a computational approach and aims to extend the concept of affordance beyond the boundaries of the dynamical systems theory of cognition. For that purpose, I consider the case of patients suffering from optic ataxia, a condition in which some aspects of visual guidance over reaching with the hand are lost following a lesion in the left parietal cortex. Etiological considerations, indeed, reveal that a computational approach to the perception of affordances allows for an explanation of ataxic behavior that is not available to the dynamical systems theory.",Silvano Zipoli Caiani,10.1177/0959354317722867,https://doi-org.crai.referencistas.com/10.1177/0959354317722867,Theory & Psychology,5,663–682,When the affordances disappear: Dynamical and computational explanations of optic ataxia,https://doi-org.crai.referencistas.com/10.1177/0959354317722867,27,2017j,
article,doi:10.1177/14680874221125538,"Predictive modeling of pre-chamber combustion engines relies primarily on the correct description of laminar and turbulent flame speeds. For engineering applications, the correlations of the flame speeds with physical variables involve empirical constants that are valid for a limited range of operating conditions. The current work aims at assessing the significance of laminar flame speed prediction in the simulation of ultra-lean pre-chamber engine combustion operated with methane. Gülder’s empirical correlation for laminar flame speed was chosen as a reference and was further modified for equivalence ratio, pressure and temperature ranges beyond what it was originally derived for, in order to confirm the original hypothesis; the pressure and temperature dependence were adopted as a power-law correlation. Based on the computational results using the skeletal reaction mechanism, the correlation was modified better represent the flame speeds at ultra-lean engine conditions, using GRI 3.0 as a reference. The modified correlation for methane was implemented in CONVERGE, a three-dimensional computational fluid dynamics (CFD) solver, and the results were validated against the experimental data. In all cases, the original formulation of Peters’s turbulent flame speed correlation was used and was found to have insignificant effect on the conditions under study, confirming the importance of the accurate determination of the laminar flame speed that dominates over any turbulence corrections for high Karlovitz number effects. The flame topology was also investigated to provide insights into the observed pressure behavior among the tested cases. Finally, the relevant turbulent combustion regimes encountered in the pre-chamber combustion engine conditions were examined in the Borghi-Peters diagram, further confirming the findings of the study.",Ghufran Alkhamis and Mickael Silva and Emre Cenker and Hong G Im,10.1177/14680874221125538,https://doi-org.crai.referencistas.com/10.1177/14680874221125538,International Journal of Engine Research,6,2538–2551,A computational assessment of flame speed correlation in an ultra-lean pre-chamber engine,https://doi-org.crai.referencistas.com/10.1177/14680874221125538,24,2023a,
article,doi:10.1177/1469066719894969,"The question of whether [CH2OH]+ should be described as the hydroxymethyl cation, +CH2OH, or protonated formaldehyde, CH2=OH+, is reconsidered in the light of experimental information and new computational evidence. Previous arguments that the charge distribution in [CH2OH]+ may be probed by considering the incremental stabilisation of [CH2OH]+ induced by homologation on carbon (to give [CH3CHOH]+) or oxygen (to produce [CH2OCH3]+) are critically examined. Cation stabilisation energies are shown to be better indicators of the nature of these oxonium ions. Further insight into the structure of larger CnH2n+1O+ oxonium ions is obtained by considering the site of protonation of enol ethers and related species. Computational information, including AIM (Atoms and Molecules) and NBA (Natural Bond Analysis) charges on the carbon and oxygen atoms in [CH2OH]+ and related species, is considered critically. Particular attention is focused on the calculated bond lengths and barriers to rotation about the C–O bond(s) in [CH2OH]+, [CH3CHOH]+, [(CH3)2COH]+, CH3OH and [CH2OCH3]+ and the C–N bond in [CH2NH2]+. Trends in these data are consistent with appreciable π-bonding only in the C–O connections which correspond to the C=O bond in the parent aldehyde or ketone from which the oxonium ion may be considered to be derived by protonation or alkyl cationation.",Richard D Bowen and William HC Martin and Charles E Hudson and David J McAdoo,10.1177/1469066719894969,https://doi-org.crai.referencistas.com/10.1177/1469066719894969,European Journal of Mass Spectrometry,3,187–194,Experimental and computational evidence for C=O π-bonding in [CH2OH]+ and related oxonium ions,https://doi-org.crai.referencistas.com/10.1177/1469066719894969,26,2020b,PMID:31969004
article,doi:10.1177/1548512916681672,"a. In 1973, the Department of Defense (DoD) created the Office of Net Assessment (ONA) with a charter and unique approach to strategic analysis. This approach questioned the suitability of systems analysis to assess long-term, dynamic competition between complex military organizations, and turned to more qualitative methods as analytic alternatives. Developments in computing technology and modeling methods over the last two decades, most notably agent-based modeling (ABM), provide new opportunities to address the central analytic questions that motivated the original development of net assessment as a distinctive practice of strategic analysis. By employing ABM to simulate and analyze the behavior of strategic, adaptive, boundedly rational actors, which have previously frustrated mathematical analysis, a new generation of computational models can provide opportunities to add rigor to net assessment.",Aaron B Frank,10.1177/1548512916681672,https://doi-org.crai.referencistas.com/10.1177/1548512916681672,The Journal of Defense Modeling and Simulation,1,79–94,Toward computational net assessment,https://doi-org.crai.referencistas.com/10.1177/1548512916681672,14,2017c,
article,doi:10.1177/039139880102400306,"Coronary artery bypass graft (CABG) operation for coronary artery disease with different types of grafts has a large clinical application world wide. Immediately after this operation patients are usually relieved of their chest pain and have improved cardiac function. However, after a while, these bypass grafts may fail due to for example, neointimal hyperplasia or thrombosis. One of the causes for this bypass graft failure is assumed to be the blood flow with low wall shear stress. The aim of this research is to estimate the wall shear stress in a graft and thus to locate areas were wall shear stress is low. This was done with the help of a blood flow computer model. Postoperative biplane angiograms of the graft were recorded, and from these the three-dimensional geometry of the graft was reconstructed and imported into the computational fluid dynamics (CFD) program FLUENT. The stationary diastolic flow through the grafts was calculated, and the wall shear stress distribution was estimated. This procedure was carried out for one native vessel and two different types of bypass grafts. One bypass graft was a saphenous vein and the other one was a varicose saphenous vein encased in a fine, flexible metal mesh. The mesh was attached to give the graft a defined diameter. The computational results show that each graft has distinct areas of low wall shear stress. The graft with the metal mesh has an area of low wall shear stress (< 1 Pa, stationary flow), which is four times smaller than the respective areas in the other graft and in the native vessel. This is thought to be caused by the smaller and more uniform diameter of the metal mesh-reinforced graft.",L. Goubergrits and K. Affeld and E. Wellnhofer and R. Zurbrügg and T. Holmer,10.1177/039139880102400306,https://doi-org.crai.referencistas.com/10.1177/039139880102400306,The International Journal of Artificial Organs,3,145–151,Estimation of wall shear stress in bypass grafts with computational fluid dynamics method,https://doi-org.crai.referencistas.com/10.1177/039139880102400306,24,2001d,PMID:11314808
article,doi:10.1177/0092055X211033632,"Despite the centrality of data analysis to the discipline, sociology departments are currently falling short of teaching both undergraduate and graduate students crucial computing and statistical software skills. We argue that sociology instructors must intentionally and explicitly teach computing skills alongside statistical concepts to prepare their students for participation in a data-driven world. We illuminate foundational concepts for computing in the social sciences and provide easy-to-integrate recommendations for building competency with these concepts in the form of a workshop designed to introduce sociology undergraduate and graduate students to the logic of statistical software. We use our workshop to show that students appreciate and gain confidence from being taught how to think about computing.",Amy L. Johnson and Rebecca D. Gleit,10.1177/0092055X211033632,https://doi-org.crai.referencistas.com/10.1177/0092055X211033632,Teaching Sociology,1,49–61,Teaching for a Data-Driven Future: Intentionally Building Foundational Computing Skills,https://doi-org.crai.referencistas.com/10.1177/0092055X211033632,50,2022e,
article,doi:10.1177/0960327115605440,"Predictive toxicology plays a critical role in reducing the failure rate of new drugs in pharmaceutical research and development. Despite recent gains in our understanding of drug-induced toxicity, however, it is urgent that the utility and limitations of our current predictive tools be determined in order to identify gaps in our understanding of mechanistic and chemical toxicology. Using recently published computational regression analyses of in vitro and in vivo toxicology data, it will be demonstrated that significant gaps remain in early safety screening paradigms. More strategic analyses of these data sets will allow for a better understanding of their domain of applicability and help identify those compounds that cause significant in vivo toxicity but which are currently mis-predicted by in silico and in vitro models. These ‘outliers’ and falsely predicted compounds are metaphorical lighthouses that shine light on existing toxicological knowledge gaps, and it is essential that these compounds are investigated if attrition is to be reduced significantly in the future. As such, the modern computational toxicologist is more productively engaged in understanding these gaps and driving investigative toxicology towards addressing them.",RT Naven and S Louise-May,10.1177/0960327115605440,https://doi-org.crai.referencistas.com/10.1177/0960327115605440,Human & Experimental Toxicology,12,1304–1309,Computational toxicology: Its essential role in reducing drug attrition,https://doi-org.crai.referencistas.com/10.1177/0960327115605440,34,2015f,PMID:26614820
article,doi:10.1080/09506608.2023.2169501,"This review article provides a critical assessment of the progress made in computational modelling of metal-based additive manufacturing (AM) with emphasis on its ability to predict physical phenomena, concepts of microstructural evolution, residual stresses, role of multiple thermal cycles, and formation of multi-dimensional defects along with the achieved degree of experimental validation. The uniqueness of this article stems from the inclusion of comprehensive information on computational progress in the field of fusion-based, sintering-based, and mechanical deformation-based AM. A computational model’s role in determining the process framework for the desired outcome of the set properties of the AM components is recognised while presenting the process-microstructure maps, thereby appraising computational ability towards the qualification of products. The inclusion of a detailed discussion on the bi-directional coupling of machine learning and physics-based computational models provides a futuristic roadmap for the digital twin of metal-based AM.",Shashank Sharma and Sameehan S. Joshi and Mangesh V. Pantawane and Madhavan Radhakrishnan and Sangram Mazumder and Narendra B. Dahotre,10.1080/09506608.2023.2169501,https://doi-org.crai.referencistas.com/10.1080/09506608.2023.2169501,International Materials Reviews,7,943–1009,Multiphysics multi-scale computational framework for linking process–structure–property relationships in metal additive manufacturing: a critical review,https://doi-org.crai.referencistas.com/10.1080/09506608.2023.2169501,68,2023g,
article,doi:10.1177/1094342016677599,"Computational biology allows and encourages the application of many different parallelism-based technologies. This special issue brings together high-quality state-of-the-art contributions about parallelism-based technologies in computational biology, from different points of view or perspectives, that is, from diverse high-performance computing applications. The special issue collects considerably extended and improved versions of the best papers, accepted and presented in PBio 2015 (the Third International Workshop on Parallelism in Bioinformatics, and part of IEEE ISPA 2015). The domains and topics covered in these seven papers are timely and important, and the authors have done an excellent job of presenting the material.",Miguel A Vega-Rodríguez and Álvaro Rubio-Largo,10.1177/1094342016677599,https://doi-org.crai.referencistas.com/10.1177/1094342016677599,The International Journal of High Performance Computing Applications,3,317–320,Parallelism in computational biology: A view from diverse high-performance computing applications,https://doi-org.crai.referencistas.com/10.1177/1094342016677599,32,2018h,
article,doi:10.3233/JAD-201011,"Background: Although the abnormal depositions of amyloid plaques and neurofibrillary tangles are the hallmark of Alzheimer’s disease (AD), converging evidence shows that the individual’s neurodegeneration trajectory is regulated by the brain’s capability to maintain normal cognition. Objective: The concept of cognitive reserve has been introduced into the field of neuroscience, acting as a moderating factor for explaining the paradoxical relationship between the burden of AD pathology and the clinical outcome. It is of high demand to quantify the degree of conceptual cognitive reserve on an individual basis. Methods: We propose a novel statistical model to quantify an individual’s cognitive reserve against neuropathological burdens, where the predictors include demographic data (such as age and gender), socioeconomic factors (such as education and occupation), cerebrospinal fluid biomarkers, and AD-related polygenetic risk score. We conceptualize cognitive reserve as a joint product of AD pathology and socioeconomic factors where their interaction manifests a significant role in counteracting the progression of AD in our statistical model. Results: We apply our statistical models to re-investigate the moderated neurodegeneration trajectory by considering cognitive reserve, where we have discovered that 1) high education individuals have significantly higher reserve against the neuropathology than the low education group; however, 2) the cognitive decline in the high education group is significantly faster than low education individuals after the level of pathological burden increases beyond the tipping point. Conclusion: We propose a computational proxy of cognitive reserve that can be used in clinical routine to assess the progression of AD.",Ying Zhang and Yajing Hao and Lang Li and Kai Xia and Guorong Wu,10.3233/JAD-201011,https://doi-org.crai.referencistas.com/10.3233/JAD-201011,Journal of Alzheimer’s Disease,3,1217–1228,A Novel Computational Proxy for Characterizing Cognitive Reserve in Alzheimer’s Disease,https://doi-org.crai.referencistas.com/10.3233/JAD-201011,78,2020i,
article,doi:10.1177/0963721420915873,"How do children learn to read? How do deficits in various components of the reading network affect learning outcomes? How does remediating one or several components change reading performance? In this article, we summarize what is known about learning to read and how this can be formalized in a developmentally plausible computational model of reading acquisition. The model is used to understand normal and impaired reading development (dyslexia). In particular, we show that it is possible to simulate individual learning trajectories and intervention outcomes on the basis of three component skills: orthography, phonology, and vocabulary. We therefore advocate a multifactorial computational approach to understanding reading that has practical implications for dyslexia and intervention.",Johannes C. Ziegler and Conrad Perry and Marco Zorzi,10.1177/0963721420915873,https://doi-org.crai.referencistas.com/10.1177/0963721420915873,Current Directions in Psychological Science,3,293–300,Learning to Read and Dyslexia: From Theory to Intervention Through Personalized Computational Models,https://doi-org.crai.referencistas.com/10.1177/0963721420915873,29,2020j,PMID:32655213
article,doi:10.1177/1469066719894969,"The question of whether [CH2OH]+ should be described as the hydroxymethyl cation, +CH2OH, or protonated formaldehyde, CH2=OH+, is reconsidered in the light of experimental information and new computational evidence. Previous arguments that the charge distribution in [CH2OH]+ may be probed by considering the incremental stabilisation of [CH2OH]+ induced by homologation on carbon (to give [CH3CHOH]+) or oxygen (to produce [CH2OCH3]+) are critically examined. Cation stabilisation energies are shown to be better indicators of the nature of these oxonium ions. Further insight into the structure of larger CnH2n+1O+ oxonium ions is obtained by considering the site of protonation of enol ethers and related species. Computational information, including AIM (Atoms and Molecules) and NBA (Natural Bond Analysis) charges on the carbon and oxygen atoms in [CH2OH]+ and related species, is considered critically. Particular attention is focused on the calculated bond lengths and barriers to rotation about the C–O bond(s) in [CH2OH]+, [CH3CHOH]+, [(CH3)2COH]+, CH3OH and [CH2OCH3]+ and the C–N bond in [CH2NH2]+. Trends in these data are consistent with appreciable π-bonding only in the C–O connections which correspond to the C=O bond in the parent aldehyde or ketone from which the oxonium ion may be considered to be derived by protonation or alkyl cationation.",Richard D Bowen and William HC Martin and Charles E Hudson and David J McAdoo,10.1177/1469066719894969,https://doi-org.crai.referencistas.com/10.1177/1469066719894969,European Journal of Mass Spectrometry,3,187–194,Experimental and computational evidence for C=O π-bonding in [CH2OH]+ and related oxonium ions,https://doi-org.crai.referencistas.com/10.1177/1469066719894969,26,2020a,PMID:31969004
article,doi:10.1177/2056305119896057,"Conflicts involving caste issues, mainly concerning the lowest caste rights, pervade modern Indian society. Caste affiliation, being rigorously enforced by the society, is an official contemporary reality. Although caste identity is a major social discrimination, it also serves as a necessary condition for affirmative action like reservation policy. In this article, we perform an original and rigorous analysis of the discourse involving the theme “caste” in India newspapers. To this purpose, we have implemented a computational analysis over a big dataset of the 2016 and 2017 editions of three major Indian newspapers to determine the most salient themes associated with “caste” in the news. We have used an original mix of state-of-the-art algorithms, including those based on statistical distributions and two-layer neural networks, to detect the relevant topics in the news and characterize their linguistic context. We concluded that there is an excessive association between lower castes, victimization, and social unrest in the news that does not adequately cover the reports on other aspects of their life and personal identity, thus reinforcing conflict, while attenuating the vocality and agency of a large section of the population. From our conclusion, we propose a positive discrimination policy in the newsroom.",António Filipe Fonseca and Sohhom Bandyopadhyay and Jorge Louçã and Jaison A. Manjaly,10.1177/2056305119896057,https://doi-org.crai.referencistas.com/10.1177/2056305119896057,Social Media + Society,4,2056305119896057,Caste in the News: A Computational Analysis of Indian Newspapers,https://doi-org.crai.referencistas.com/10.1177/2056305119896057,5,2019b,
article,doi:10.1037/1089-2680.10.2.113,"Studies of scientific and technological thinking can be organized via a taxonomy of methodological approaches that reveal areas for further study. Dunbar provides such a taxonomy, using biological methods like in vivo and in vitro as examples. In vitro corresponds to laboratory simulations of scientific thinking; In Vivo corresponds to field studies of actual scientists and inventors. Dunbar expands this taxonomy to incorporate historical studies of scientists and inventors, computer simulation and the possibility of neurological studies. These methods can and should be combined: Computational simulations are frequently based on historical case-studies, for example. In this article, a wide range of studies are classified according to this taxonomy, and their main points summarized. Consideration is also given to studies of scientific and technological thinking in collaborative dyads and teams. The article concludes with suggestions for future research.",Michael E. Gorman,10.1037/1089-2680.10.2.113,https://doi-org.crai.referencistas.com/10.1037/1089-2680.10.2.113,Review of General Psychology,2,113–129,Scientific and Technological Thinking,https://doi-org.crai.referencistas.com/10.1037/1089-2680.10.2.113,10,2006c,
article,doi:10.1177/039139880102400306,"Coronary artery bypass graft (CABG) operation for coronary artery disease with different types of grafts has a large clinical application world wide. Immediately after this operation patients are usually relieved of their chest pain and have improved cardiac function. However, after a while, these bypass grafts may fail due to for example, neointimal hyperplasia or thrombosis. One of the causes for this bypass graft failure is assumed to be the blood flow with low wall shear stress. The aim of this research is to estimate the wall shear stress in a graft and thus to locate areas were wall shear stress is low. This was done with the help of a blood flow computer model. Postoperative biplane angiograms of the graft were recorded, and from these the three-dimensional geometry of the graft was reconstructed and imported into the computational fluid dynamics (CFD) program FLUENT. The stationary diastolic flow through the grafts was calculated, and the wall shear stress distribution was estimated. This procedure was carried out for one native vessel and two different types of bypass grafts. One bypass graft was a saphenous vein and the other one was a varicose saphenous vein encased in a fine, flexible metal mesh. The mesh was attached to give the graft a defined diameter. The computational results show that each graft has distinct areas of low wall shear stress. The graft with the metal mesh has an area of low wall shear stress (< 1 Pa, stationary flow), which is four times smaller than the respective areas in the other graft and in the native vessel. This is thought to be caused by the smaller and more uniform diameter of the metal mesh-reinforced graft.",L. Goubergrits and K. Affeld and E. Wellnhofer and R. Zurbrügg and T. Holmer,10.1177/039139880102400306,https://doi-org.crai.referencistas.com/10.1177/039139880102400306,The International Journal of Artificial Organs,3,145–151,Estimation of wall shear stress in bypass grafts with computational fluid dynamics method,https://doi-org.crai.referencistas.com/10.1177/039139880102400306,24,2001d,PMID:11314808
article,doi:10.1177/00405175211036733,"The design of metallic card clothing, which is one of the most important devices in the textile industry, has always been based on operational experience. With the development of types of fibers and the requirements for the quality of yarns, those principles concluded by engineers seem to be losing their efficiency. Recent research found that airflow played an important role in the card process, which means airflow should be carefully studied. Computational fluid dynamics (CFD) simulation greatly helps in the analysis of airflow because the gauge between carding elements is too narrow to put in any measuring device. In the present study, with the help of CFD simulation, the air around different carding clothing with varied tooth depth was analyzed. It was concluded that the carding efficiency improvement in card clothing with lower tooth depth may be related to more concentrated air velocity at the tooth tips. This resulted in more probabilities that fibers would get through the cylinder surface at the teeth tips, so that the fibers could be caught by flat-top needles more efficiently. With this assumption, a new generation of card clothing called “double teeth” containing two teeth in a single section has been invented. The new configuration design of card clothing was then applied in several spinning mills on an industrial scale for experiments. The results showed about a 30% improvement in production at the same quality level as conventional card clothing, which implied the usefulness of the newly applied principles related to airflow. Despite the difficulty in the study of the complex carding process, the new airflow analysis method has shown an optional and worthwhile way of thinking that could make a difference in future research in the textile industry.",Weihua Gu and Fuguo Li and Qinchao Gao and Chengzhi Zhuo and Zhong Lu,10.1177/00405175211036733,https://doi-org.crai.referencistas.com/10.1177/00405175211036733,Textile Research Journal,15–16,2909–2921,Design of double teeth metallic card clothing for the high-efficiency carding process by computational fluid dynamics,https://doi-org.crai.referencistas.com/10.1177/00405175211036733,92,2022e,
article,doi:10.1177/0960327115605440,"Predictive toxicology plays a critical role in reducing the failure rate of new drugs in pharmaceutical research and development. Despite recent gains in our understanding of drug-induced toxicity, however, it is urgent that the utility and limitations of our current predictive tools be determined in order to identify gaps in our understanding of mechanistic and chemical toxicology. Using recently published computational regression analyses of in vitro and in vivo toxicology data, it will be demonstrated that significant gaps remain in early safety screening paradigms. More strategic analyses of these data sets will allow for a better understanding of their domain of applicability and help identify those compounds that cause significant in vivo toxicity but which are currently mis-predicted by in silico and in vitro models. These ‘outliers’ and falsely predicted compounds are metaphorical lighthouses that shine light on existing toxicological knowledge gaps, and it is essential that these compounds are investigated if attrition is to be reduced significantly in the future. As such, the modern computational toxicologist is more productively engaged in understanding these gaps and driving investigative toxicology towards addressing them.",RT Naven and S Louise-May,10.1177/0960327115605440,https://doi-org.crai.referencistas.com/10.1177/0960327115605440,Human & Experimental Toxicology,12,1304–1309,Computational toxicology: Its essential role in reducing drug attrition,https://doi-org.crai.referencistas.com/10.1177/0960327115605440,34,2015f,PMID:26614820
article,doi:10.1177/14780771241279350,"This paper introduces a computational aesthetics framework utilizing computer vision (CV) and artificial neural networks (ANN) to predict the aesthetic preferences of groups of people for architecture. It relies on part-to-whole theories from aesthetics and cognitive psychology. A survey of a group of people on preferences of images is held to record an average hedonic response (AHR). CV algorithms MSER and SAM recognize parts in images. Birkhoff’s aesthetic measure formula is adapted by employing the number of parts and their connections. These quantities are used as input layers of an ANN, and the AHR is the target output. The ANN evaluates images to output a predicted hedonic response (PHR), which is tested as a criterion in parametric design space navigation and in mapping the latent space of GANs. We conclude that such a framework is a heuristic method for better understanding the design and latent spaces and exploring designs.",Victor Sardenberg and Igor Guatelli and Mirco Becker,10.1177/14780771241279350,https://doi-org.crai.referencistas.com/10.1177/14780771241279350,International Journal of Architectural Computing,0,14780771241279350,A computational framework for aesthetic preferences in architecture using computer vision and artificial neural networks,https://doi-org.crai.referencistas.com/10.1177/14780771241279350,0,2024g,
article,doi:10.1080/09506608.2023.2169501,"This review article provides a critical assessment of the progress made in computational modelling of metal-based additive manufacturing (AM) with emphasis on its ability to predict physical phenomena, concepts of microstructural evolution, residual stresses, role of multiple thermal cycles, and formation of multi-dimensional defects along with the achieved degree of experimental validation. The uniqueness of this article stems from the inclusion of comprehensive information on computational progress in the field of fusion-based, sintering-based, and mechanical deformation-based AM. A computational model’s role in determining the process framework for the desired outcome of the set properties of the AM components is recognised while presenting the process-microstructure maps, thereby appraising computational ability towards the qualification of products. The inclusion of a detailed discussion on the bi-directional coupling of machine learning and physics-based computational models provides a futuristic roadmap for the digital twin of metal-based AM.",Shashank Sharma and Sameehan S. Joshi and Mangesh V. Pantawane and Madhavan Radhakrishnan and Sangram Mazumder and Narendra B. Dahotre,10.1080/09506608.2023.2169501,https://doi-org.crai.referencistas.com/10.1080/09506608.2023.2169501,International Materials Reviews,7,943–1009,Multiphysics multi-scale computational framework for linking process–structure–property relationships in metal additive manufacturing: a critical review,https://doi-org.crai.referencistas.com/10.1080/09506608.2023.2169501,68,2023h,
article,doi:10.1177/1094342016677599,"Computational biology allows and encourages the application of many different parallelism-based technologies. This special issue brings together high-quality state-of-the-art contributions about parallelism-based technologies in computational biology, from different points of view or perspectives, that is, from diverse high-performance computing applications. The special issue collects considerably extended and improved versions of the best papers, accepted and presented in PBio 2015 (the Third International Workshop on Parallelism in Bioinformatics, and part of IEEE ISPA 2015). The domains and topics covered in these seven papers are timely and important, and the authors have done an excellent job of presenting the material.",Miguel A Vega-Rodríguez and Álvaro Rubio-Largo,10.1177/1094342016677599,https://doi-org.crai.referencistas.com/10.1177/1094342016677599,The International Journal of High Performance Computing Applications,3,317–320,Parallelism in computational biology: A view from diverse high-performance computing applications,https://doi-org.crai.referencistas.com/10.1177/1094342016677599,32,2018i,
article,doi:10.1177/0963721420915873,"How do children learn to read? How do deficits in various components of the reading network affect learning outcomes? How does remediating one or several components change reading performance? In this article, we summarize what is known about learning to read and how this can be formalized in a developmentally plausible computational model of reading acquisition. The model is used to understand normal and impaired reading development (dyslexia). In particular, we show that it is possible to simulate individual learning trajectories and intervention outcomes on the basis of three component skills: orthography, phonology, and vocabulary. We therefore advocate a multifactorial computational approach to understanding reading that has practical implications for dyslexia and intervention.",Johannes C. Ziegler and Conrad Perry and Marco Zorzi,10.1177/0963721420915873,https://doi-org.crai.referencistas.com/10.1177/0963721420915873,Current Directions in Psychological Science,3,293–300,Learning to Read and Dyslexia: From Theory to Intervention Through Personalized Computational Models,https://doi-org.crai.referencistas.com/10.1177/0963721420915873,29,2020j,PMID:32655213
article,doi:10.1177/1094342016649245,"In the last 20 years, a new approach has emerged to investigate the physiopathology of circulation. By merging medical images with validated numerical models, it is possible to support doctors’ decision-making process. The iCardioCloud project aims at establishing a computational framework to perform a complete patient-specific numerical analysis, specially oriented to aortic diseases (like dissections or aneurysms) and to deliver a compelling synthesis. The project can be considered a pioneering example of a Computer Aided Clinical Trial: i.e., a comprehensive analysis of patients where the level of knowledge extracted by traditional measures and statistics is enhanced through the massive use of numerical modeling. From a computer engineering point of view, iCardioCloud faces multiple challenges. First, the number of problems to solve for each patient is significantly huge – this is typical of computational fluid dynamics (CFD) – and it requires parallel methods. In addition, working in a clinical environment demands efficiency as the timeline requires rapid quantitative answers (as may happen in an emergency scenario). It is therefore mandatory to employ high-end parallel systems, such as large clusters or supercomputers. Here we discuss a parallel implementation of an application within the iCardioCloud project, built with a black-box approach – i.e., by assembling and configuring existing packages and libraries and in particular LifeV, a finite element library developed to solve CFD problems. The goal of this paper is to describe the software architecture underlying LifeV and to assess its performance and the most appropriate parallel paradigm. This paper is an extension of a previous work presented at the PBio 2015 Conference. This revision extends the description of the software architecture and discusses several new serial and parallel optimizations to the application. We discuss the introduction of hybrid parallelism in order to mitigate some performance problems previously experienced.",F Auricchio and M Ferretti and A Lefieux and M Musci and A Reali and S Trimarchi and A Veneziani,10.1177/1094342016649245,https://doi-org.crai.referencistas.com/10.1177/1094342016649245,The International Journal of High Performance Computing Applications,3,351–362,Parallelizing a finite element solver in computational hemodynamics: A black box approach,https://doi-org.crai.referencistas.com/10.1177/1094342016649245,32,2018a,
article,doi:10.1177/00222429231221698,"McShane et al.’s (2024) wide-ranging critique of null hypothesis significance testing provides a number of specific suggestions for improved practice in empirical research. This commentary amplifies several of these from the perspective of computational statistics—particularly nonparametrics, resampling/bootstrapping, and Bayesian methods—applied to common research problems. Throughout, the author emphasizes estimation (as opposed to testing) and uncertainty quantification through a comprehensive process of “curating” a variety of graphical and tabular evidence. Specifically, researchers should be encouraged to estimate the quantities that matter, with as few assumptions as possible, in multiple ways, then try to visualize it all, documenting their pathway from data to results for others to follow.",Fred Feinberg,10.1177/00222429231221698,https://doi-org.crai.referencistas.com/10.1177/00222429231221698,Journal of Marketing,3,20–28,p-Values as QWERTY: Curating Evidence in the Computational Era,https://doi-org.crai.referencistas.com/10.1177/00222429231221698,88,2024b,
article,doi:10.1177/0037549716675956,"The development of a real-time driving simulator involves highly complex integrated and interdependent subsystems that require a large amount of computational time. When advanced hardware is unavailable for economic reasons, achieving real-time simulation is challenging, and thus delays are inevitable. Moreover, computational delays in the response of driving simulator subsystems reduce the fidelity of the simulation. In this paper, we propose a technique to decrease computational delays in a driving simulator. We used approximation techniques, sensitivity analysis, decomposition, and sampling techniques to develop a surrogate-based vehicle dynamic model (SBVDM). This global surrogate model can be used in place of the conventional vehicle dynamic model to reduce the computational burden while maintaining an acceptable accuracy. Our results showed that the surrogate model can significantly reduce computing costs compared to the computationally expensive conventional model. In addition, the response time of the SBVDM is nearly five times faster than the original simulation codes. Also, as a method to reduce hardware cost, the SBVDM was used and the results showed that most of the responses were accurate and acceptable in relation to longitudinal and lateral dynamics. Based on the results, the authors suggested that the proposed framework could be useful for developing low-cost vehicle simulation systems that require fast computational output.",Nariman Fouladinejad and Nima Fouladinejad and Mohamad Kasim Abdul Jalil and Jamaludin Mohd Taib,10.1177/0037549716675956,https://doi-org.crai.referencistas.com/10.1177/0037549716675956,SIMULATION,12,1087–1102,Development of a surrogate-based vehicle dynamic model to reduce computational delays in a driving simulator,https://doi-org.crai.referencistas.com/10.1177/0037549716675956,92,2016c,
article,doi:10.1177/0261927X20969752,"Politics is an area that is traditionally believed to be gender divided. According to intergroup communication theory, this gender-salient context might cause differences in political communications between genders. Moreover, the internet and social media, which creates a computer-mediated interactive context, might also impact the traditional gender discrepancies in political discourse. This study used Twitter trace-data and computational text analysis to examine such suppositions. By analyzing over one million tweets, we found that compared to men, women generally had a stronger sense of group awareness and cohesion and showed a desire to promote their tweets while avoiding addressing other users in political discussions. Women also focused on family- and home-related issues more than men did. These findings suggest that Twitter is not an ideal public sphere where differences and inequalities are eliminated, but it might be a counter-public sphere that promotes the voices and increases the publicity of marginalized groups.",Lingshu Hu and Michael Wayne Kearney,10.1177/0261927X20969752,https://doi-org.crai.referencistas.com/10.1177/0261927X20969752,Journal of Language and Social Psychology,4,482–503,Gendered Tweets: Computational Text Analysis of Gender Differences in Political Discussion on Twitter,https://doi-org.crai.referencistas.com/10.1177/0261927X20969752,40,2021d,
article,doi:10.1177/1468087417701280,"Mixing and combustion of engine combustion network Spray A after end of injection are modeled using highly resolved multidimensional numerical simulations to explore the physics underlying recent experimental observations of combustion recession. Reacting spray simulations are performed using a traditional Lagrangian–Eulerian coupled formulation for two-phase mixture transport with a Reynolds-averaged Navier–Stokes approach using the open-source computational fluid dynamics code OpenFOAM. Chemical kinetics models for n-dodecane by Cai et al. and Yao et al. are deployed to evaluate the impact of mechanism formulation and low-temperature chemistry on predictions of combustion recession behavior. Simulations with the Cai mechanism show that under standard Spray A conditions, the end-of-injection transient induces second-stage ignition in distinct regions near the nozzle that are initially spatially separated from the lifted diffusion flame, but then rapidly merge with flame. By contrast, the Yao mechanism fails to predict sufficient low-temperature chemistry in mixtures upstream of the diffusion flame during the end-of-injection transient and does not predict combustion recession for the same conditions. The effects of the shape and duration of the end-of-injection transient on the entrainment wave near the nozzle, the likelihood of combustion recession, and the spatiotemporal development of mixing and chemistry in near-nozzle mixtures are also investigated. With a more rapid ramp-down injection profile (ramp-down duration < 400 µs), a weaker combustion recession occurs earlier in time after the start of ramp-down. For extremely fast ramp-down (ramp-down duration = 0), the entrainment flux varies rapidly near the nozzle and over-leaning of the mixture completely suppresses combustion recession. For a slower ramp-down profile with respect to the standard Spray A condition, complete combustion recession back toward the nozzle is observed and combustion recession occurred later in time. Simulations qualitatively agreed with the past experimental and modeling observations of combustion recession with different end-of-injection transients.",Dorrin Jarrahbashi and Sayop Kim and Benjamin W Knox and Caroline L Genzale,10.1177/1468087417701280,https://doi-org.crai.referencistas.com/10.1177/1468087417701280,International Journal of Engine Research,10,1088–1110,Computational analysis of end-of-injection transients and combustion recession,https://doi-org.crai.referencistas.com/10.1177/1468087417701280,18,2017e,
article,doi:10.1177/1538574413503561,"Objectives: To evaluate hemodynamic changes during aneurysmal dilatation in chronic type B aortic dissections compared to hemodynamic parameters in the healthy aorta with the use of computational fluid dynamics (CFD). Methods: True lumen (TL)/false lumen (FL) dimensional changes, changes in total pressure (TP), and wall shear stress (WSS) were evaluated at follow-up (FU) compared to initial examination (IE) with transient CFD simulation with geometries derived from clinical image data and inflow boundary conditions from magnetic resonance images. The TL/FL pressure gradient between ascending and descending aorta (DAo) and maximum WSS at the site of largest dilatation was compared to values for the healthy aorta. Results: Hemodynamic changes at site of largest FL dilatation included 77% WSS reduction and 69% TP reduction. Compared to the healthy aorta, pressure gradient between ascending and DAo was a factor of 1.4 higher in the TL and a factor of 1.5 in the FL and increased at FU (1.6 and 1.7, respectively). Maximum WSS at the site of largest dilatation was a factor of 3 lower than that for the healthy aorta at IE and decreased by more than a factor of 2 at FU. Conclusions: The FL dilatation at FU favorably reduced TP. In contrast, unfavorable increase in pressure gradient between ascending and DAo was observed with higher values than in the healthy aorta. Maximum WSS was reduced at the site of largest dilation compared to healthy aorta.",Christof Karmonik and Matthias Müller-Eschner and Sasan Partovi and Philipp Geisbüsch and Maria-Katharina Ganten and Jean Bismuth and Mark G. Davies and Dittmar Böckler and Matthias Loebe and Alan B. Lumsden et al.,10.1177/1538574413503561,https://doi-org.crai.referencistas.com/10.1177/1538574413503561,Vascular and Endovascular Surgery,8,625–631,Computational Fluid Dynamics Investigation of Chronic Aortic Dissection Hemodynamics Versus Normal Aorta,https://doi-org.crai.referencistas.com/10.1177/1538574413503561,47,2013f,PMID:24048257
article,doi:10.1177/2053951720949571,"This article introduces an interpretative approach to the analysis of situations in computational settings called situational analytics. I outline the theoretical and methodological underpinnings of this approach, which is still under development, and show how it can be used to surface situations from large data sets derived from online platforms such as YouTube. Situational analytics extends to computationally-mediated settings a qualitative methodology developed by Adele Clarke, Situational Analysis (2005), which uses data mapping to detect heterogeneous entities in fieldwork data to determine ‘what makes a difference’ in a situation. Situational analytics scales up this methodology to analyse situations latent in computational data sets with semi-automated methods of textual and visual analysis. I discuss how this approach deviates from recent analyses of situations in computational social science, and argue that Clarke’s framework renders tractable a fundamental methodological problem that arises in this area of research: while social researchers turn to computational settings in order to analyse social life, the social processes unfolding in these envirnoments are fundamentally affected by the computational architectures in which they occur. Situational analytics offers a way to address this problematic by making a heterogeneously composed situation – involving social, technical and media elements – the unit of computational analysis. To conclude, I show how situational analytics can be applied in a case study of YouTube videos featuring intelligent vehicles and discuss how situational analysis itself needs to be elaborated if we are to come to terms with computational transformations of the situational fabric of social life.",Noortje Marres,10.1177/2053951720949571,https://doi-org.crai.referencistas.com/10.1177/2053951720949571,Big Data & Society,2,2053951720949571,For a situational analytics: An interpretative methodology for the study of situations in computational settings,https://doi-org.crai.referencistas.com/10.1177/2053951720949571,7,2020g,
article,doi:10.1177/0957456516655224,"Ever-rising fuel costs necessitate design of fuel-efficient vehicles. Consequently, modern vehicle manufacturers are focused on designing low aerodynamic drag vehicles which would in-turn reduce the fuel consumption. This study analyses the contribution of external rear-view mirrors to the total drag force and the overall sound pressure level at the A, B and C pillars, while optimising the external rear-view mirror design accordingly. Solid Works renditions of external rear-view mirror models mounted on a reference luxury sedan were analysed using a commercially available computational fluid dynamic package ANSYS FLUENT. A different approach was followed to carry out the empirical flow visualisation and predict sound pressure levels. The aerodynamic characterisation of the vehicle was done utilising the widely used shear stress transport turbulence model, while the analysis of wind noise and the contributing vortices employed a large eddy simulation. This approach significantly reduced computational time without compromising on accuracy.",Yagnavalkya Mukkamala and Sandeep Devabhaktuni and Vishnu Ganesh Rajkumar,10.1177/0957456516655224,https://doi-org.crai.referencistas.com/10.1177/0957456516655224,Noise & Vibration Worldwide,1–2,7–16,Computational aero-acoustic modelling of external rear-view mirrors on a mid-sized Sedan,https://doi-org.crai.referencistas.com/10.1177/0957456516655224,47,2016h,
article,doi:10.5772/50932,"Conflict management is one of the most important issues in leveraging organizational competitiveness. However, traditional social scientists built theories or models in this area which were mostly expressed in words and diagrams are insufficient. Social science research based on computational modeling and simulation is beginning to augment traditional theory building. Simulation provides a method for people to try their actions out in a way that is cost effective, faster, appropriate, flexible, and ethical. In this paper, a computational simulation model for conflict management in team building is presented. The model is designed and used to explore the individual performances related to the combination of individuals who have a range of conflict handling styles, under various types of resources and policies. The model is developed based on agent-based modeling method. Each of the agents has one of the five conflict handling styles: accommodation, compromise, competition, contingency, and learning. There are three types of scenarios: normal, convex, and concave. There are two types of policies: no policy, and a reward and punishment policy. Results from running the model are also presented. The simulation has led us to derive two implications concerning conflict management. First, a concave type of resource promotes competition, while convex type of resource promotes compromise and collaboration. Second, the performance ranking of different styles can be influenced by introducing different policies. On the other hand, it is possible for us to promote certain style by introducing different policies.",W. M. Wang and S. L. Ting,10.5772/50932,https://doi-org.crai.referencistas.com/10.5772/50932,International Journal of Engineering Business Management, ,14,Development of a Computational Simulation Model for Conflict Management in Team Building,https://doi-org.crai.referencistas.com/10.5772/50932,3,2011i,
article,doi:10.1177/1029864918757595,"In musicology, there has been a long debate about a meaningful partitioning and description of music history regarding composition styles. Particularly, concepts of historical periods have been criticized since they cannot account for the continuous and interwoven evolution of style. To systematically study this evolution, large corpora are necessary suggesting the use of computational strategies. This article presents such strategies and experiments relying on a dataset of 2000 audio recordings, which cover more than 300 years of music history. From the recordings, we extract different tonal features. We propose a method to visualize these features over the course of history using evolution curves. With the curves, we re-trace hypotheses concerning the evolution of chord transitions, intervals, and tonal complexity. Furthermore, we perform unsupervised clustering of recordings across composition years, individual pieces, and composers. In these studies, we found independent evidence of historical periods that broadly agrees with traditional views as well as recent data-driven experiments. This shows that computational experiments can provide novel insights into the evolution of styles.",Christof Weiß and Matthias Mauch and Simon Dixon and Meinard Müller,10.1177/1029864918757595,https://doi-org.crai.referencistas.com/10.1177/1029864918757595,Musicae Scientiae,4,486–507,Investigating style evolution of Western classical music: A computational approach,https://doi-org.crai.referencistas.com/10.1177/1029864918757595,23,2019j,
article,doi:10.1177/00222429231221698,"McShane et al.’s (2024) wide-ranging critique of null hypothesis significance testing provides a number of specific suggestions for improved practice in empirical research. This commentary amplifies several of these from the perspective of computational statistics—particularly nonparametrics, resampling/bootstrapping, and Bayesian methods—applied to common research problems. Throughout, the author emphasizes estimation (as opposed to testing) and uncertainty quantification through a comprehensive process of “curating” a variety of graphical and tabular evidence. Specifically, researchers should be encouraged to estimate the quantities that matter, with as few assumptions as possible, in multiple ways, then try to visualize it all, documenting their pathway from data to results for others to follow.",Fred Feinberg,10.1177/00222429231221698,https://doi-org.crai.referencistas.com/10.1177/00222429231221698,Journal of Marketing,3,20–28,p-Values as QWERTY: Curating Evidence in the Computational Era,https://doi-org.crai.referencistas.com/10.1177/00222429231221698,88,2024a,
article,doi:10.1243/09544062JMES2464,"A robust approach to computational kinematics intended to cope with algorithmic singularities is introduced in this article. The approach is based on the reduction of the original system of equations to a subsystem of bivariate equations, as opposed to the multivariate polynomial reduction leading to the characteristic univariate polynomial. The effectiveness of the approach is illustrated for the exact function-generation synthesis of planar, spherical, and spatial four-bar linkages. Some numerical examples are provided for the case of the spherical four-bar function generator with six precision points to show the benefits of the proposed method with respect to methods reported in the literature.",L Gracia and J Angeles,10.1243/09544062JMES2464,https://doi-org.crai.referencistas.com/10.1243/09544062JMES2464,"Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science",4,987–999,Robustness to algorithmic singularities and sensitivity in computational kinematics,https://doi-org.crai.referencistas.com/10.1243/09544062JMES2464,225,2011b,
article,doi:10.1177/0261927X20969752,"Politics is an area that is traditionally believed to be gender divided. According to intergroup communication theory, this gender-salient context might cause differences in political communications between genders. Moreover, the internet and social media, which creates a computer-mediated interactive context, might also impact the traditional gender discrepancies in political discourse. This study used Twitter trace-data and computational text analysis to examine such suppositions. By analyzing over one million tweets, we found that compared to men, women generally had a stronger sense of group awareness and cohesion and showed a desire to promote their tweets while avoiding addressing other users in political discussions. Women also focused on family- and home-related issues more than men did. These findings suggest that Twitter is not an ideal public sphere where differences and inequalities are eliminated, but it might be a counter-public sphere that promotes the voices and increases the publicity of marginalized groups.",Lingshu Hu and Michael Wayne Kearney,10.1177/0261927X20969752,https://doi-org.crai.referencistas.com/10.1177/0261927X20969752,Journal of Language and Social Psychology,4,482–503,Gendered Tweets: Computational Text Analysis of Gender Differences in Political Discussion on Twitter,https://doi-org.crai.referencistas.com/10.1177/0261927X20969752,40,2021c,
article,doi:10.1177/1468087417701280,"Mixing and combustion of engine combustion network Spray A after end of injection are modeled using highly resolved multidimensional numerical simulations to explore the physics underlying recent experimental observations of combustion recession. Reacting spray simulations are performed using a traditional Lagrangian–Eulerian coupled formulation for two-phase mixture transport with a Reynolds-averaged Navier–Stokes approach using the open-source computational fluid dynamics code OpenFOAM. Chemical kinetics models for n-dodecane by Cai et al. and Yao et al. are deployed to evaluate the impact of mechanism formulation and low-temperature chemistry on predictions of combustion recession behavior. Simulations with the Cai mechanism show that under standard Spray A conditions, the end-of-injection transient induces second-stage ignition in distinct regions near the nozzle that are initially spatially separated from the lifted diffusion flame, but then rapidly merge with flame. By contrast, the Yao mechanism fails to predict sufficient low-temperature chemistry in mixtures upstream of the diffusion flame during the end-of-injection transient and does not predict combustion recession for the same conditions. The effects of the shape and duration of the end-of-injection transient on the entrainment wave near the nozzle, the likelihood of combustion recession, and the spatiotemporal development of mixing and chemistry in near-nozzle mixtures are also investigated. With a more rapid ramp-down injection profile (ramp-down duration < 400 µs), a weaker combustion recession occurs earlier in time after the start of ramp-down. For extremely fast ramp-down (ramp-down duration = 0), the entrainment flux varies rapidly near the nozzle and over-leaning of the mixture completely suppresses combustion recession. For a slower ramp-down profile with respect to the standard Spray A condition, complete combustion recession back toward the nozzle is observed and combustion recession occurred later in time. Simulations qualitatively agreed with the past experimental and modeling observations of combustion recession with different end-of-injection transients.",Dorrin Jarrahbashi and Sayop Kim and Benjamin W Knox and Caroline L Genzale,10.1177/1468087417701280,https://doi-org.crai.referencistas.com/10.1177/1468087417701280,International Journal of Engine Research,10,1088–1110,Computational analysis of end-of-injection transients and combustion recession,https://doi-org.crai.referencistas.com/10.1177/1468087417701280,18,2017d,
article,doi:10.1177/1350650112466769,"Interfacial phenomena between the wafer and the polishing pad during chemical mechanical polishing are an area of great interest as they affect post-chemical mechanical polishing wafer topographies. Traditionally, the Reynolds equation has been used to predict the fluid pressure between the wafer and the polishing pad. However, with computational fluid dynamics it is possible to predict the fluid pressure and obtain insight into the fluid motion at the leading edge and trailing edge of the wafer. Additionally, computational fluid dynamics allows for the added ability to increase the resolution of the fluid physics to the asperity scale. In this study, a model is developed to predict phenomena related to mixed lubrication chemical mechanical polishing using computational fluid dynamics. Contact mechanics between the wafer and the pad are resolved through a Winkler elastic foundation formulation. The wafer is mounted on a ball joint which allows free rotation to occur. Friction between the wafer and the polishing pad causes the wafer to assume a position which produces a sub-ambient pressure distribution similar to that obtained from experiments. The effects of different table speeds on the interfacial fluid pressure, as predicted by the computational fluid dynamics are presented.",Jeremiah N Mpagazehe and C Fred Higgs,10.1177/1350650112466769,https://doi-org.crai.referencistas.com/10.1177/1350650112466769,"Proceedings of the Institution of Mechanical Engineers, Part J: Journal of Engineering Tribology",7,777–786,A three-dimensional transient model to predict interfacial phenomena during chemical mechanical polishing using computational fluid dynamics,https://doi-org.crai.referencistas.com/10.1177/1350650112466769,227,2013e,
article,doi:10.1177/21677026211022013,"Suicide, a leading cause of death, is a complex and a hard-to-predict human tragedy. In this article, we introduce a comprehensive outlook on the emerging movement to integrate computational linguistics (CL) in suicide prevention research and practice. Focusing mainly on the state-of-the-art deep neural network models, in this “travel guide” article, we describe, in a relatively plain language, how CL methodologies could facilitate early detection of suicide risk. Major potential contributions of CL methodologies (e.g., word embeddings, interpretational frameworks) for deepening that theoretical understanding of suicide behaviors and promoting the personalized approach in psychological assessment are presented as well. We also discuss principal ethical and methodological obstacles in CL suicide prevention, such as the difficulty to maintain people’s privacy/safety or interpret the “black box” of prediction algorithms. Ethical guidelines and practical methodological recommendations addressing these obstacles are provided for future researchers and clinicians.",Yaakov Ophir and Refael Tikochinski and Anat Brunstein Klomek and Roi Reichart,10.1177/21677026211022013,https://doi-org.crai.referencistas.com/10.1177/21677026211022013,Clinical Psychological Science,2,212–235,The Hitchhiker’s Guide to Computational Linguistics in Suicide Prevention,https://doi-org.crai.referencistas.com/10.1177/21677026211022013,10,2022f,
article,doi:10.1177/1754073909103589,"Based on the belief that computational modeling (thinking in terms of representation and computations) can help to clarify controversial issues in emotion theory, this article examines emotional experience from the perspective of the Computational Belief–Desire Theory of Emotion (CBDTE), a computational explication of the belief–desire theory of emotion. It is argued that CBDTE provides plausible answers to central explanatory challenges posed by emotional experience, including: the phenomenal quality, intensity and object-directedness of emotional experience, the function of emotional experience and its relation to cognition and motivation, and the relation between emotional experience and emotion. In addition, CBDTE avoids most objections that have been raised against cognitive theories of emotion. A remaining objection, that beliefs are not necessary for the emotions covered by CBDTE, is rejected as empirically unsupported.",Rainer Reisenzein,10.1177/1754073909103589,https://doi-org.crai.referencistas.com/10.1177/1754073909103589,Emotion Review,3,214–222,Emotional Experience in the Computational Belief–Desire Theory of Emotion,https://doi-org.crai.referencistas.com/10.1177/1754073909103589,1,2009g,
article,doi:10.3233/JHS-130457,"Over the past decade, the ever-increasing energy demands of IT infrastructures have posed significant challenges for the research community in terms of reducing their total power consumption and minimizing their environmental impact. Optical communication networks are envisioned to be promising candidates to help preventing this problem affecting the Internet backbone, as well as for distributed applications such as computational grids. In this paper, we propose an adaptive and distributed scheme for the establishment of energy-efficient lightpaths in computational grids. The grid is deployed over an optical circuit-switched backbone network, defining an optical grid network. Each node of the backbone network maintains two different dynamic thresholds values and estimates the changes in network performance by evaluating the moving average of the total wavelength channel occupancy on all its input/output links. The nodes have the ability of reducing the energy consumption by entering into an Energy Saving Mode (ESM) on the basis of a comparison between their channel occupancy and the thresholds. Furthermore, we extend our framework by allowing the thresholds to be dynamically adapted depending on the network performance in terms of blocking probability. We show that the proposed method achieves considerable energy savings when compared to a normal energy-unaware operational mode and still allows to maintain an acceptable level of network performance in terms of blocking probability and end-to-end delay. Numerical results are obtained with a Java event-driven simulator of two different optical network topologies.",Daniele Tafani and Burak Kantarci and Hussein T. Mouftah and Conor McArdle and Liam P. Barry,10.3233/JHS-130457,https://doi-org.crai.referencistas.com/10.3233/JHS-130457,Journal of High Speed Networks,1,1–18,A distributed framework for energy-efficient lightpaths in computational grids,https://doi-org.crai.referencistas.com/10.3233/JHS-130457,19,2013h,
article,doi:10.1177/0036850419901235,"Hydrodynamic effects of mussel farms have attracted increased research attentions in recent years. The understanding of the hydrodynamic impacts is essential for predicting the sustainability of mussel farms. A large mussel farm includes thousands of mussel droppers, and the combined drag on the mussel droppers is sufficient to possibly affect the longevity of the entire long-lines. This article intends to study the drag and wake of an individual long-line mussel dropper using computational fluid dynamics approaches. Two equivalent rough cylinders, namely, Curved-Model and Sharp-Model, have been utilized to simulate the mussel dropper, and each rough cylinder is assigned with surface roughness. The porosity is not considered in this article due to its complexity from inhalant and exhalant of mussels. Two-dimensional laminar simulations are conducted at Reynolds number from 10 to 200, and three-dimensional large eddy simulations are conducted at subcritical Reynolds number ranging from 3900 to . The results show that larger drag coefficients and Strouhal numbers are attributed to surface roughness and sharp crowns on the rough cylinder. The obtained drag coefficient ranges from 1.1 to 1.2 with respect to the diameter of the mussel dropper and the peak value of the tidal velocities. Wakes behind rough cylinders fluctuate more actively compared to those of smooth cylinders. This research work provides new insight for further investigations on hydrodynamic interactions between fluid and mussel droppers.",Zhijing Xu and Hongde Qin and Peng Li and Rujun Liu,10.1177/0036850419901235,https://doi-org.crai.referencistas.com/10.1177/0036850419901235,Science Progress,1,0036850419901235,Computational fluid dynamics approaches to drag and wake of a long-line mussel dropper under tidal current,https://doi-org.crai.referencistas.com/10.1177/0036850419901235,103,2020i,PMID:32024433
article,doi:10.1177/07356331231213548,"Robotics education has received widespread attention in K-12 education. Studies have pointed out that in robotics courses, learners face challenges in learning abstract content, such as constructing a robot with a good structure and writing programs to drive a robot to complete specific learning tasks. The present study proposed the embodied learning-based computer programming approach and applied it to the LEGO Mindstorms EV3 robotics course. To evaluate its effectiveness, a quasi-experiment was conducted in one public primary school to explore its effects on students’ learning achievement, learning motivation, learning attitudes, learning engagement, and cognitive load. The experimental group (40 students) adopted the embodied learning-based computer programming approach, while the control group (40 students) adopted the conventional computer programming approach. The results showed that the experimental group had significantly better learning achievement in robotics than the control group, and that there was no significant difference in the cognitive load of the two groups. In terms of learning motivation, although both groups showed improvement, the experimental group had higher intrinsic learning motivation. In addition, the experimental group outperformed the control group with regard to learning attitudes and learning engagement (including cognitive, behavioral, and emotional engagement). Accordingly, this study could contribute to future research for developing more effective robotics teaching approaches and computer programming activity design.",Xinli Zhang and Yuchen Chen and Danqing Li and Lailin Hu and Gwo-Jen Hwang and Yun-Fang Tu,10.1177/07356331231213548,https://doi-org.crai.referencistas.com/10.1177/07356331231213548,Journal of Educational Computing Research,2,532–558,Engaging Young Students in Effective Robotics Education: An Embodied Learning-Based Computer Programming Approach,https://doi-org.crai.referencistas.com/10.1177/07356331231213548,62,2024j,
article,doi:10.1177/1176934319840289,"Reversible phosphorylation maintained by protein kinases and phosphatases is an integral part of intracellular signalling, and phosphorylation on tyrosine is extensively utilised in higher eukaryotes. Tyrosine phosphatases are enzymes that not only scavenge phosphotyrosine but are also involved in wide range of signalling pathways. As a result, mutations in these enzymes have been implicated in the pathogenesis of several diseases like cancer, autoimmune disorders, and muscle-related diseases. The genes that harbour phosphatase domain also display diversity in co-existing domains suggesting the recruitment of the catalytic machinery in diverse pathways. We have examined the current draft of the human genome, using a combination of 3 sequence search methods and validations, and identified 101 genes encoding tyrosine phosphatase-containing gene products, agreeing with previous reports. Such gene products adopt 37 unique domain architectures (DAs), including few new ones and harbouring few co-existing domains that have not been reported before. This semi-automated computational approach for detection of gene products belonging to a particular superfamily can now be easily applied at whole genome level on other mammalian genomes and for other protein domains as well.",Teerna Bhattacharyya and Ramanathan Sowdhamini,10.1177/1176934319840289,https://doi-org.crai.referencistas.com/10.1177/1176934319840289,Evolutionary Bioinformatics, ,1176934319840289,Genome-Wide Search for Tyrosine Phosphatases in the Human Genome Through Computational Approaches Leads to the Discovery of Few New Domain Architectures,https://doi-org.crai.referencistas.com/10.1177/1176934319840289,15,2019a,PMID:31007525
article,doi:10.1177/10755470231165941,"This research note describes ByrdBot, a science communication tool that leverages bird songs to communicate data regarding human impacts on the environment. With ByrdBot, listeners can compare simulated soundscapes of 1970, 2017, and 2065 to immediately, and viscerally, experience decades of past or projected future environmental change. The communication tactic of ByrdBot—what we call emergent sonification—is discussed as one that capitalizes on computational media to facilitate attunement to nonhuman voices and, subsequently, to offer an affective grasping of the impacts of such phenomena as habitat destruction and climate change on wildlife displacement and loss.",Miles C. Coleman and Brandon Simon and Matt Pierce and Charles A. Schutte,10.1177/10755470231165941,https://doi-org.crai.referencistas.com/10.1177/10755470231165941,Science Communication,2,252–266,Emergent Sonification: Using Computational Media to Communicate the Anthropocene in ByrdBot,https://doi-org.crai.referencistas.com/10.1177/10755470231165941,45,2023b,
article,doi:10.1177/09610006241265102,"This study aims to contribute to the pertinent body of knowledge by examining the field of data literacy (DL) to better understand its trends and evolution, thematic clusters, relevant studies and the most productive authors and journals. The analysis of scientific literature indexed by Web of Science from 1980 to 2023 (n = 1704 items) combined co-occurrence (using VOSviewer) and co-citation (using CiteSpace) techniques based on the words in the title and abstract, as well as the keywords, authors and journals. There is evidence of four main trend topics (Data Literacy, Statistical Literacy, Data-based assessment and e-society) and six thematic clusters (Data Literacy, Statistical Literacy, Quantitative Literacy, Big Data, Data Science and Quantitative Skills). With DL emerging in 2011, the research initially focused on both quantitative and statistical literacy, and later (2012–2016) shifted toward applying statistical literacy to various disciplines. Since 2018, the use of data has led to the emergence of fields like big data and data science, resulting in progress being made in data literacy. The combination of the two analysis techniques offers complementary perspectives: co-word analysis reveals fields of application, and co-citation analysis shows the internal evolution of the discipline. This study evidences a significant increase in publications on DL, indicating its expansion to several disciplines and a promising, yet uncertain, future.",Rosaura Fernández-Pascual and Maria Pinto and Francisco Javier García Marco,10.1177/09610006241265102,https://doi-org.crai.referencistas.com/10.1177/09610006241265102,Journal of Librarianship and Information Science,0,09610006241265102,Emergence and evolution of data literacy: Insights from a bibliometric study,https://doi-org.crai.referencistas.com/10.1177/09610006241265102,0,2024c,
article,doi:10.1177/1350650117743684,"The performance of air bearing is highly influenced by the geometrical parameters of its restrictor. This study aims to maximize the load-carrying capacity and stiffness of air bearing, and minimize its volume flow rate by optimizing the geometrical parameters of restrictor. To facilitate the calculation of air bearing performance, a parametric computational fluid dynamics model is developed. Then, it is combined with multiobjective optimization genetic algorithm to search the Pareto optimal solutions. Furthermore, as a case study, the optimal design of an annular thrust air bearing is implemented. The stiffness of air bearing is improved 38.5%, the load-carrying capacity is improved 33.9%, and the volume flow rate is declined 19.6%, which are finally validated by experiments. It proves the reliability of proposed parametric computational fluid dynamics model and genetic optimization algorithm.",Qiang Gao and Lihua Lu and Wanqun Chen and Guanglin Wang,10.1177/1350650117743684,https://doi-org.crai.referencistas.com/10.1177/1350650117743684,"Proceedings of the Institution of Mechanical Engineers, Part J: Journal of Engineering Tribology",10,1203–1214,Optimal design of an annular thrust air bearing using parametric computational fluid dynamics model and genetic algorithms,https://doi-org.crai.referencistas.com/10.1177/1350650117743684,232,2018d,
article,doi:10.5301/jva.5000226,Purpose Stenosis in a vascular access circuit is the predominant cause of access dysfunction. Hemodynamic significance of a stenosis identified by angiography in an access circuit is uncertain. This study utilizes computational fluid dynamics (CFD) to model flow through arteriovenous fistula to predict the functional significance of stenosis in vascular access circuits. Methods Three-dimensional models of fistulas were created with a range of clinically relevant stenoses using SolidWorks. Stenoses diameters ranged from 1.0 to 3.0 mm and lengths from 5 to 60 mm within a fistula diameter of 7 mm. CFD analyses were performed using a blood model over a range of blood pressures. Eight patient-specific stenoses were also modeled and analyzed with CFD and the resulting blood flow calculations were validated by comparison with brachial artery flow measured by duplex ultrasound. Results Predicted flow rates were derived from CFD analysis of a range of stenoses. These stenoses were modeled by CFD and correlated with the ultrasound measured flow rate through the fistula of eight patients. The calculated flow rate using CFD correlated within 20% of ultrasound measured flow for five of eight patients. The mean difference was 17.2% (ranged from 1.3% to 30.1%). Conclusions CFD analysis-generated flow rate tables provide valuable information to assess the functional significance of stenosis detected during imaging studies. The CFD study can help in determining the clinical relevance of a stenosis in access dysfunction and guide the need for intervention.,David M. Hoganson and Cameron J. Hinkel and Xiaomin Chen and Ramesh K. Agarwal and Surendra Shenoy,10.5301/jva.5000226,https://doi-org.crai.referencistas.com/10.5301/jva.5000226,The Journal of Vascular Access,5,409–414,Validation of Computational Fluid Dynamics-Based Analysis to Evaluate                     Hemodynamic Significance of access Stenosis,https://doi-org.crai.referencistas.com/10.5301/jva.5000226,15,2014e,PMID:24811588
article,doi:10.1179/0308018814Z.00000000082,"The emergent reflexive process, by which researchers in a computational humanities project work towards a viable organizational modality for interdisciplinary collaboration, is analyzed. Using the metaphor of decomposition, successful collaboration between computer scientists and humanities scholars can be seen to require a reflexive scrutiny — a decomposition — of the disciplinary research processes that are involved, thus allowing crucial differences with respect to typical ways of posing research questions, the role of data, and the rhythm of the research process to be highlighted. It is argued that the currently popular expectation towards data as a self-identical organizational unit tends to downplay the role of decomposition as practice and process. A European cyberinfrastructure initiative that tries to respect the specificities of scholarly practice in the humanities is critically assessed, reflecting in particular on the inherent tension between ‘mutual shaping’ of digital tools and their users on the one hand, and the policy interest in efficient, functionalist design principles on the other.",Wolfgang Kaltenbrunner,10.1179/0308018814Z.00000000082,https://doi-org.crai.referencistas.com/10.1179/0308018814Z.00000000082,Interdisciplinary Science Reviews,2,143–161,Decomposition as Practice and Process: Creating Boundary Objects in Computational Humanities,https://doi-org.crai.referencistas.com/10.1179/0308018814Z.00000000082,39,2014f,
article,doi:10.1177/0165551515615842,"Computational cognitive models of web-navigation developed so far have largely been tested only on mock-up websites. In this paper, for the first time, we compare and contrast the performance of two models, CoLiDeS and CoLiDeS+, on two real websites from the domains of technology and health, under two conditions of task difficulty, simple and difficult. We found that CoLiDeS+ predicted more hyperlinks on the correct path and had a higher path completion ratio than CoLiDeS. CoLiDeS+ found the target page more often than CoLiDeS, took more steps to reach the target page and was more ‘disoriented’ than CoLiDeS for difficult tasks. Difficult tasks in general for both models had less task success and lower path completion ratio, predicted less hyperlinks on the correct path, visited pages with lower mean LSA and took more steps to complete compared with simple tasks. Overall, inclusion of context from previously visited pages and implementation of backtracking strategies (which are both part of CoLiDeS+) led to better modelling performance. Suggestions to further improve the performance of these computational cognitive models on real websites are discussed.",Saraschandra Karanam and Herre van Oostendorp and Wai Tat Fu,10.1177/0165551515615842,https://doi-org.crai.referencistas.com/10.1177/0165551515615842,Journal of Information Science,1,94–113,Performance of computational cognitive models of web-navigation on real websites,https://doi-org.crai.referencistas.com/10.1177/0165551515615842,42,2016g,
article,doi:10.1179/1743285514Y.0000000056,"The smelting of nickel laterite ores to ferronickel alloy is unique in extractive metallurgy. It treats feed that is very low grade with respect to the target metal and, as a result, produces much more waste slag than valuable metal product. The energy consumption per tonne of product is therefore high and requires sustained research and design development in an effort to improve the economics of laterite smelting. In this work, the main characteristics of nickel laterite smelting are reviewed, and then a simple and transparent computational thermodynamics model of the electric furnace smelting step is developed. This model predicts the nickel grade, nickel recovery and FeO content of the slag as functions of the iron recovery to ferronickel satisfactorily. It correctly predicts that the carbon and silicon contents in ferronickel increase sharply at high iron recoveries. However, in common with more sophisticated models, it incorrectly predicts the iron recovery at which this increase is observed in practice. It is concluded that the model provides an accessible and a satisfactorily accurate vehicle for understanding the relationships between process variables and process outcomes during nickel laterite smelting.",D. R. Swinbourne,10.1179/1743285514Y.0000000056,https://doi-org.crai.referencistas.com/10.1179/1743285514Y.0000000056,Mineral Processing and Extractive Metallurgy,3,127–140,Understanding ferronickel smelting from laterites through computational thermodynamics modelling,https://doi-org.crai.referencistas.com/10.1179/1743285514Y.0000000056,123,2014h,
article,doi:10.1177/1094428118780308,"Theories are the core of any science, but many imprecisely stated theories in organizational and management science are hampering progress in the field. Computational modeling of existing theories can help address the issue. Computational models are a type of formal theory that are represented mathematically or by other formal logic and can be simulated, allowing theorists to assess whether the theory can explain the phenomena intended as well as make testable predictions. As an example of the process, Locke’s integrated model of work motivation is translated into static and dynamic computational models. Simulations of these models are compared to the empirical data used to develop and test the theory. For the static model, the simulations revealed largely strong associations with robust empirical findings. However, adding dynamics created several challenges to key precepts of the theory. Moreover, the effort revealed where empirical work is needed to further refine or refute the theory. Discussion focuses on the value of computational modeling as a method for formally testing, pruning, and extending extant theories in the field.",Jeffrey B. Vancouver and Mo Wang and Xiaofei Li,10.1177/1094428118780308,https://doi-org.crai.referencistas.com/10.1177/1094428118780308,Organizational Research Methods,2,238–274,Translating Informal Theories Into Formal Theories: The Case of the Dynamic Computational Model of the Integrated Model of Work Motivation,https://doi-org.crai.referencistas.com/10.1177/1094428118780308,23,2020i,
article,doi:10.4137/BECB.S5594,"Molecular biology focuses on genes and their interactions at the transcription, regulation and protein level. Finding genes that cause certain behaviors can make therapeutic interventions more effective. Although biological tools can extract the genes and perform some analyses, without the help of computational methods, deep insight of the genetic function and its effects will not occur. On the other hand, complex systems can be modeled by networks, introducing the main data as nodes and the links in-between as the transactions occurring within the network. Gene regulatory networks are examples that are modeled and analyzed in order to gain insight of their exact functions. Since a cell’s specific functionality is greatly determined by the genes it expresses, translation or the act of converting mRNA to proteins is highly regulated by the control network that directs cellular activities. This paper briefly reviews the most important computational methods for analyzing, modeling and controlling the gene regulatory networks.",Zahra Zamani and Amirhossein Hajihosseini and Ali Masoudi-Nejad,10.4137/BECB.S5594,https://doi-org.crai.referencistas.com/10.4137/BECB.S5594,Biomedical Engineering and Computational Biology, ,BECB.S5594,"Computational Methodologies for Analyzing, Modeling and Controlling Gene Regulatory Networks",https://doi-org.crai.referencistas.com/10.4137/BECB.S5594,2,2010j,
article,doi:10.1177/104538902761696814,"In this paper we discuss the sound absorption property of arrays of micro-acoustic actuators at a control surface. We use the wave equation over the half plane for the velocity potential with a boundary dissipation by a proportional pressure feedback law along the half plane boundary. The feedback gain over the array is described by a distributed shape function. We develop a computational method based on the Fourier transform and employ it for analyzing and evaluating the decay rate of acoustic energy. Specifically, we carry out computations for a diffusive random initial field and report on our resulting numerical findings.",H. T. Banks and D. G. Cole and K. M. Furati and K. Ito and G. A. Pinter,10.1177/104538902761696814,https://doi-org.crai.referencistas.com/10.1177/104538902761696814,Journal of Intelligent Material Systems and Structures,4,231–240,A Computational Model for Sound Field Absorption by Acoustic Arrays,https://doi-org.crai.referencistas.com/10.1177/104538902761696814,13,2002a,
article,doi:10.1177/09610006241265102,"This study aims to contribute to the pertinent body of knowledge by examining the field of data literacy (DL) to better understand its trends and evolution, thematic clusters, relevant studies and the most productive authors and journals. The analysis of scientific literature indexed by Web of Science from 1980 to 2023 (n = 1704 items) combined co-occurrence (using VOSviewer) and co-citation (using CiteSpace) techniques based on the words in the title and abstract, as well as the keywords, authors and journals. There is evidence of four main trend topics (Data Literacy, Statistical Literacy, Data-based assessment and e-society) and six thematic clusters (Data Literacy, Statistical Literacy, Quantitative Literacy, Big Data, Data Science and Quantitative Skills). With DL emerging in 2011, the research initially focused on both quantitative and statistical literacy, and later (2012–2016) shifted toward applying statistical literacy to various disciplines. Since 2018, the use of data has led to the emergence of fields like big data and data science, resulting in progress being made in data literacy. The combination of the two analysis techniques offers complementary perspectives: co-word analysis reveals fields of application, and co-citation analysis shows the internal evolution of the discipline. This study evidences a significant increase in publications on DL, indicating its expansion to several disciplines and a promising, yet uncertain, future.",Rosaura Fernández-Pascual and Maria Pinto and Francisco Javier García Marco,10.1177/09610006241265102,https://doi-org.crai.referencistas.com/10.1177/09610006241265102,Journal of Librarianship and Information Science,0,09610006241265102,Emergence and evolution of data literacy: Insights from a bibliometric study,https://doi-org.crai.referencistas.com/10.1177/09610006241265102,0,2024b,
article,doi:10.1177/15554120231211376,"This article analyzes the configuration of fear generated by the computational monster in computer games. We view the monster as a computational entity, which we approach through our theory of game-play coupled with the concepts of loss aversion and endowment effect. Of particular interest is player perception of the threat posed by monsters as they perturb the experience of progression and the sensation of control within the game. We scrutinize this aspect from a situational as well as an existential perspective. Furthermore, we advance an analytical scheme of the threat of the computational monster, which is radically different from the traditional academic approach with its emphasis on the representation of monsters. Overall, we argue that the threat players perceive when facing monsters in computer games springs more from the computational nature of monsters—how they upset progression and the feeling of control—and less from the representation of the monster(s).",Lasse Juel Larsen and Bo Kampmann Walther,10.1177/15554120231211376,https://doi-org.crai.referencistas.com/10.1177/15554120231211376,Games and Culture,0,15554120231211376,Fear of Monsters: Toward an Understanding of the Threat of the Computational Monster Read Through the Theoretical Lens  of Game-Play,https://doi-org.crai.referencistas.com/10.1177/15554120231211376,0,2023c,
article,doi:10.1179/174328509X431454,"Stainless steel alloys are widely used in many important applications but their production presents difficulties because they contain expensive chromium, which can be extensively oxidised during decarburisation to the very low carbon levels required. Modern stainless steelmaking largely avoids this problem by having two distinct stages and is therefore described as duplex practice. Molten high carbon stainless steel is produced in an electric arc furnace and then the melt is decarburised in an argon–oxygen converter or a vacuum oxygen decarburising converter. In this work, computational thermodynamics has been used to examine the major reactions occurring in the electric arc furnace and to show the effect of various process variables on chromium recovery. It was shown that significant oxidation of the scrap must occur during melting, and that subsequent carbon/oxygen injection initially oxidises some chromium, but then mostly oxidises the added carbon. Chromium was predicted to exist in the slag as CrO and CrO1·5 in almost equal proportions. Increasing the temperature should improve chromium recovery but results in less benefit than expected due to the decreasing activity coefficients of CrO and CrO1·5 and the increasing oxygen partial pressure. Ferrosilicon additions reduce chromium oxides from the slag, but much of the silicon simply dissolves into the steel. Computational thermodynamics is seen to be a very effective educational tool for gaining an understanding of smelting processes.",T. S. Kho and D. R. Swinbourne and B. Blanpain and S. Arnout and D. Langberg,10.1179/174328509X431454,https://doi-org.crai.referencistas.com/10.1179/174328509X431454,Mineral Processing and Extractive Metallurgy,1,1–8,Understanding stainless steelmaking through computational thermodynamics Part 1: electric arc furnace melting,https://doi-org.crai.referencistas.com/10.1179/174328509X431454,119,2010d,
article,doi:10.1177/07356331221143832,This study implemented and evaluated the innovative use of a performance-based assessment platform to support the development of self-regulated learning (SRL) in senior primary students as they completed programming tasks. We embedded SRL support features into a performance-based assessment platform as scaffolding to help the students implement problem-solving strategies. A mixed-methods approach was adopted to evaluate the intervention. The students’ perceptions of their SRL skills after working through the programming tasks were measured by a survey of 45 students. The quantitative results suggested that the students benefited from the performance-based assessment platform in developing their SRL skills. A thematic analysis of interview data from 20 students further indicated that the embedded SRL scaffolding and automatic marking function helped them to solve the programming tasks. The results demonstrate that a well-designed performance-based assessment platform with embedded SRL support can be an effective tool for developing students’ SRL. The qualitative results further revealed that algorithmic thinking is an aspect of programming for which students need more SRL support.,Siu-Cheung Kong and Bowen Liu,10.1177/07356331221143832,https://doi-org.crai.referencistas.com/10.1177/07356331221143832,Journal of Educational Computing Research,5,977–1007,Supporting the Self-Regulated Learning of Primary School Students With a Performance-Based Assessment Platform for Programming Education,https://doi-org.crai.referencistas.com/10.1177/07356331221143832,61,2023e,
article,doi:10.1177/0735633119887508,"This study implemented a data-driven approach to identify Chinese high school students’ common errors in a Java-based introductory programming course using the data in an automated assessment tool called the Mulberry. Students’ error-related behaviors were also analyzed, and their relationships to success in introductory programming were investigated. This study identified 15 common compilation errors and 6 common test errors. The results showed that these common errors accounted for a large proportion of all errors, so identifying the common errors is important to help students succeed in introductory programming courses. Based on these common errors, five underlying student difficulties were identified and are discussed. In addition, after analyzing existing measures of students’ error-related behaviors, we developed a measure called improvement rate to quantify students’ success in fixing errors. The results of our study suggest that students’ competence of improving code is important to their success in introductory programming. We recommend researchers design and develop automated assessment tools that provide feedback messages for common student errors and instructors who explicitly teach knowledge and skills of improving code in class.",Yizhou Qian and James Lehman,10.1177/0735633119887508,https://doi-org.crai.referencistas.com/10.1177/0735633119887508,Journal of Educational Computing Research,5,919–945,An Investigation of High School Students’ Errors in Introductory Programming: A Data-Driven Approach,https://doi-org.crai.referencistas.com/10.1177/0735633119887508,58,2020f,
article,doi:10.1177/2398212818810591,"Metacognition supports reflection upon and control of other cognitive processes. Despite metacognition occupying a central role in human psychology, its neural substrates remain underdetermined, partly due to study-specific differences in task domain and type of metacognitive judgement under study. It is also unclear how metacognition relates to other apparently similar abilities that depend on recursive thought such as theory of mind or mentalising. Now that neuroimaging studies of metacognition are more prevalent, we have an opportunity to characterise consistencies in neural substrates identified across different analysis types and domains. Here we used quantitative activation likelihood estimation methods to synthesise findings from 47 neuroimaging studies on metacognition, divided into categories based on the target of metacognitive evaluation (memory and decision-making), analysis type (judgement-related activation, confidence-related activation, and predictors of metacognitive sensitivity), and, for metamemory judgements, temporal focus (prospective and retrospective). A domain-general network, including medial and lateral prefrontal cortex, precuneus, and insula was associated with the level of confidence in self-performance in both decision-making and memory tasks. We found preferential engagement of right anterior dorsolateral prefrontal cortex in metadecision experiments and bilateral parahippocampal cortex in metamemory experiments. Results on metacognitive sensitivity were inconclusive, likely due to fewer studies reporting this contrast. Finally, by comparing our results to meta-analyses of mentalising, we obtain evidence for common engagement of the ventromedial and anterior dorsomedial prefrontal cortex in both metacognition and mentalising, suggesting that these regions may support second-order representations for thinking about the thoughts of oneself and others.",Anthony G. Vaccaro and Stephen M. Fleming,10.1177/2398212818810591,https://doi-org.crai.referencistas.com/10.1177/2398212818810591,Brain and Neuroscience Advances, ,2398212818810591,Thinking about thinking: A coordinate-based meta-analysis of neuroimaging studies of metacognitive judgements,https://doi-org.crai.referencistas.com/10.1177/2398212818810591,2,2018g,PMID:30542659
article,doi:10.1177/0738894215570433,"Many accounts of civil war violence assume that a conflict’s master cleavage also explains the local occurrence of violence. Some scholars, however, have argued that violence is often the result of local cleavages and feuds, many of which may be unrelated to the conflict’s master cleavage. How is local violence related to the conflict’s master cleavage? Using a computational model, this paper studies an alliance mechanism proposed by Kalyvas (2006, The Logic of Violence in Civil War, Cambridge University Press), where macro-actors support local ones that fight on their behalf. While these alliances create a principal–agent problem, the model shows that they can raise the overall severity of the conflict and serve the interests of the macro-actor. However, the model also shows that these mechanisms work only under limited conditions. Alliances can increase the level of violence perpetrated in the interest of the macro-actor, but only if (a) the latter supports agents that have in the past fought along the master cleavage and if (b) this happens in rural areas. This emphasizes again the importance of the rural dimension in the study of civil war.",Nils B. Weidmann,10.1177/0738894215570433,https://doi-org.crai.referencistas.com/10.1177/0738894215570433,Conflict Management and Peace Science,5,539–558,Micro-cleavages and violence in civil wars: A computational assessment,https://doi-org.crai.referencistas.com/10.1177/0738894215570433,33,2016h,
article,doi:10.1177/1729881418766190,"Accurate calculation of canopy aerodynamic parameters is a prerequisite for precise modeling of a parafoil airdrop system. This investigation analyses the aerodynamic performance of the canopy in airdrop testing combining the leading-edge incision and the trailing-edge deflection. Aerodynamic parameters of the canopy are obtained using the computational fluid dynamic simulations, and then, the output data are used to estimate the deflection and incision factors. The estimated lift and drag coefficients instead of the traditional parameters based on lifting-line theory are incorporated into the eight degrees of freedom dynamic model of an airdrop system and make some simulations. The effectiveness of the proposed method for calculating aerodynamic coefficients is verified by actual airdrop testing.",Wannan Wu and Qinglin Sun and Shuzhen Luo and Mingwei Sun and Zengqiang Chen and Hao Sun,10.1177/1729881418766190,https://doi-org.crai.referencistas.com/10.1177/1729881418766190,International Journal of Advanced Robotic Systems,2,1729881418766190,Accurate calculation of aerodynamic coefficients of parafoil airdrop system based on computational fluid dynamic,https://doi-org.crai.referencistas.com/10.1177/1729881418766190,15,2018i,
article,doi:10.1177/0049124115610347,"Model uncertainty is pervasive in social science. A key question is how robust empirical results are to sensible changes in model specification. We present a new approach and applied statistical software for computational multimodel analysis. Our approach proceeds in two steps: First, we estimate the modeling distribution of estimates across all combinations of possible controls as well as specified functional form issues, variable definitions, standard error calculations, and estimation commands. This allows analysts to present their core, preferred estimate in the context of a distribution of plausible estimates. Second, we develop a model influence analysis showing how each model ingredient affects the coefficient of interest. This shows which model assumptions, if any, are critical to obtaining an empirical result. We demonstrate the architecture and interpretation of multimodel analysis using data on the union wage premium, gender dynamics in mortgage lending, and tax flight migration among U.S. states. These illustrate how initial results can be strongly robust to alternative model specifications or remarkably dependent on a knife-edge specification.",Cristobal Young and Katherine Holsteen,10.1177/0049124115610347,https://doi-org.crai.referencistas.com/10.1177/0049124115610347,Sociological Methods & Research,1,3–40,Model Uncertainty and Robustness: A Computational Framework for Multimodel Analysis,https://doi-org.crai.referencistas.com/10.1177/0049124115610347,46,2017j,
article,doi:10.1177/07356331211004048,"As schools and districts across the United States adopt computer science standards and curriculum for K-12 computer science education, they look to integrate the foundational concepts of computational thinking (CT) into existing core subjects of elementary-age students. Research has shown the effectiveness of teaching CT elements (abstraction, generalization, decomposition, algorithmic thinking, debugging) using non-programming, unplugged approaches. These approaches address common barriers teachers face with lack of knowledge, familiarity, or technology tools. Picture books and graphic novels present an unexplored non-programming, unplugged resource for teachers to integrate computational thinking into their CT or CT-integrated lessons. This analysis examines 27 picture books and graphic novels published between 2015 and 2020 targeted to K-6 students for representation of computational thinking elements. Using the computational thinking curriculum framework for K-6, we identify the grade-level competencies of the CT elements featured in the books compared to the books’ target age groups. We compare grade-level competencies to interest level to identify each CT element representation as “foundational,” “on-target,” or “advanced.” We conclude that literature offers teachers a non-programming unplugged resource to expose students to CT and enhance CT and CT-integrated lessons, while also personalizing learning based on CT readiness and interest level.",Evan David Ballard and Rachelle Haroldson,10.1177/07356331211004048,https://doi-org.crai.referencistas.com/10.1177/07356331211004048,Journal of Educational Computing Research,8,1487–1516,Analysis of Computational Thinking in Children’s Literature for K-6 Students: Literature as a Non-Programming Unplugged Resource,https://doi-org.crai.referencistas.com/10.1177/07356331211004048,59,2022a,
article,doi:10.1177/1476718X231175464,"Computational thinking (CT) has emerged as an important method in the United States for helping children learn to solve complex problems and develop skills necessary for coding and other computer science-related endeavors. Research has revealed that CT can be encouraged with children as young as 3–4 years of age. While some preschools and schools are incorporating CT into their curriculum for young children, ages 0–8 years, it is important to understand how environments outside of schools are using CT with young children, particularly given that, in the United States, a large percent of young children, ages 0–5 years, are not in formal school settings. This study provides insight into this area through 20 interviews with educators in libraries and museums to understand how they incorporate CT into their work with young children, ages 0–8 years, and their families. The interviews reveal that library and museum educators are using a variety of developmentally-appropriate approaches, such as play, experimentation, and narrative, to design and offer a diverse array of engaging, hands-on CT activities that allow young children to practice CT in child-centered, meaningful ways.",Kathleen Campana and J Elizabeth Mills,10.1177/1476718X231175464,https://doi-org.crai.referencistas.com/10.1177/1476718X231175464,Journal of Early Childhood Research,3,369–383,"Playing, tinkering, and problem solving: Understanding early computational thinking in libraries and museums",https://doi-org.crai.referencistas.com/10.1177/1476718X231175464,21,2023b,
article,doi:10.1177/07356331211055379,"Although abstraction is widely understood to be one of the primary components of computational thinking, the roots of abstraction may be traced back to different fields. Hence, the meaning of abstraction in the context of computational thinking is often confounded, as researchers interpret abstraction through diverse lenses. To disentangle these conceptual threads and gain insight into the operationalisation of abstraction, a systematic review of 96 empirical studies was undertaken. Analysis revealed that identifying features of entities, extracting relevant features, discovering patterns, creating rules and assembling the parts together were the core actions of abstraction. With the primary aim of simplifying practical procedures, abstraction was operationalised as the sophistication of a program, the matching of patterns, the creation of alternative representations, the transfer of solutions, the measurement of a learner’s activity and reading program codes. There is an obvious need for researchers to align the conceptual meanings they have established of abstraction with the practical facts of operationalisation. The need to empirically validate emerging models and the implications for future research are discussed.",Ndudi O. Ezeamuzie and Jessica S.C. Leung and Fridolin S.T. Ting,10.1177/07356331211055379,https://doi-org.crai.referencistas.com/10.1177/07356331211055379,Journal of Educational Computing Research,4,877–905,Unleashing the Potential of Abstraction From Cloud of Computational Thinking: A Systematic Review of Literature,https://doi-org.crai.referencistas.com/10.1177/07356331211055379,60,2022c,
article,doi:10.1177/2347631120970177,"In this article, Fishbone-based advanced computational thinking (FACT) pedagogy is proposed by fusing fishbone pedagogy and computational thinking pedagogy for enhancing teaching-learning process while teaching engineering and science courses, for engineering and science students respectively. The proposed FACT pedagogy has been implemented using the concept of X-ray machine in biomedical instrumentation course and biomolecules, in biochemistry course. Using fishbone approach, various components of X-ray machine in biomedical course and the components of biomolecules in biochemistry course are visually explained as ribs and riblets of a fishbone diagram, without coining the keywords X-ray and biomolecules in an engineering institution and science institution respectively. Finally, the targeted concept is arrived and explained. Similarly, the same concepts of X-ray and biomolecules are coined among students and they are asked to divide or decompose the concepts into sub-concepts separately. To implement and evaluate the proposed pedagogy, an engineering institution and a science institution have been selected and evaluation results have been published in this article. In this pedagogical approach, the same complex concept is taught as a backward thinking by the teacher using fishbone pedagogy and forward thinking by the students using computational thinking pedagogy. This combined approach helps students to understand any complex concept in science courses. Also, it helps the teachers to easily convey and embed the same among the student community while teaching science courses.",B. Gopinath and R. Santhi,10.1177/2347631120970177,https://doi-org.crai.referencistas.com/10.1177/2347631120970177,Higher Education for the Future,1,108–122,Development and Evaluation of Fishbone-Based Advanced Computational Thinking (FACT) Pedagogy: A Teacher-Student Collaborative Learning Environment in Engineering and Science Education,https://doi-org.crai.referencistas.com/10.1177/2347631120970177,8,2021d,
article,doi:10.1177/07356331211057819,"This study describes the development and validation process of a computational thinking (CT) test for adults. The team designed a set of items and explored a subset of those through two qualitative pilots. Then, in order to provide validity evidence based on the test content, a team of 11 subject-matter experts coded the initial pool of items using two different systems of categories based on CT components and contents. Next, the items were piloted on a sample of 289 participants, 137 experts in CT, and 152 novices. After a series of confirmatory factor analyses, a unidimensional model that represents algorithmic thinking was adopted. Further analyzing the psychometric quality of the 27 items, 20 of them with excellent reliability indices were selected for the test. Thus, this study provides a tool to evaluate adults’ CT: the Algorithmic Thinking Test for Adults (ATTA), which was developed according to psychometric standards. This article also reflects on the nature of CT as a construct.",Marc Lafuente Martínez and Olivier Lévêque and Isabel Benítez and Cécile Hardebolle and Jessica Dehler Zufferey,10.1177/07356331211057819,https://doi-org.crai.referencistas.com/10.1177/07356331211057819,Journal of Educational Computing Research,6,1436–1463,Assessing Computational Thinking: Development and Validation of the Algorithmic Thinking Test for Adults,https://doi-org.crai.referencistas.com/10.1177/07356331211057819,60,2022e,
article,doi:10.1177/0735633120905605,"In this work, we examine whether repeated participation in an after-school computing program influenced student learning of computational thinking concepts, practices, and perspectives. We also examine gender differences in learning outcomes. The program was developed through a school–university partnership. Data were collected from 138 students over a 2.5-year period. Data sources included pre–post content assessments of computational concepts related to programming in addition to computational artifacts and interviews with a purposeful sample of 12 participants. Quantitative data were analyzed using statistical methods to identify gains in pre- and post-learning of computational thinking concepts and examine potential gender differences. Interview data were analyzed qualitatively. Results indicated that students made significant gains in their learning of computational thinking concepts and that gains persisted over time. Results also revealed differences in learning of computational thinking concepts among boys and girls both at the beginning and end of the program. Finally, results from student interviews provided insights into the development of computational thinking practices and perspectives over time. Results have implications for the design of after-school computing programs that help broaden participation in computing.",Chrystalla Mouza and Yi-Cheng Pan and Hui Yang and Lori Pollock,10.1177/0735633120905605,https://doi-org.crai.referencistas.com/10.1177/0735633120905605,Journal of Educational Computing Research,5,1029–1056,"A Multiyear Investigation of Student Computational Thinking Concepts, Practices, and Perspectives in an After-School Computing Program",https://doi-org.crai.referencistas.com/10.1177/0735633120905605,58,2020f,
article,doi:10.1177/07356331231180951,"Computational thinking (CT) is considered a fundamental skill that everyone in the 21st century should have. Game-based learning (GBL) may be used to teach CT, and it’s necessary to clarify how to design and implement game-based CT teaching. The literature was systematically searched for empirical studies published between 2011 and 2021. Thirty-nine studies were included in the review and findings suggested that GBL has positive effects on CT, but has non-significant effects on some CT elements (e.g., conditions, triggers, and abstraction) because of limited time to learn these elements and students’ preferences for using CT elements. Game elements, particularly clear goals and rules, progressive challenges, immediate feedback, storyline, avatar, social interaction and various reward mechanisms were used to motivate students to engage in activities to develop CT. Furthermore, single or multiple theoretical foundations, such as constructivist learning theory and experiential learning theory, may guide the design and implementation of game-based activities. Problem-solving, project-based approaches were used to encourage students to use CT to solve problems or complete a project. Finally, guidelines for designing and implementing game-based learning activities for promoting CT were discussed.",Xinyue Wang and Mengmeng Cheng and Xinfeng Li,10.1177/07356331231180951,https://doi-org.crai.referencistas.com/10.1177/07356331231180951,Journal of Educational Computing Research,7,1505–1536,Teaching and Learning Computational Thinking Through Game-Based Learning: A Systematic Review,https://doi-org.crai.referencistas.com/10.1177/07356331231180951,61,2023g,
article,doi:10.1177/0735633120978530,"Computer science and computational thinking (CT) education in K-12 schools have been escalating in recent years. A couple of CT instructional models have been proposed to depict the roles of CT in K-16 education. Yet, neither of them discussed CT infusion into a subject course. In this article, we proposed a CT-integration model called TPC2T. In this model, we suggested considering CT as a second subject and using an appropriate technological pedagogical approach to make students’ learning of two subjects meaningful and engaging. We implemented this model in a CT-integrated lesson in two sections of a high-school Spanish course. Students worked in small groups and coded three small and one comprehensive digital Spanish-culture stories in Scratch. Results showed that students taking the CT-integrated lesson had the same degree of improvement in their Spanish culture knowledge as their peers who did not take the CT-integrated lesson. Besides, students taking the CT-integrated lesson had a significant improvement in their CT knowledge. At the same time, their CT self-efficacy outperformed those who did not take the CT-integrated lesson. We discussed the results and offered suggestions for researchers and educators at the end of the article.",Shenghua Zha and Debra A. L. Morrow and Jennifer Curtis and Shane Mitchell,10.1177/0735633120978530,https://doi-org.crai.referencistas.com/10.1177/0735633120978530,Journal of Educational Computing Research,5,844–869,Learning Culture and Computational Thinking in a Spanish Course: A Development Model,https://doi-org.crai.referencistas.com/10.1177/0735633120978530,59,2021h,
article,doi:10.1177/20965311231158393,"Purpose To analyze mathematics problem-solving (PS) procedures in Chinese (CH) and Canadian (CA) elementary mathematics textbooks that leverage computational thinking (CT) as a cognitive tool, which have evidently existed and been implemented. Design/Approach/Methods In this study, an analysis framework was developed to investigate the characteristics of CT tools for three PS steps—understand the problem, devise and conduct plans, and look back into textbooks—in four contexts: data practices, modeling and simulation practices, computational tools practices, and systemic thinking practices. Findings Our results demonstrate the tools (CT) employed in the PS process in CH and CA mathematics textbooks. The strong connections between the “look back” stage and CT tools were explored. During the “look back” stage, both countries required students to transfer their knowledge and perform generalization. In addition, CT is regarded as a basic skill analysis for students in mathematics education and has received significant attention at every stage of the PS process. Originality/Value This study brings a new perspective to CT research in education by regarding CT as a cognitive tool for students in mathematics PS.",Yimei Zhang (张艺美) and Annie Savard,10.1177/20965311231158393,https://doi-org.crai.referencistas.com/10.1177/20965311231158393,ECNU Review of Education,4,677–699,Defining Computational Thinking as an Evident Tool in Problem-Solving: Comparative Research on Chinese and Canadian Mathematics Textbooks,https://doi-org.crai.referencistas.com/10.1177/20965311231158393,6,2023i,
article,doi:10.1177/07356331241268474,"Computational thinking (CT), an essential competency for comprehending and addressing intricate issues in the digital world, has been incorporated into curriculum planning as a goal for programming education. This study introduced flow design into programming curricula to investigate its impact on undergraduates ’CT skills during pair work. Two types of flow design approaches, construct-by-self flow design (CBS-FD) and construct-on-scaffold flow design (COS-FD), were proposed to determine which approach better enhances students’ CT skills. Seventy-six first-year undergraduates participated, including thirty in the CBS group and thirty-six in the COS group. Evaluations made from the results and processes of programming tasks were employed to describe computational performance and computational practices, respectively. Data gathered from CT skill surveys were thoroughly analyzed to gain a deeper understanding of computational perspectives. Our findings highlighted that COS-FD significantly improved participants’ computational performance compared with CBS-FD. The COS groups fostered an engaging, sharing atmosphere, while CBS groups spent more energy on negotiating the manipulation of flow design. Moreover, both COS-FD and CBS-FD proved beneficial in enhancing participants’ computational perspectives, with the COS groups better improving their algorithm thinking. The study presents valuable perspectives on the design and implementation of collaborative programming activities within curriculum education.",Ruijie Zhou and Chong Xie and Xiuling He and Yangyang Li and Qiong Fan and Ying Yu and Zhonghua Yan,10.1177/07356331241268474,https://doi-org.crai.referencistas.com/10.1177/07356331241268474,Journal of Educational Computing Research,7,1865–1895,Effect of Different Flow Design Approaches on Undergraduates’ Computational Thinking During Pair Programming,https://doi-org.crai.referencistas.com/10.1177/07356331241268474,62,2024j,
article,doi:10.1177/104538902761696814,"In this paper we discuss the sound absorption property of arrays of micro-acoustic actuators at a control surface. We use the wave equation over the half plane for the velocity potential with a boundary dissipation by a proportional pressure feedback law along the half plane boundary. The feedback gain over the array is described by a distributed shape function. We develop a computational method based on the Fourier transform and employ it for analyzing and evaluating the decay rate of acoustic energy. Specifically, we carry out computations for a diffusive random initial field and report on our resulting numerical findings.",H. T. Banks and D. G. Cole and K. M. Furati and K. Ito and G. A. Pinter,10.1177/104538902761696814,https://doi-org.crai.referencistas.com/10.1177/104538902761696814,Journal of Intelligent Material Systems and Structures,4,231–240,A Computational Model for Sound Field Absorption by Acoustic Arrays,https://doi-org.crai.referencistas.com/10.1177/104538902761696814,13,2002a,
article,doi:10.1258/002367798780600070,"As part of a recent animal facility refurbishment, a cubicle containment system was designed to increase the amount of experimental space and also provide containment facilities to support the holding and use of specialized animal models. In order to achieve this, a series of computational fluid dynamic (CFD) studies was undertaken to evaluate the effects of different airflows and in order to optimize ventilation, a variety of exhaust/supply arrangements and animal loads was employed. These studies showed that air delivered via two, opposed, low level ducts, at a rate of 20 air changes per hour and exhausted high in the cubicle above the rack, was the optimal configuration resulting in minimal turbulence, stagnation and entrainment.",G. Curry and H. C. Hughes and D. Loseby and S. Reynolds,10.1258/002367798780600070,https://doi-org.crai.referencistas.com/10.1258/002367798780600070,Laboratory Animals,2,117–127,Advances in cubicle design using computational fluid dynamics as a design tool,https://doi-org.crai.referencistas.com/10.1258/002367798780600070,32,1998b,PMID:9587893
article,doi:10.1177/0954410011417541,"The application of a previously developed computational method to the prediction of high-lift performance for multi-element aerofoil sections operating at transonic flow conditions is described. The flows are computed by solving the Reynolds-averaged Navier–Stokes equations, using a full differential Reynolds-stress turbulence model to evaluate the various Reynolds-stress components appearing in the governing mean-flow equations. Algebraic wall functions are used to bridge the molecular viscosity-dominated region immediately adjacent to the aerofoil surfaces. An unstructured grid-based computational fluid dynamics (CFD) methodology is used to deal with the geometric complexity of the multi-element aerofoil configurations. Initial results are presented for the viscous, transonic flow development around the SKF 1.1 supercritical aerofoil section, equipped with either a trailing-edge flap or a leading-edge slat. Predicted surface pressure distributions generally compare well with experimental data for the two high-lift aerofoil geometries considered, at a free-stream Mach number of 0.6 and over a range of incidence angles. There are some discrepancies in the regions immediately downstream of shock wave/boundary layer interactions, possibly resulting from the use of wall-function boundary conditions in the computations. Predicted Mach number contours indicate the complexity of the transonic flow fields for high-lift configurations, with the slat wake passing through an extensive supersonic-flow region, terminated by a normal shock wave, on the main aerofoil upper surface, for example.",LJ Johnston,10.1177/0954410011417541,https://doi-org.crai.referencistas.com/10.1177/0954410011417541,"Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering",8,912–929,"Computational fluid dynamics analysis of multi-element, high-lift aerofoil sections at transonic manoeuvre conditions",https://doi-org.crai.referencistas.com/10.1177/0954410011417541,226,2012c,
article,doi:10.1177/15554120231211376,"This article analyzes the configuration of fear generated by the computational monster in computer games. We view the monster as a computational entity, which we approach through our theory of game-play coupled with the concepts of loss aversion and endowment effect. Of particular interest is player perception of the threat posed by monsters as they perturb the experience of progression and the sensation of control within the game. We scrutinize this aspect from a situational as well as an existential perspective. Furthermore, we advance an analytical scheme of the threat of the computational monster, which is radically different from the traditional academic approach with its emphasis on the representation of monsters. Overall, we argue that the threat players perceive when facing monsters in computer games springs more from the computational nature of monsters—how they upset progression and the feeling of control—and less from the representation of the monster(s).",Lasse Juel Larsen and Bo Kampmann Walther,10.1177/15554120231211376,https://doi-org.crai.referencistas.com/10.1177/15554120231211376,Games and Culture,0,15554120231211376,Fear of Monsters: Toward an Understanding of the Threat of the Computational Monster Read Through the Theoretical Lens  of Game-Play,https://doi-org.crai.referencistas.com/10.1177/15554120231211376,0,2023d,
article,doi:10.1177/0735633119887508,"This study implemented a data-driven approach to identify Chinese high school students’ common errors in a Java-based introductory programming course using the data in an automated assessment tool called the Mulberry. Students’ error-related behaviors were also analyzed, and their relationships to success in introductory programming were investigated. This study identified 15 common compilation errors and 6 common test errors. The results showed that these common errors accounted for a large proportion of all errors, so identifying the common errors is important to help students succeed in introductory programming courses. Based on these common errors, five underlying student difficulties were identified and are discussed. In addition, after analyzing existing measures of students’ error-related behaviors, we developed a measure called improvement rate to quantify students’ success in fixing errors. The results of our study suggest that students’ competence of improving code is important to their success in introductory programming. We recommend researchers design and develop automated assessment tools that provide feedback messages for common student errors and instructors who explicitly teach knowledge and skills of improving code in class.",Yizhou Qian and James Lehman,10.1177/0735633119887508,https://doi-org.crai.referencistas.com/10.1177/0735633119887508,Journal of Educational Computing Research,5,919–945,An Investigation of High School Students’ Errors in Introductory Programming: A Data-Driven Approach,https://doi-org.crai.referencistas.com/10.1177/0735633119887508,58,2020e,
article,doi:10.1177/1687814015606307,"Any hydraulic reaction turbine is installed with a draft tube that impacts widely the entire turbine performance, on which its functions are as follows: drive the flux in appropriate manner after it releases its energy to the runner; recover the suction head by a suction effect; and improve the dynamic energy in the runner outlet. All these functions are strongly linked to the geometric definition of the draft tube. This article proposes a geometric parametrization and analysis of a Francis turbine draft tube. Based on the parametric definition, geometric changes in the draft tube are proposed and the turbine performance is modeled by computational fluid dynamics; the boundary conditions are set by measurements performed in a hydroelectric power plant. This modeling allows us to see the influence of the draft tube shape on the entire turbine performance. The numerical analysis is based on the steady-state solution of the turbine component flows for different guide vanes opening and multiple modified draft tubes. The computational fluid dynamics predictions are validated using hydroelectric plant measurements. The prediction of the turbine performance is successful and it is linked to the draft tube geometric features; therefore, it is possible to obtain a draft tube parameter value that results in a desired turbine performance.",JB Sosa and G Urquiza and JC García and LL Castro,10.1177/1687814015606307,https://doi-org.crai.referencistas.com/10.1177/1687814015606307,Advances in Mechanical Engineering,10,1687814015606307,Computational fluid dynamics simulation and geometric design of hydraulic turbine draft tube,https://doi-org.crai.referencistas.com/10.1177/1687814015606307,7,2015f,
article,doi:10.1179/037195504225004706,"Most manganese used in the world is consumed as ferroalloys by the steelmaking industry. Submerged arc electric furnace smelting using the manganese-rich slag method is widely used to produce ferromanganese. This process has been modelled using the HSC computational thermodynamics package. It was assumed that higher manganese and iron oxides are reduced to MnO and FeO before entering the zone where molten slag and alloy form and equilibrate. The model predictions were compared to data from Thermit Alloys (P) Limited, an Indian ferroalloy smelter, and the agreement was found to be good. It was then used to examine the affects of changing the amount of carbon reductant and temperature on several performance indicators. The results of this modelling are discussed and it is concluded that the model is useful as an aid to understanding ferromanganese smelting.",E. C. Vanderstaay and D. R. Swinbourne and M. Monteiro,10.1179/037195504225004706,https://doi-org.crai.referencistas.com/10.1179/037195504225004706,Mineral Processing and Extractive Metallurgy,1,38–44,A computational thermodynamics model of submerged arc electric furnace ferromanganese smelting,https://doi-org.crai.referencistas.com/10.1179/037195504225004706,113,2004g,
article,doi:10.1177/1420326X17718053,"To design a comfortable aircraft cabin environment, designers conventionally follow an iterative guess-and-correction procedure to determine the air-supply parameters. The conventional method has an extremely low efficiency but does not guarantee an optimal design. This investigation proposed an inverse design method based on a proper orthogonal decomposition of the thermo-flow data provided by full computational fluid dynamics simulations. The orthogonal spatial modes of the thermo-flow fields and corresponding coefficients were firstly extracted. Then, a thermo-flow field was expressed into a linear combination of the spatial modes with their coefficients. The coefficients for each spatial mode are functions of air-supply parameters, which can be interpolated. With a quick map of the cause–effect relationship between the air-supply parameters and the exhibited thermo-flow fields, the optimal air-supply parameters were determined from specific design targets. By setting the percentage of dissatisfied and the predicted mean vote as design targets, the proposed method was implemented for inverse determination of air-supply parameters in two aircraft cabins. The results show that the inverse design using computational fluid dynamics-based proper orthogonal decomposition method is viable. Most of computing time lies in the construction of data samples of thermo-flow fields, while the proper orthogonal decomposition analysis and data interpolation is efficient.",Jihong Wang and Tengfei (Tim) Zhang and Hongbiao Zhou and Shugang Wang,10.1177/1420326X17718053,https://doi-org.crai.referencistas.com/10.1177/1420326X17718053,Indoor and Built Environment,10,1379–1391,Inverse design of aircraft cabin environment using computational fluid dynamics-based proper orthogonal decomposition method,https://doi-org.crai.referencistas.com/10.1177/1420326X17718053,27,2018h,
article,doi:10.1177/0049124115610347,"Model uncertainty is pervasive in social science. A key question is how robust empirical results are to sensible changes in model specification. We present a new approach and applied statistical software for computational multimodel analysis. Our approach proceeds in two steps: First, we estimate the modeling distribution of estimates across all combinations of possible controls as well as specified functional form issues, variable definitions, standard error calculations, and estimation commands. This allows analysts to present their core, preferred estimate in the context of a distribution of plausible estimates. Second, we develop a model influence analysis showing how each model ingredient affects the coefficient of interest. This shows which model assumptions, if any, are critical to obtaining an empirical result. We demonstrate the architecture and interpretation of multimodel analysis using data on the union wage premium, gender dynamics in mortgage lending, and tax flight migration among U.S. states. These illustrate how initial results can be strongly robust to alternative model specifications or remarkably dependent on a knife-edge specification.",Cristobal Young and Katherine Holsteen,10.1177/0049124115610347,https://doi-org.crai.referencistas.com/10.1177/0049124115610347,Sociological Methods & Research,1,3–40,Model Uncertainty and Robustness: A Computational Framework for Multimodel Analysis,https://doi-org.crai.referencistas.com/10.1177/0049124115610347,46,2017i,
article,doi:10.1177/1056789508090748,"The primary objective of this investigation is to develop efficient and robust computational schemes for a damage-coupled cyclic thermoviscoplasticity model for solder materials. Three constitutive integration algorithms, Euler, modified Euler, and semi-implicit algorithm for the model are examined. The three algorithms for the model are coded in the commercial finite element (FE) code ABAQUS (version 6.21) via its user-defined material subroutine UMAT. Two single-step algorithms of the substep scheme are applied for the modified Euler algorithm to control the error in the integration of constitutive laws. A semi-empirical formulation is established for an adaptive time stepping algorithm that is based on the Euler algorithm. The simulations of single-element, miniature specimen and notched specimen simulations have been conducted and compared with the test results under monotonic tensile, creep, and fatigue tests of 63Sn-37Pb solder. It is observed that the explicit algorithm consistently requires much less CPU time than others. The modified Euler algorithm has shown, on the other hand, to be not only efficient but also accurate. The semi-implicit algorithm yields an accurate solution. It is worth noting that the method is also effective by applying an appropriate integration scheme.",A.H. Zhao and C.L. Chow,10.1177/1056789508090748,https://doi-org.crai.referencistas.com/10.1177/1056789508090748,International Journal of Damage Mechanics,6,507–532,Computational Algorithms for a Damage-coupled Cyclic Viscoplasticity Material Model,https://doi-org.crai.referencistas.com/10.1177/1056789508090748,18,2009j,
article,doi:10.1179/030192310X12731438631804,"All operations in process metallurgy involve complex phenomena comprising momentum, heat, and/or mass transport; iron- and steelmaking is not an exception. Transport phenomena, i.e. fluid flows, heat transfer and mass transfer, play a dominant role in process metallurgy since their respective laws govern the kinetics of the various physical phenomena occurring in ironmaking and in steelmaking. These phenomena include such events as three-phase reactions, entrainment of slag and gas in liquid steel, vacuum degassing, alloy melting and mixing, the movements and flotation of inclusions, melt temperature losses, residence times in a metallurgical reactor, erosion of refractory linings, etc. In all these aspects, the evolution in our techniques and abilities to model single and multiphase flows and their attendant heat and mass transfer processes has contributed significantly to our understanding and effectively operating these processes, to designing improvements, and to developing new processes. To be ignorant of these matters can doom a processing operation to the scrap heap of metallurgical failures. Computational fluid dynamics (CFD) and computational heat and mass transfer has been a very effective tool over the last three decades, for modelling iron- and steelmaking processes, starting from the blast furnace up to continuous casting and beyond. With the advent of commercial CFD packages and ever increasing computational power through parallel processing, CFD has now become the dominant approach for predicting various aspects in iron- and steelmaking processes. In Part 1 of this review paper, the applications of CFD in ironmaking processes are thoroughly reviewed, discussed and critiqued. In Part 2, fluid flows and CFD in steelmaking and steel casting processes are similarly reviewed and critiqued.",K. Chattopadhyay and M. Isac and R. I. L. Guthrie,10.1179/030192310X12731438631804,https://doi-org.crai.referencistas.com/10.1179/030192310X12731438631804,Ironmaking & Steelmaking,8,554–561,Applications of Computational Fluid Dynamics (CFD) in iron- and steelmaking: Part 1,https://doi-org.crai.referencistas.com/10.1179/030192310X12731438631804,37,2010a,
article,doi:10.1177/1945892420950157,"Background Past studies reported a low correlation between rhinomanometry and computational fluid dynamics (CFD), but the source of the discrepancy was unclear. Low correlation or lack of correlation has also been reported between subjective and objective measures of nasal patency. Objective: This study investigates (1) the correlation and agreement between nasal resistance derived from CFD (RCFD) and rhinomanometry (RRMN), and (2) the correlation between objective and subjective measures of nasal patency. Methods Twenty-five patients with nasal obstruction underwent anterior rhinomanometry before and after mucosal decongestion with oxymetazoline. Subjective nasal patency was assessed with a 0-10 visual analog scale (VAS). CFD simulations were performed based on computed tomography scans obtained after mucosal decongestion. To validate the CFD methods, nasal resistance was measured in vitro (REXPERIMENT) by performing pressure-flow experiments in anatomically accurate plastic nasal replicas from 6 individuals. Results Mucosal decongestion was associated with a reduction in bilateral nasal resistance (0.34 ± 0.23 Pa.s/ml to 0.19 ± 0.24 Pa.s/ml, p = 0.003) and improved sensation of nasal airflow (bilateral VAS decreased from 5.2 ± 1.9 to 2.6 ± 1.9, p < 0.001). A statistically significant correlation was found between VAS in the most obstructed cavity and unilateral airflow before and after mucosal decongestion (r = −0.42, p = 0.003). Excellent correlation was found between RCFD and REXPERIMENT (r = 0.96, p < 0.001) with good agreement between the numerical and in vitro values (RCFD/REXPERIMENT = 0.93 ± 0.08). A weak correlation was found between RCFD and RRMN (r = 0.41, p = 0.003) with CFD underpredicting nasal resistance derived from rhinomanometry (RCFD/RRMN = 0.65 ± 0.63). A stronger correlation was found when unilateral airflow at a pressure drop of 75 Pa was used to compare CFD with rhinomanometry (r = 0.76, p < 0.001). Conclusion CFD and rhinomanometry are moderately correlated, but CFD underpredicts nasal resistance measured in vivo due in part to the assumption of rigid nasal walls. Our results confirm previous reports that subjective nasal patency correlates better with unilateral than with bilateral measurements and in the context of an intervention.",Giancarlo B. Cherobin and Richard L. Voegels and Fábio R. Pinna and Eloisa M. M. S. Gebrim and Ryan S. Bailey and Guilherme J. M. Garcia,10.1177/1945892420950157,https://doi-org.crai.referencistas.com/10.1177/1945892420950157,American Journal of Rhinology & Allergy,2,245–255,"Rhinomanometry Versus Computational Fluid Dynamics: Correlated, but Different Techniques",https://doi-org.crai.referencistas.com/10.1177/1945892420950157,35,2021b,PMID:32806938
article,doi:10.1177/1468087412438796,"The mixture formation and combustion process of a hydrogen direct-injection internal combustion engine is computed using a modified version of a commercial three-dimensional computational fluid dynamics code. The aim of the work is the evaluation of hydrogen laminar flame speed correlations and turbulent flame speed closures with respect to combustion of premixed and stratified mixtures at various levels of air-to-fuel equivalence ratio. Heat-release rates derived from in-cylinder pressure traces are used for the validation of the combustion simulations. A turbulent combustion model with closures for a turbulent flame speed is investigated. The value of the computed heat-release rates mainly depends on the quality of laminar burning velocities and standard of turbulence quantities provided to the combustion model. Combustion simulations performed with experimentally derived laminar flame speed data give better results than those using laminar flame speeds obtained from a kinetic scheme. However, experimental data of hydrogen laminar flame speeds found in the literature are limited regarding the range of pressures, temperatures and air-to-fuel equivalence ratios, and do not comply with the demand of high-pressure engine-relevant conditions.",Udo Gerke and Konstantinos Boulouchos,10.1177/1468087412438796,https://doi-org.crai.referencistas.com/10.1177/1468087412438796,International Journal of Engine Research,5,464–481,Three-dimensional computational fluid dynamics simulation of hydrogen engines using a turbulent flame speed closure combustion model,https://doi-org.crai.referencistas.com/10.1177/1468087412438796,13,2012c,
article,doi:10.1177/1094342016677586,"Magnetic resonance imaging (MRI) is one of the most important diagnostic tools in modern medicine. Since it is a high-cost and highly-complex imaging modality, computational models are frequently built to enhance its understanding as well as to support further development. However, such models often have to be simplified to complete simulations in a reasonable time. Thus, the simulations with high spatial/temporal resolutions, with any motion consideration (like blood flow) and/or with 3D objects usually call for using parallel computing environments. In this paper, we propose to use graphics processing units (GPUs) for fast simulations of MRI of vascular structures. We apply a CUDA environment which supports general purpose computation on GPU (GPGPU). The data decomposition strategy is applied and thus the parts of each virtual object are spread over the GPU cores. The GPU cores are responsible for calculating the influence of blood flow behavior and MRI events after successive time steps. In the proposed approach, different data layouts, memory access patterns, and other memory improvements are applied to efficiently exploit GPU resources. Computational performance is thoroughly validated for various vascular structures and different NVIDIA GPUs. Results show that MRI simulations can be accelerated significantly thanks to GPGPU. The proposed GPU-based approach may be easily adopted in the modeling of other flow related phenomena like perfusion, diffusion or transport of contrast agents.",Krzysztof Jurczuk and Marek Kretowski and Johanne Bezy–Wendling,10.1177/1094342016677586,https://doi-org.crai.referencistas.com/10.1177/1094342016677586,The International Journal of High Performance Computing Applications,4,496–511,GPU-based computational modeling of magnetic resonance imaging of vascular structures,https://doi-org.crai.referencistas.com/10.1177/1094342016677586,32,2018d,
article,doi:10.1177/1744259117750495,"A combined experimental-computational approach is used for the analysis of hygrothermal performance of a brick wall provided with interior thermal insulation system. A 2D laboratory experiment is performed to determine temperature and moisture fields in a characteristic segment of the envelope over a sufficiently long period including cold winter months. Then, a computational model of moisture and heat transport is developed, using an integral two-phase balance equation capable of distinguishing between the particular phases of water and an enthalpy-based heat balance equation. A 2D computational representation of the experiment is used for model calibration and identification of unknown parameters, resulting in a very good agreement of experimental and calculated fields, with R2 between 0.9687 and 0.9888. The calibrated model is subsequently used for a long-term hygrothermal assessment of the studied detail to demonstrate the functionality of the interior thermal insulation system, as well as the applicability of the developed model.",Václav Kočí and Jan Kočí and Jiří Maděra and Zbyšek Pavlík and Xianglin Gu and Weiping Zhang and Robert Černý,10.1177/1744259117750495,https://doi-org.crai.referencistas.com/10.1177/1744259117750495,Journal of Building Physics,6,497–520,Thermal and hygric assessment of an inside-insulated brick wall: 2D critical experiment and computational analysis,https://doi-org.crai.referencistas.com/10.1177/1744259117750495,41,2018e,
article,doi:10.1177/20539517211062885,"The concept of ‘digital phenotyping’ was originally developed by researchers in the mental health field, but it has travelled to other disciplines and areas. This commentary draws upon our experiences of working in two scientific projects that are based at the University of Oxford’s Big Data Institute – The RADAR-AD project and The Minerva Initiative – which are developing algorithmic phenotyping technologies. We describe and analyse the concepts of digital biomarkers and computational phenotyping that underlie these projects, explain how they are linked to other research in digital phenotyping and compare and contrast some of their epistemological and ethical implications. In particular, we argue that the phenotyping paradigm in both projects is grounded on an assumption of ‘objectivity’ that is articulated in different ways depending on the role that is given to the computational/digital tools. Using the concept of ‘affordance’, we show how specific functionalities relate to potential uses and social implications of these technologies and argue that it is important to distinguish among them as the concept of digital phenotyping is increasingly being used with a variety of meanings.",Federica Lucivero and Nina Hallowell,10.1177/20539517211062885,https://doi-org.crai.referencistas.com/10.1177/20539517211062885,Big Data & Society,2,20539517211062884,Digital/computational phenotyping: What are the differences in the science and the ethics?,https://doi-org.crai.referencistas.com/10.1177/20539517211062885,8,2021f,
article,doi:10.1177/089443930101900105,"There has been a continued expansion of the uses of computer-based tools and techniques in public sector endeavors: from traditional notions of data collection and management (bean counting) to the processing of data into information that supports managerial activities. Advances in technology based on emerging work in decision theory, information science, and cognitive science will allow for use of these computational models in more expansive “advisory” roles to decision makers of all types. To what degree can public sector decision makers use computational models to support or advise decision making? As these new technologies become a routine part of the policy process, will a belief in computer omnipotence tempt public sector decision makers to abdicate personal responsibility for poor choices? The authors explore the choice-related implications associated with the increased use of computer-based models, define possible computer-based decision support models (CBDSMs), and present a typology of credible uses of CBDSMs.",Desmond Saunders-Newton and Harold Scott,10.1177/089443930101900105,https://doi-org.crai.referencistas.com/10.1177/089443930101900105,Social Science Computer Review,1,47–65,“But the Computer Said!”: Credible Uses of Computational Modeling in Public Sector Decision Making,https://doi-org.crai.referencistas.com/10.1177/089443930101900105,19,2001g,
article,doi:10.1177/1094428104271998,"To encourage the use of computational modeling in organizational behavior research, an example computational model is developed and rigorous tests of it presented. Specifically, a computational model based on control theory was created to test the theory’s explanation of the goal-level effect (e.g., higher goals lead to higher performance). Data from simulations of the model were compared with the behavior of 32 undergraduate students performing a scheduling task under various within-subject manipulations and across time. Correlational analyses indicated that the model accounted for most of the participants’data, with coefficients between the model and each participant’s behavior mostly in the high 90s.",Jeffrey B. Vancouver and Dan J. Putka and Charles A. Scherbaum,10.1177/1094428104271998,https://doi-org.crai.referencistas.com/10.1177/1094428104271998,Organizational Research Methods,1,100–127,Testing a Computational Model of the Goal-Level Effect: An Example of a Neglected Methodology,https://doi-org.crai.referencistas.com/10.1177/1094428104271998,8,2005h,
article,doi:10.1177/1687814017734109,"Mesh partitioning is significant to the efficiency of parallel computational fluid dynamics simulations. The most time-consuming parts of parallel computational fluid dynamics simulations are iteratively solving linear systems derived from partial differential equation discretizations. This article aims at mesh partitioning for better iterative convergence feature of this procedure. For typical computational fluid dynamics simulations in which partial differential equations are discretized and solved after the mesh is partitioned, numerical information of the linear systems is not available yet during mesh partitioning. We propose to construct approximations for matrix elements and theoretically find out that for finite-volume-based problems, the face area can approximate the corresponding matrix element well. A mesh partitioning scheme using the matrix value approximations for better iterative convergence behavior is implemented and numerically testified. The results show that our method can capture the most important factor influencing the matrix values and achieve partitions with good performance throughout the simulations with non-uniform meshes. The novel partitioning strategy is general and easy to implement in various partitioning packages.",Miao Wang and Xinhai Xu and Xiaoguang Ren and Chao Li and Juan Chen and Xuejun Yang,10.1177/1687814017734109,https://doi-org.crai.referencistas.com/10.1177/1687814017734109,Advances in Mechanical Engineering,11,1687814017734109,Mesh partitioning using matrix value approximations for parallel computational fluid dynamics simulations,https://doi-org.crai.referencistas.com/10.1177/1687814017734109,9,2017i,
article,doi:10.1177/08944393211058112,"Since its inception, computational social science (CSS) has been characterized as an interdisciplinary field. Nevertheless, unlike a mature interdisciplinary field that duly integrates knowledge beyond disciplinary boundaries, CSS has arguably been fragmented into multiple lines of inquiry. Although such fragmentation has been a constant concern, limited empirical evidence exists to substantiate any degree of integration in research on CSS. To systematically map the landscape of research on CSS, we examined the dynamic topology of the bibliometric network of CSS during the past 20 years. By comparing the structure of the coupling network and the co-subject network with three prototypical network models that we simulated—the centralized model, the fragmented model, and the cohesive model—our analysis revealed that the citation networks of research on CSS are highly centralized but less fragmented than often assumed. Beyond that, a driving factor shaping the coupling network’s cohesive structure is the citation to high-impact articles. Those and other findings contribute to current understandings of the process of integration in the evolution of disciplines.",Xiaohui Wang and Yunya Song and Youzhen Su,10.1177/08944393211058112,https://doi-org.crai.referencistas.com/10.1177/08944393211058112,Social Science Computer Review,3,946–966,Less Fragmented but Highly Centralized: A Bibliometric Analysis of Research in Computational Social Science,https://doi-org.crai.referencistas.com/10.1177/08944393211058112,41,2023j,
article,doi:10.1179/030192310X12731438631804,"All operations in process metallurgy involve complex phenomena comprising momentum, heat, and/or mass transport; iron- and steelmaking is not an exception. Transport phenomena, i.e. fluid flows, heat transfer and mass transfer, play a dominant role in process metallurgy since their respective laws govern the kinetics of the various physical phenomena occurring in ironmaking and in steelmaking. These phenomena include such events as three-phase reactions, entrainment of slag and gas in liquid steel, vacuum degassing, alloy melting and mixing, the movements and flotation of inclusions, melt temperature losses, residence times in a metallurgical reactor, erosion of refractory linings, etc. In all these aspects, the evolution in our techniques and abilities to model single and multiphase flows and their attendant heat and mass transfer processes has contributed significantly to our understanding and effectively operating these processes, to designing improvements, and to developing new processes. To be ignorant of these matters can doom a processing operation to the scrap heap of metallurgical failures. Computational fluid dynamics (CFD) and computational heat and mass transfer has been a very effective tool over the last three decades, for modelling iron- and steelmaking processes, starting from the blast furnace up to continuous casting and beyond. With the advent of commercial CFD packages and ever increasing computational power through parallel processing, CFD has now become the dominant approach for predicting various aspects in iron- and steelmaking processes. In Part 1 of this review paper, the applications of CFD in ironmaking processes are thoroughly reviewed, discussed and critiqued. In Part 2, fluid flows and CFD in steelmaking and steel casting processes are similarly reviewed and critiqued.",K. Chattopadhyay and M. Isac and R. I. L. Guthrie,10.1179/030192310X12731438631804,https://doi-org.crai.referencistas.com/10.1179/030192310X12731438631804,Ironmaking & Steelmaking,8,554–561,Applications of Computational Fluid Dynamics (CFD) in iron- and steelmaking: Part 1,https://doi-org.crai.referencistas.com/10.1179/030192310X12731438631804,37,2010a,
article,doi:10.1177/0894439320951766,"The increasing availability of data, along with sophisticated computational methods for analyzing them, presents researchers with new opportunities and challenges. In this article, we address both by describing computational and network methods that can be used to identify cases of rare phenomena. We evaluate each method’s relative utility in the identification of a specific rare phenomenon of interest to social movement researchers: the spillover of social movement claims from one movement to another. We identify and test five different approaches to detecting cases of spillover in the largest data set of protest events currently available, finding that an ensemble approach that combines clique and correspondence analysis and an ensemble approach combining all methods perform considerably better than others. Our approach is preferable to other ways of analyzing such cases; compared to qualitative approaches, our computational process identifies many more cases of spillover—some of which are surprising and would likely not be otherwise investigated. At the same time, compared to crude quantitative measures, our approach substantially reduces the “noise,” or identification of false-positive cases, of movement spillover. We argue that this technique, which can be adapted to other research topics, is a good illustration of how the thoughtful implementation of computational methods can allow for the efficient identification of rare events and also bridge deductive and inductive approaches to scientific inquiry.",Thomas Elliott and Misty Ring-Ramirez and Jennifer Earl,10.1177/0894439320951766,https://doi-org.crai.referencistas.com/10.1177/0894439320951766,Social Science Computer Review,5,981–1002,Spillover as Movement Agenda Setting: Using Computational and Network Techniques for Improved Rare Event Identification,https://doi-org.crai.referencistas.com/10.1177/0894439320951766,39,2021b,
article,doi:10.1177/0022219407311003,"Knowledge and skill in multiplication were investigated for late elementary-grade students with mathematics learning disabilities (MLD), typically achieving age-matched peers, low-achieving age-matched peers, and ability-matched peers by examining multiple measures of computational skill, working memory, and conceptual knowledge. Poor multiplication fact mastery and calculation fluency and general working memory discriminated children with MLD from typically achieving age-matched peers. Furthermore, children with MLD were slower in executing backup procedures than typically achieving age-matched peers. The performance of children with MLD on multiple measures of multiplication skill and knowledge was most similar to that of ability-matched younger children. MLD may be due to difficulties in computational skills and working memory. Implications for the diagnosis and remediation of MLD are discussed.",Donald J. Mabbott and Jeffrey Bisanz,10.1177/0022219407311003,https://doi-org.crai.referencistas.com/10.1177/0022219407311003,Journal of Learning Disabilities,1,15–28,"Computational Skills, Working Memory, and Conceptual Knowledge in Older Children With Mathematics Learning Disabilities",https://doi-org.crai.referencistas.com/10.1177/0022219407311003,41,2008c,PMID:18274501
article,doi:10.1177/0954411915626742,"The current criterion for surgical intervention in abdominal aortic aneurysms, based upon a maximal aortic diameter, is considered conservative due to the high mortality rate in case of rupture. The research community is actively investigating the use of computational mechanics tools combined with patient-specific imaging to help identify more accurate criteria. Widespread uptake of a successful metric will however be limited by the need for computed tomography, which is at present the primary image extraction method on account of the location and complex shape of the aneurysms. The use of three-dimensional ultrasound as the scanning method is more attractive on account of increased availability, reduced cost and reduced risk to patients. The suitability of three-dimensional ultrasound is assessed for this purpose in the present work; computational fluid dynamics simulations were performed on geometries obtained from the same patient using both ultrasound and computed tomography. The influence of different smoothing algorithms is investigated in the geometry preparation stage and Taubin’s low-pass filter was found to best preserve geometry features. Laminar, Newtonian, steady-state simulation analysis identified haemodynamic characteristics to be qualitatively similar in terms of wall shear stress, velocity and vorticity. The study demonstrates the potential for three-dimensional ultrasound to be integrated into a more accessible patient-specific modelling tool able to identify the need for surgical intervention of abdominal aortic aneurysms.",Benjamin Owen and Christopher Lowe and Neil Ashton and Parthasarathi Mandal and Steven Rogers and Wolfgang Wein and Charles McCollum and Alistair Revell,10.1177/0954411915626742,https://doi-org.crai.referencistas.com/10.1177/0954411915626742,"Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine",3,201–210,Computational hemodynamics of abdominal aortic aneurysms: Three-dimensional ultrasound versus computed tomography,https://doi-org.crai.referencistas.com/10.1177/0954411915626742,230,2016d,PMID:26893226
article,doi:10.4137/BBI.S13403,"Sea anemone neurotoxins are peptides that interact with Na+ and K+ channels, resulting in specific alterations on their functions. Some of these neurotoxins (1ROO, 1BGK, 2K9E, 1BEI) are important for the treatment of about 80 autoimmune disorders because of their specificity for Kv1.3 channel. The aim of this study was to identify the common residues among these neurotoxins by computational methods, and establish whether there is a pattern useful for the future generation of a treatment for autoimmune diseases. Our results showed eight new key common residues between the studied neurotoxins interacting with a histidine ring and the selectivity filter of the receptor, thus showing a possible pattern of interaction. This knowledge may serve as an input for the design of more promising drugs for autoimmune treatments.",Angélica Sabogal-Arango and George E. Barreto and David Ramírez-Sánchez and Juan González-Mendoza and Viviana Barreto and Ludis Morales and Janneth González,10.4137/BBI.S13403,https://doi-org.crai.referencistas.com/10.4137/BBI.S13403,Bioinformatics and Biology Insights, ,BBI.S13403,Computational Insights of the Interaction among Sea Anemones Neurotoxins and Kv1.3 Channel,https://doi-org.crai.referencistas.com/10.4137/BBI.S13403,8,2014e,PMID:24812496
article,doi:10.1177/1094428112449655,"Theorists in management and organizational science rarely use computational modeling to support theoretical development or refinement, particularly at the micro level of analysis. This article argues that organizational scholars, who strive to understand dynamic behavior in a complex context, are particularly in need of the support computational models offer. Moreover, organizational scholars can build on (a) the plethora of informal theories extant in the literature and (b) the computational architectures and model building platforms developed in recent years. To increase the number of organizational scholars building and evaluating computational models, the article provides a tutorial in model building and simulation. Specifically, a new computational model is built and assessed. Surprising realizations emerge in the process. There is also an extensive section on model evaluation involving empirical observations.",Jeffrey B. Vancouver and Justin M. Weinhardt,10.1177/1094428112449655,https://doi-org.crai.referencistas.com/10.1177/1094428112449655,Organizational Research Methods,4,602–623,Modeling the Mind and the Milieu: Computational Modeling for Micro-Level Organizational Researchers,https://doi-org.crai.referencistas.com/10.1177/1094428112449655,15,2012f,
article,doi:10.1177/1687814017734109,"Mesh partitioning is significant to the efficiency of parallel computational fluid dynamics simulations. The most time-consuming parts of parallel computational fluid dynamics simulations are iteratively solving linear systems derived from partial differential equation discretizations. This article aims at mesh partitioning for better iterative convergence feature of this procedure. For typical computational fluid dynamics simulations in which partial differential equations are discretized and solved after the mesh is partitioned, numerical information of the linear systems is not available yet during mesh partitioning. We propose to construct approximations for matrix elements and theoretically find out that for finite-volume-based problems, the face area can approximate the corresponding matrix element well. A mesh partitioning scheme using the matrix value approximations for better iterative convergence behavior is implemented and numerically testified. The results show that our method can capture the most important factor influencing the matrix values and achieve partitions with good performance throughout the simulations with non-uniform meshes. The novel partitioning strategy is general and easy to implement in various partitioning packages.",Miao Wang and Xinhai Xu and Xiaoguang Ren and Chao Li and Juan Chen and Xuejun Yang,10.1177/1687814017734109,https://doi-org.crai.referencistas.com/10.1177/1687814017734109,Advances in Mechanical Engineering,11,1687814017734109,Mesh partitioning using matrix value approximations for parallel computational fluid dynamics simulations,https://doi-org.crai.referencistas.com/10.1177/1687814017734109,9,2017g,
article,doi:10.1177/08944393211058112,"Since its inception, computational social science (CSS) has been characterized as an interdisciplinary field. Nevertheless, unlike a mature interdisciplinary field that duly integrates knowledge beyond disciplinary boundaries, CSS has arguably been fragmented into multiple lines of inquiry. Although such fragmentation has been a constant concern, limited empirical evidence exists to substantiate any degree of integration in research on CSS. To systematically map the landscape of research on CSS, we examined the dynamic topology of the bibliometric network of CSS during the past 20 years. By comparing the structure of the coupling network and the co-subject network with three prototypical network models that we simulated—the centralized model, the fragmented model, and the cohesive model—our analysis revealed that the citation networks of research on CSS are highly centralized but less fragmented than often assumed. Beyond that, a driving factor shaping the coupling network’s cohesive structure is the citation to high-impact articles. Those and other findings contribute to current understandings of the process of integration in the evolution of disciplines.",Xiaohui Wang and Yunya Song and Youzhen Su,10.1177/08944393211058112,https://doi-org.crai.referencistas.com/10.1177/08944393211058112,Social Science Computer Review,3,946–966,Less Fragmented but Highly Centralized: A Bibliometric Analysis of Research in Computational Social Science,https://doi-org.crai.referencistas.com/10.1177/08944393211058112,41,2023h,
article,doi:10.1080/19462166.2010.485698,"This paper reports our research concerning dialogue strategies suitable for adoption by a human–computer debating system. We propose a set of strategic heuristics for a computer to adopt to enable it to function as a dialogue participant. In particular, we consider means of assessing the proposed strategy. A system involving two agents in dialogue with each other and a human–agent debate system are constructed and subsequently used to facilitate the evaluations. The evaluations suggest that the proposed strategy can enable the computer to act as an effective dialogue participant. It is anticipated that this work will contribute towards the development of computerised dialogue systems and help to illuminate research issues concerning strategies in dialectical systems.",Tangming Yuan and David Moore and Alec Grierson,10.1080/19462166.2010.485698,https://doi-org.crai.referencistas.com/10.1080/19462166.2010.485698,Argument & Computation,3,215–248,Assessing debate strategies via computational agents,https://doi-org.crai.referencistas.com/10.1080/19462166.2010.485698,1,2010i,
article,doi:10.1177/20965311241265373,"Purpose This article takes a postfoundational lens to reflect upon my ethnographic (re)searching experience in a Hong Kong high school biology classroom to expose ignorant theoretical–methodological assumptions of researchers and teachers on critical thinking for new realizations. Design/Approach/Methods Using an encountered embodied thinking moment as a trigger, this article examines the texts/discourses collected from teachers/teaching and students/learning to unpack underlying philosophical–theoretical–methodological traps and ignorance. Findings The analysis exposes three ignorant assumptions. First is a mind–body dualism that has historically disembodied thinking as an abstract and invisible mind/cognitive activity. Second is a knowledge–skill/thinking divide that upgrades critical thinking as a transferrable higher-order skill above and external to knowledge. Third is a naturalized assumption that didactic instructions in Asian classrooms are not as conducive to thinking cultivation as (Western) student-centered pedagogies. Originality/Value My postfoundational reflections interrogate and expand these philosophical–theoretical–methodological grounds to reconstruct effective thinking curricula and classrooms.",Weili Zhao (赵伟黎),10.1177/20965311241265373,https://doi-org.crai.referencistas.com/10.1177/20965311241265373,ECNU Review of Education,0,20965311241265372,(Re)Searching Critical Thinking in a Hong Kong Classroom: A Postfoundational Reflection on Ignorant Modernity,https://doi-org.crai.referencistas.com/10.1177/20965311241265373,0,2024j,
article,doi:10.1177/14614448241251804,"TikTok has emerged as a powerful platform for the dissemination of mis- and disinformation about the war in Ukraine. During the initial three months after the Russian invasion in February 2022, videos under the hashtag #Ukraine garnered 36.9 billion views, with individual videos scaling up to 88 million views. Beyond the traditional methods of spreading misleading information through images and text, the medium of sound has emerged as a novel, platform-specific audiovisual technique. Our analysis distinguishes various war-related sounds utilized by both Ukraine and Russia and classifies them into a mis- and disinformation typology. We use computational propaganda features—automation, scalability, and anonymity—to explore how TikTok’s auditory practices are exploited to exacerbate information disorders in the context of ongoing war events. These practices include reusing sounds for coordinated campaigns, creating audio meme templates for rapid amplification and distribution, and deleting the original sounds to conceal the orchestrators’ identities. We conclude that TikTok’s recommendation system (the “for you” page) acts as a sound space where exposure is strategically navigated through users’ intervention, enabling semi-automated “soft” propaganda to thrive by leveraging its audio features.",Marcus Bösch and Tom Divon,10.1177/14614448241251804,https://doi-org.crai.referencistas.com/10.1177/14614448241251804,New Media & Society,9,5081–5106,"The sound of disinformation: TikTok, computational propaganda, and the invasion of Ukraine",https://doi-org.crai.referencistas.com/10.1177/14614448241251804,26,2024a,
article,doi:10.1177/27538699221128218,"Design research has much to contribute to and much to gain from the emerging field of possibility studies. In this short essay, I discuss these opportunities with respect to four topics: (1) processes of mediation and representation, (2) systems perspectives on creative work, (3) methodological options for investigation, and (4) educational challenges that should be addressed. Considering design research’s contributions to each of these topics raises interesting questions that possibility studies might address as it develops. Conversely, possibility studies is already raising issues that design research should also attend to.",Nathan Crilly,10.1177/27538699221128218,https://doi-org.crai.referencistas.com/10.1177/27538699221128218,Possibility Studies & Society,1–2,46–50,Design research and the study of the possible,https://doi-org.crai.referencistas.com/10.1177/27538699221128218,1,2023b,
article,doi:10.1177/0265532210378031,"The authors present a model of lexical proficiency based on lexical indices related to vocabulary size, depth of lexical knowledge, and accessibility to core lexical items. The lexical indices used in this study come from the computational tool Coh-Metrix and include word length scores, lexical diversity values, word frequency counts, hypernymy values, polysemy values, semantic co-referentiality, word meaningfulness, word concreteness, word imagability, and word familiarity. Human raters evaluated a corpus of 240 written texts using a standardized rubric of lexical proficiency. To ensure a variety of text levels, the corpus comprised 60 texts each from beginning, intermediate, and advanced second language (L2) adult English learners. The L2 texts were collected longitudinally from 10 English learners. In addition, 60 texts from native English speakers were collected. The holistic scores from the trained human raters were then correlated to a variety of lexical indices. The researchers found that lexical diversity, word hypernymy values and content word frequency explain 44% of the variance of the human evaluations of lexical proficiency in the examined writing samples. The findings represent an important step in the development of a model of lexical proficiency that incorporates both vocabulary size and depth of lexical knowledge features.",Scott A. Crossley and Tom Salsbury and Danielle S. McNamara and Scott Jarvis,10.1177/0265532210378031,https://doi-org.crai.referencistas.com/10.1177/0265532210378031,Language Testing,4,561–580,Predicting lexical proficiency in language learner texts using computational indices,https://doi-org.crai.referencistas.com/10.1177/0265532210378031,28,2011c,
article,doi:10.1177/17470161241247686,"Recital 33 GDPR has often been interpreted as referring to ‘broad consent’. This version of informed consent was intended to allow data subjects to provide their consent for certain areas of research, or parts of research projects, conditional to the research being in line with ‘recognised ethical standards’. In this article, we argue that broad consent is applicable in the emerging field of Computational Social Science (CSS), which lies at the intersection of data science and social science. However, the lack of recognised ethical standards specific to CSS poses a practical barrier to the use of broad consent in this field and other fields that lack recognised ethical standards. Upon examining existing research ethics standards in social science and data science, we argue that they are insufficient for CSS. We further contend that the fragmentation of European Union (EU) law and research ethics sources makes it challenging to establish universally recognised ethical standards for scientific research. As a result, CSS researchers and other researchers in emerging fields that lack recognised ethical standards are left without sufficient guidance on the use of broad consent as provided for in the GDPR. We conclude that responsible EU bodies should provide additional guidance to facilitate the use of broad consent in CSS research.",Seliem El-Sayed and Filip Paspalj,10.1177/17470161241247686,https://doi-org.crai.referencistas.com/10.1177/17470161241247686,Research Ethics,3,433–452,"No recognised ethical standards, no broad consent: navigating the quandary in computational social science research",https://doi-org.crai.referencistas.com/10.1177/17470161241247686,20,2024d,
article,doi:10.1177/0143624418759783,"People spend most of their time indoors; therefore, maintaining a good indoor air quality and meeting the requirements of comfort and energy efficiency are essential. One of the most widespread strategies to achieve this objective is improving ventilation efficiency; therefore, the main aim of this study was to show an optimization of the ventilation efficiency, in a specific room, considering 47 variations (case studies) in the furniture arrangement. For this purpose, a numerical analysis using computational fluid dynamics techniques, validated by the tracer gas decay technique, was used to assess the distribution of the age of air within the space. The concept of “age of air” was implemented in the computational fluid dynamics code through user-defined functions, using the steady-state method based on the resolution of a transport equation for an additional scalar. Variations up to 5.75% in the ventilation efficiency between the cases studied have been achieved. It is concluded that an improvement up to 1.65% can be obtained when the elements of the study are introduced in a way that facilitates the air movement towards the exhaust; therefore, improvement of the ventilation efficiency through specific furniture distributions is possible, although not significant, according to the outcomes.",Susana Hormigos-Jimenez and Miguel Ángel Padilla-Marcos and Alberto Meiss and Roberto Alonso Gonzalez-Lezcano and Jesús Feijó-Muñoz,10.1177/0143624418759783,https://doi-org.crai.referencistas.com/10.1177/0143624418759783,Building Services Engineering Research and Technology,5,557–571,Computational fluid dynamics evaluation of the furniture arrangement for ventilation efficiency,https://doi-org.crai.referencistas.com/10.1177/0143624418759783,39,2018e,
article,doi:10.4137/BBI.S8971,"Computational design of small molecule putative inhibitors of Polo-like kinase 1 (Plk1) is presented. Plk1, which regulates the cell cycle, is often over expressed in cancers. Down regulation of Plk1 has been shown to inhibit tumor progression. Most kinase inhibitors interact with the ATP binding site on Plk1, which is highly conserved. This makes the development of Plk1-specific inhibitors challenging, since different kinases have similar ATP sites. However, Plk1 also contains a unique region called the polo-box domain (PBD), which is absent from other kinases. In this study, the PBD site was used as a target for designed Plk1 putative inhibitors. Common structural features of several experimentally known Plk1 ligands were first identified. The findings were used to design small molecules that specifically bonded Plk1. Drug likeness and possible toxicities of the molecules were investigated. Molecules with no implied toxicities and optimal drug likeness values were used for docking studies. Several molecules were identified that made stable complexes only with Plk1 and LYN kinases, but not with other kinases. One molecule was found to bind exclusively the PBD site of Plk1. Possible utilization of the designed molecules in drugs against cancers with over expressed Plk1 is discussed.",Krupa S. Jani and D.S. Dalafave,10.4137/BBI.S8971,https://doi-org.crai.referencistas.com/10.4137/BBI.S8971,Bioinformatics and Biology Insights, ,BBI.S8971,Computational Design of Targeted Inhibitors of Polo-Like Kinase 1 (Plk1),https://doi-org.crai.referencistas.com/10.4137/BBI.S8971,6,2012f,PMID:22399850
article,doi:10.1177/10762175211070350,"A phenomenon from the natural world, cricket chirping behavior in relation to ambient temperature, is used as the springboard for engaging the curiosity of gifted students in an interdisciplinary classroom curriculum. Mathematics and science standards and disciplinary practices are prominent in the investigation, while other disciplines deepen the experience. An analysis of the cricket project in terms of the Parallel Curriculum (core, connections, practice, and identity) provides an interesting lens for examining interdisciplinarity (see Tomlinson, C. A., Kaplan, S. N., Renzulli, and J. S., et al. (2009). Parallel curriculum: A design to develop learner potential and challenge advanced learners. Corwin Press).",Kim Krusen McComas,10.1177/10762175211070350,https://doi-org.crai.referencistas.com/10.1177/10762175211070350,Gifted Child Today,2,105–109,Investigating Crickets: Jumping Across the Disciplines in a Naturally Interdisciplinary Project,https://doi-org.crai.referencistas.com/10.1177/10762175211070350,45,2022g,
article,doi:10.1177/1748048520928334,"This study uses diachronic computational analysis enhanced with a qualitative approach to examine ongoing changes in communication studies, comparing trends in two European media studies journals and three major International Communication Association journals. We analyze the titles, keywords, and abstracts of 2,585 articles published between 1994–2007 and 2008–2016. We find differences between topics in the two periods in each of the journals’ groups and between the two groups themselves. In the European group, we find centrality of topics related to media change and media logic. In the ICA journals, we find a strengthening of scholarly engagement with effects studies. At the same time, we find evidence of erosion of the place of cultural studies as a distinctive research stream.",Oren Soffer and Dorit Geifman,10.1177/1748048520928334,https://doi-org.crai.referencistas.com/10.1177/1748048520928334,International Communication Gazette,8,753–775,Comparing research topics in European and International Communication Association journals: Computational analysis,https://doi-org.crai.referencistas.com/10.1177/1748048520928334,83,2021h,
article,doi:10.7227/IJMEE.42.1.7,"This paper reports the development of a computational fluid dynamics (CFD) model of a spark ignition (SI) engine and the application of the engine model into an undergraduate internal combustion (IC) course. This two-dimensional (2D) four-stroke SI engine model simulates the combustion of the fuel, heptane, in the engine cylinder based on realistic boundary conditions. The development of the model helps engineering students better understand the combined effects of chemical reactions, species transport, flow patterns and temperature distributions in the SI engine. This model has been applied in a practical session in an undergraduate engineering course since 2012. To the best knowledge of the authors, this is the first time that CFD engine models are used as a hands-on tool in IC engine courses. Feedback from students is quite positive.",Zhao Feng Tian and John Abraham,10.7227/IJMEE.42.1.7,https://doi-org.crai.referencistas.com/10.7227/IJMEE.42.1.7,International Journal of Mechanical Engineering Education,1,73–83,Application of Computational Fluid Dynamics (CFD) in Teaching Internal Combustion Engines,https://doi-org.crai.referencistas.com/10.7227/IJMEE.42.1.7,42,2014i,
article,doi:10.1177/1475472X221079557,"Broadband noise due to the turbulence-aerofoil interaction, which is also called the leading edge noise, is one of the major noise sources of aircraft (including the engine). To study the noise properties numerically is a popular approach with the increasing power of computers. Conventional approaches of using body-fitted grids at the boundaries would be convoluted due to the complex geometries, which can constrain the efficiency of parametric studies. A promising approach to tackle this issue is to use the immersed boundary method (IBM). Among various IBM variants, the volume penalization (VP) approach employs a masking function to identify the immersed solid boundary, and continuous forcing terms are added to the original flow governing equations to account for the boundary conditions. It is, therefore, efficient and easy to implement into the existing computational aeroacoustics solvers. In this work, the VP-based IBM is used to simulate the leading edge noise by combining with the advanced synthetic turbulence method. The simulations are conducted for both the isolated aerofoils and cascade, and the results are compared with the well-validated body-fitted grid solutions. The viscosity effect is also highlighted by comparing the results obtained by solving both Euler and Navier–Stokes equations.",Wei Ying and Ryu Fattah and Sinforiano Cantos and Siyang Zhong and Tatiana Kozubskaya,10.1177/1475472X221079557,https://doi-org.crai.referencistas.com/10.1177/1475472X221079557,International Journal of Aeroacoustics,1–2,74–94,Computational aeroacoustics of aerofoil leading edge noise using the volume penalization-based immersed boundary methods,https://doi-org.crai.referencistas.com/10.1177/1475472X221079557,21,2022j,
article,doi:10.1177/14614448241251804,"TikTok has emerged as a powerful platform for the dissemination of mis- and disinformation about the war in Ukraine. During the initial three months after the Russian invasion in February 2022, videos under the hashtag #Ukraine garnered 36.9 billion views, with individual videos scaling up to 88 million views. Beyond the traditional methods of spreading misleading information through images and text, the medium of sound has emerged as a novel, platform-specific audiovisual technique. Our analysis distinguishes various war-related sounds utilized by both Ukraine and Russia and classifies them into a mis- and disinformation typology. We use computational propaganda features—automation, scalability, and anonymity—to explore how TikTok’s auditory practices are exploited to exacerbate information disorders in the context of ongoing war events. These practices include reusing sounds for coordinated campaigns, creating audio meme templates for rapid amplification and distribution, and deleting the original sounds to conceal the orchestrators’ identities. We conclude that TikTok’s recommendation system (the “for you” page) acts as a sound space where exposure is strategically navigated through users’ intervention, enabling semi-automated “soft” propaganda to thrive by leveraging its audio features.",Marcus Bösch and Tom Divon,10.1177/14614448241251804,https://doi-org.crai.referencistas.com/10.1177/14614448241251804,New Media & Society,9,5081–5106,"The sound of disinformation: TikTok, computational propaganda, and the invasion of Ukraine",https://doi-org.crai.referencistas.com/10.1177/14614448241251804,26,2024a,
article,doi:10.1177/089443939401200410,"Computational organization theory is a growing interdisciplinary area centered on the development of organization theory through the use of computational techniques. Research in this area grows out of work in many scientific areas including sociology, psychology, classic organization theory, and distributed artificial intelligence. The research in this area is united by a view of organizations as collections of processes and intelligent adaptive agents that are task oriented, socially situated, and technologically bound. This paper reviews this growing area and discusses both issues involved in the development of models in this area and theoretical issues that are being explored by work in this area. Keywords’ simulation, organization theory, organizational learning, social networks, expert systems, computers.",Kathleen Carley,10.1177/089443939401200410,https://doi-org.crai.referencistas.com/10.1177/089443939401200410,Social Science Computer Review,4,611–624,Sociology: Computational Organization Theory,https://doi-org.crai.referencistas.com/10.1177/089443939401200410,12,1994b,
article,doi:10.1177/27538699221128218,"Design research has much to contribute to and much to gain from the emerging field of possibility studies. In this short essay, I discuss these opportunities with respect to four topics: (1) processes of mediation and representation, (2) systems perspectives on creative work, (3) methodological options for investigation, and (4) educational challenges that should be addressed. Considering design research’s contributions to each of these topics raises interesting questions that possibility studies might address as it develops. Conversely, possibility studies is already raising issues that design research should also attend to.",Nathan Crilly,10.1177/27538699221128218,https://doi-org.crai.referencistas.com/10.1177/27538699221128218,Possibility Studies & Society,1–2,46–50,Design research and the study of the possible,https://doi-org.crai.referencistas.com/10.1177/27538699221128218,1,2023c,
article,doi:10.1177/0265532210378031,"The authors present a model of lexical proficiency based on lexical indices related to vocabulary size, depth of lexical knowledge, and accessibility to core lexical items. The lexical indices used in this study come from the computational tool Coh-Metrix and include word length scores, lexical diversity values, word frequency counts, hypernymy values, polysemy values, semantic co-referentiality, word meaningfulness, word concreteness, word imagability, and word familiarity. Human raters evaluated a corpus of 240 written texts using a standardized rubric of lexical proficiency. To ensure a variety of text levels, the corpus comprised 60 texts each from beginning, intermediate, and advanced second language (L2) adult English learners. The L2 texts were collected longitudinally from 10 English learners. In addition, 60 texts from native English speakers were collected. The holistic scores from the trained human raters were then correlated to a variety of lexical indices. The researchers found that lexical diversity, word hypernymy values and content word frequency explain 44% of the variance of the human evaluations of lexical proficiency in the examined writing samples. The findings represent an important step in the development of a model of lexical proficiency that incorporates both vocabulary size and depth of lexical knowledge features.",Scott A. Crossley and Tom Salsbury and Danielle S. McNamara and Scott Jarvis,10.1177/0265532210378031,https://doi-org.crai.referencistas.com/10.1177/0265532210378031,Language Testing,4,561–580,Predicting lexical proficiency in language learner texts using computational indices,https://doi-org.crai.referencistas.com/10.1177/0265532210378031,28,2011d,
article,doi:10.1177/17470161241247686,"Recital 33 GDPR has often been interpreted as referring to ‘broad consent’. This version of informed consent was intended to allow data subjects to provide their consent for certain areas of research, or parts of research projects, conditional to the research being in line with ‘recognised ethical standards’. In this article, we argue that broad consent is applicable in the emerging field of Computational Social Science (CSS), which lies at the intersection of data science and social science. However, the lack of recognised ethical standards specific to CSS poses a practical barrier to the use of broad consent in this field and other fields that lack recognised ethical standards. Upon examining existing research ethics standards in social science and data science, we argue that they are insufficient for CSS. We further contend that the fragmentation of European Union (EU) law and research ethics sources makes it challenging to establish universally recognised ethical standards for scientific research. As a result, CSS researchers and other researchers in emerging fields that lack recognised ethical standards are left without sufficient guidance on the use of broad consent as provided for in the GDPR. We conclude that responsible EU bodies should provide additional guidance to facilitate the use of broad consent in CSS research.",Seliem El-Sayed and Filip Paspalj,10.1177/17470161241247686,https://doi-org.crai.referencistas.com/10.1177/17470161241247686,Research Ethics,3,433–452,"No recognised ethical standards, no broad consent: navigating the quandary in computational social science research",https://doi-org.crai.referencistas.com/10.1177/17470161241247686,20,2024e,
article,doi:10.1177/1745691620970585,"Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined—what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.",Olivia Guest and Andrea E. Martin,10.1177/1745691620970585,https://doi-org.crai.referencistas.com/10.1177/1745691620970585,Perspectives on Psychological Science,4,789–802,How Computational Modeling Can Force Theory Building in Psychological Science,https://doi-org.crai.referencistas.com/10.1177/1745691620970585,16,2021f,PMID:33482070
article,doi:10.1177/0143624418759783,"People spend most of their time indoors; therefore, maintaining a good indoor air quality and meeting the requirements of comfort and energy efficiency are essential. One of the most widespread strategies to achieve this objective is improving ventilation efficiency; therefore, the main aim of this study was to show an optimization of the ventilation efficiency, in a specific room, considering 47 variations (case studies) in the furniture arrangement. For this purpose, a numerical analysis using computational fluid dynamics techniques, validated by the tracer gas decay technique, was used to assess the distribution of the age of air within the space. The concept of “age of air” was implemented in the computational fluid dynamics code through user-defined functions, using the steady-state method based on the resolution of a transport equation for an additional scalar. Variations up to 5.75% in the ventilation efficiency between the cases studied have been achieved. It is concluded that an improvement up to 1.65% can be obtained when the elements of the study are introduced in a way that facilitates the air movement towards the exhaust; therefore, improvement of the ventilation efficiency through specific furniture distributions is possible, although not significant, according to the outcomes.",Susana Hormigos-Jimenez and Miguel Ángel Padilla-Marcos and Alberto Meiss and Roberto Alonso Gonzalez-Lezcano and Jesús Feijó-Muñoz,10.1177/0143624418759783,https://doi-org.crai.referencistas.com/10.1177/0143624418759783,Building Services Engineering Research and Technology,5,557–571,Computational fluid dynamics evaluation of the furniture arrangement for ventilation efficiency,https://doi-org.crai.referencistas.com/10.1177/0143624418759783,39,2018g,
article,doi:10.1177/10762175211070350,"A phenomenon from the natural world, cricket chirping behavior in relation to ambient temperature, is used as the springboard for engaging the curiosity of gifted students in an interdisciplinary classroom curriculum. Mathematics and science standards and disciplinary practices are prominent in the investigation, while other disciplines deepen the experience. An analysis of the cricket project in terms of the Parallel Curriculum (core, connections, practice, and identity) provides an interesting lens for examining interdisciplinarity (see Tomlinson, C. A., Kaplan, S. N., Renzulli, and J. S., et al. (2009). Parallel curriculum: A design to develop learner potential and challenge advanced learners. Corwin Press).",Kim Krusen McComas,10.1177/10762175211070350,https://doi-org.crai.referencistas.com/10.1177/10762175211070350,Gifted Child Today,2,105–109,Investigating Crickets: Jumping Across the Disciplines in a Naturally Interdisciplinary Project,https://doi-org.crai.referencistas.com/10.1177/10762175211070350,45,2022h,
article,doi:10.1177/09610006221124619,"Presentation of data is a major component to academic research. However, programming languages, computational tools, and methods for exploring and analyzing data can be time consuming and frustrating to learn and finding help with these stages of the broader research process can be daunting. In this work, we highlight the impacts that computational research support programs housed in library contexts can have for fulfilling gaps in student, staff, and faculty research needs. The archival history of one such organization, Software and Services for Data Science (SSDS) in the Stanford University Cecil H. Green Library, is used to outline challenges faced by social sciences and humanities researchers from the 1980s to the present day. To compliment this history, participation metrics from consulting services (1999–2021) and workshops (2000–2021) are presented along with updated workshop participant feedback forms (n = 99) and further illustrate the profound impacts that these services can have for helping researchers succeed. Consulting and workshop metrics indicate that SSDS has supported at least 27,031 researchers between 1999 and 2021 (average of more than 1175 per year). A t-test on the feedback form data indicates that participant knowledge in workshops statistically significantly increased more than one scale point from workshop start to completion. Results also indicate that despite our successes, many past challenges continue to present barriers regardless of exponential advances in computing, teaching, and learning—specifically around learning to access data and learning the software and tools to use it. We hope that our story helps other institutions understand how indispensable computational research support is within the library.",Evan Muzzall and Vijoy Abraham and Ron Nakao,10.1177/09610006221124619,https://doi-org.crai.referencistas.com/10.1177/09610006221124619,Journal of Librarianship and Information Science,1,267–283,A perspective on computational research support programs in the library: More than 20 years of data from Stanford University Libraries,https://doi-org.crai.referencistas.com/10.1177/09610006221124619,56,2024i,
article,doi:10.1177/1475472X221079557,"Broadband noise due to the turbulence-aerofoil interaction, which is also called the leading edge noise, is one of the major noise sources of aircraft (including the engine). To study the noise properties numerically is a popular approach with the increasing power of computers. Conventional approaches of using body-fitted grids at the boundaries would be convoluted due to the complex geometries, which can constrain the efficiency of parametric studies. A promising approach to tackle this issue is to use the immersed boundary method (IBM). Among various IBM variants, the volume penalization (VP) approach employs a masking function to identify the immersed solid boundary, and continuous forcing terms are added to the original flow governing equations to account for the boundary conditions. It is, therefore, efficient and easy to implement into the existing computational aeroacoustics solvers. In this work, the VP-based IBM is used to simulate the leading edge noise by combining with the advanced synthetic turbulence method. The simulations are conducted for both the isolated aerofoils and cascade, and the results are compared with the well-validated body-fitted grid solutions. The viscosity effect is also highlighted by comparing the results obtained by solving both Euler and Navier–Stokes equations.",Wei Ying and Ryu Fattah and Sinforiano Cantos and Siyang Zhong and Tatiana Kozubskaya,10.1177/1475472X221079557,https://doi-org.crai.referencistas.com/10.1177/1475472X221079557,International Journal of Aeroacoustics,1–2,74–94,Computational aeroacoustics of aerofoil leading edge noise using the volume penalization-based immersed boundary methods,https://doi-org.crai.referencistas.com/10.1177/1475472X221079557,21,2022j,
article,doi:10.1177/14703572241247836,"Images are today at the centre of multiple social and technological tensions as a consequence of the adoption of digital coding, of the massive diffusion of social networks and of the algorithmic processing to which they are subject, resulting in new opportunities for developing analytical inquiries and meaning-producing social actions. In this introduction, the authors intend to reconstruct the broad context that makes images one of the most important resources of the digital era and to focus on some of the research tracks that characterize it. In the first part, they begin by focusing on the relationship between images and the digital, which they retrace in accordance with the selection of three key moments: the transition from ontology to the epistemology of digital media; the opening, by social networks and portable devices, of a field for the computational study of contemporary cultures; and, finally, the analytical potential arising from the encounter between digital archives and computer algorithms. In the second part, they present the three axes around which this issue is structured: archives, identity and algorithms. They first of all discuss the concept of the archive, by presenting four different understandings it has come to bear in conjunction with digital encoding – the archive as heritage, resource, effect and as database. They go on to address the relation between images and identities, arguing that social platforms and visual apps are a new domain for identity experimentation and social aggregation. Finally, they discuss the issue of algorithms and more generally of the new computational economy that associates large amounts of data with their mobilization as operational images.",Enzo D’Armenio and Maria Giulia Dondero,10.1177/14703572241247836,https://doi-org.crai.referencistas.com/10.1177/14703572241247836,Visual Communication,3,405–425,"Introduction: hyper-visuality: images in the era of social platforms, digital archives and computational economies",https://doi-org.crai.referencistas.com/10.1177/14703572241247836,23,2024a,
article,doi:10.1057/jit.2011.2,"Research on information technology has been focused primarily on the worlds of IT and management systems for business and government to the relative neglect of research on the digital and institutional infrastructures that underpin the research enterprise itself. When digital research is studied, the emphasis has been on the diffusion of technological innovations, rather than the social and political dynamics shaping the design and role of technologies in research. However, what researchers know, and with whom they collaborate, could be transformed through the strategic use of advances designed to support research, defined here as ‘research-centred computational networks’. This article presents a framework for conceptualizing the social and technological choices shaping the next generation of research in ways that could open – democratize – key aspects of the research process that move well beyond academic publication. The framework highlights the limited scope of innovation to date, and identifies a variety of factors that maintain and enhance institutional control over the research process, at the risk of losing the creative and productive bottom-up participation by networked researchers and citizen researchers among the public at large. Conceptualizing, prioritizing and advancing study of next generation research is one of the most significant but difficult challenges facing scholars of information technology.",William H Dutton,10.1057/jit.2011.2,https://doi-org.crai.referencistas.com/10.1057/jit.2011.2,Journal of Information Technology,2,109–119,The Politics of Next Generation Research Democratizing Research-Centred Computational Networks,https://doi-org.crai.referencistas.com/10.1057/jit.2011.2,26,2011b,
article,doi:10.1068/p7275,"Marr proposed that human vision constructs “a true description of what is there”. He argued that to understand human vision one must discover the features of the world it recovers and the constraints it uses in the process. Bayesian decision theory (BDT) is used in modern vision research as a probabilistic framework for understanding human vision along the lines laid out by Marr. Marr’s contribution to vision research is substantial and justly influential. We propose, however, that evolution by natural selection does not, in general, favor perceptions that are true descriptions of the objective world. Instead, research with evolutionary games shows that perceptual systems tuned solely to fitness routinely outcompete those tuned to truth. Fitness functions depend not just on the true state of the world, but also on the organism, its state, and the type of action. Thus, fitness and truth are distinct. Natural selection depends only on expected fitness. It shapes perceptual systems to guide fitter behavior, not to estimate truth. To study perception in an evolutionary context, we introduce the framework of Computational Evolutionary Perception (CEP). We show that CEP subsumes BDT, and reinterprets BDT as evaluating expected fitness rather than estimating truth.",Donald D Hoffman and Manish Singh,10.1068/p7275,https://doi-org.crai.referencistas.com/10.1068/p7275,Perception,9,1073–1091,Computational Evolutionary Perception,https://doi-org.crai.referencistas.com/10.1068/p7275,41,2012c,PMID:23409373
article,doi:10.1177/1468087420931730,"One of the major limitations of reactivity controlled compression ignition is higher unburned hydrocarbon and carbon monoxide emissions and lower thermal efficiency at part load operating conditions. In the present study, a combined numerical approach using a commercial three-dimensional computational fluid dynamics code CONVERGE along with artificial neural network and genetic algorithm is presented to address the above limitation. A production light-duty diesel engine is modified to run in reactivity controlled compression ignition by replacing an existing mechanical fuel injection system with a flexible electronic port fuel injection and common rail direct injection systems. The injection schedules of port fuel injection and direct injection injectors are controlled using National Instruments port and direct injection driver modules. Upon validation of combustion and emission parameters, parametric investigations are carried out to establish the effects of direct-injected diesel fuel timing start of injection (SOI), premixed fuel ratio and intake charge temperature on the engine performance and emissions in reactivity controlled compression ignition. The results obtained show that the start of injection timing and intake charge temperature significantly influence combustion phasing, while the premixed fuel ratio controls mixture reactivity and combustion quality. By utilizing the data generated with the validated computational fluid dynamics models, the artificial neural network models are trained to predict the engine exhaust emissions and efficiency. The artificial neural network models for gross indicated efficiency and oxides of nitrogen (NOx) are then coupled with genetic algorithm to maximize gross indicated efficiency while keeping the NOx and soot emissions within Euro VI emission limits. By optimizing the start of injection timing, premixed fuel ratio and intake charge temperature simultaneously using the artificial neural network models coupled with genetic algorithm, 19% improvement in gross indicated efficiency, 60% and 64% reduction in hydrocarbon and carbon monoxide emissions, respectively, are obtained in reactivity controlled compression ignition compared to the baseline case.",Avilash Jain and Anand Krishnasamy and Pradeep V,10.1177/1468087420931730,https://doi-org.crai.referencistas.com/10.1177/1468087420931730,International Journal of Engine Research,7,2213–2232,Computational optimization of reactivity controlled compression ignition combustion to achieve high efficiency and clean combustion,https://doi-org.crai.referencistas.com/10.1177/1468087420931730,22,2021d,
article,doi:10.1243/095765005X31261,"Abstract A typical centrifugal impeller characterized by a low flow coefficient and cylindrical blades is redesigned by means of an intelligent automatic search program. The procedure consists of a feasible sequential quadratic programming algorithm (Fletcher, R. Practical Methods of optimization, 2000 (Wiley)) coupled to a lazy learning (LL) interpolator 1 to speed-up the process. The program is able to handle geometric constraints to reduce the computational effort devoted to the analysis of non-physical configurations. The objective function evaluator is an in-house developed structured computational fluid dynamics (CFD) code. The LL approx-imator is called each time the stored database can provide a sufficiently accurate performance estimate for a given geometry, thus reducing the effective CFD computations. The impeller is represented by 25 geometric parameters describing the vane in the meridional and s-0 planes, the blade thickness, and the leading edge shape. The optimization is carried out on the impeller design point maximizing the polytropic efficiency with nearly constant flow coefficient and polytropic head. The optimization is accomplished by maintaining unaltered those geometrical parameters which have to be kept fixed in order to make the impeller fit the original stage. The optimization, carried out on a cluster of 16 PCs, is self-learning and leads to a geometry presenting an increased design point efficiency. The program is completely general and can be applied to any component which can be described by a finite number of geometrical parameters and computed by any numerical instrument to provide performance indices. The work presented in this paper was done under the METHOD EC funded project for the implementation of new technologies for optimization of centrifugal compressors.",F Martelli and S Pazzi and V Michelassi,10.1243/095765005X31261,https://doi-org.crai.referencistas.com/10.1243/095765005X31261,"Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy",7,549–557,Automatic computational fluid dynamics-based procedure for the optimization of a centrifugal impeller,https://doi-org.crai.referencistas.com/10.1243/095765005X31261,219,2005e,
article,doi:10.1177/0954406217737104,"Symbolic computational dynamic solvers are currently under development in order to provide new and powerful tools for modelling nonlinear dynamical systems. Such solvers consist of two parts; the core solver, which comprises an approximate analytical method based on perturbation, averaging, or harmonic balance, and a specialised term-tracker. A term-tracking approach has been introduced to provide a powerful new feature into computational approximate analytical solutions by highlighting the many mathematical connections that exist, but which are invariably lost through processing, between the physical model of the system, the solution procedure itself, and the final result which is usually expressed in equation form. This is achieved by a highly robust process of term-tracking, recording, and identification of all the symbolic mathematical information within the problem. In this paper, the novel source and evolution encoding method is introduced for the first time and an implementation in Mathematica is described through the development of a specialised algorithm.",Niloufar Motazedi and Matthew P Cartmell and Jem A Rongong,10.1177/0954406217737104,https://doi-org.crai.referencistas.com/10.1177/0954406217737104,"Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science",19,3439–3452,Extending the functionality of a symbolic computational dynamic solver by using a novel term-tracking method,https://doi-org.crai.referencistas.com/10.1177/0954406217737104,232,2018f,
article,doi:10.1177/0956797618823540,"Learning to read is foundational for literacy development, yet many children in primary school fail to become efficient readers despite normal intelligence and schooling. This condition, referred to as developmental dyslexia, has been hypothesized to occur because of deficits in vision, attention, auditory and temporal processes, and phonology and language. Here, we used a developmentally plausible computational model of reading acquisition to investigate how the core deficits of dyslexia determined individual learning outcomes for 622 children (388 with dyslexia). We found that individual learning trajectories could be simulated on the basis of three component skills related to orthography, phonology, and vocabulary. In contrast, single-deficit models captured the means but not the distribution of reading scores, and a model with noise added to all representations could not even capture the means. These results show that heterogeneity and individual differences in dyslexia profiles can be simulated only with a personalized computational model that allows for multiple deficits.",Conrad Perry and Marco Zorzi and Johannes C. Ziegler,10.1177/0956797618823540,https://doi-org.crai.referencistas.com/10.1177/0956797618823540,Psychological Science,3,386–395,Understanding Dyslexia Through Personalized Large-Scale Computational Models,https://doi-org.crai.referencistas.com/10.1177/0956797618823540,30,2019g,PMID:30730792
article,doi:10.1177/0002716215569220,"There is considerable controversy surrounding the study of presidential debates, particularly efforts to connect their content and impact. Research has long debated whether the citizenry reacts to what candidates say, how they say it, or simply how they appear. This study uses detailed coding of the first 2012 debate between Barack Obama and Mitt Romney to test the relative influence of the candidates’ verbal persuasiveness and nonverbal features on viewers’ “second screen” behavior—their use of computers, tablets, and mobile phones to enhance or extend the televised viewing experience. To examine these relationships, we merged two datasets: (1) a shot-by-shot content analysis coded for functional, tonal, and visual elements of both candidates’ communication behavior during the debate; and (2) corresponding real-time measures, synched and lagged, of the volume and sentiment of Twitter expression about Obama and Romney. We find the candidates’ facial expressions and physical gestures to be more consistent and robust predictors of the volume and valence of Twitter expression than candidates’ persuasive strategies, verbal utterances, and voice tone during the debate.",Dhavan V. Shah and Alex Hanna and Erik P. Bucy and Chris Wells and Vidal Quevedo,10.1177/0002716215569220,https://doi-org.crai.referencistas.com/10.1177/0002716215569220,The ANNALS of the American Academy of Political and Social Science,1,225–245,The Power of Television Images in a Social Media Age: Linking Biobehavioral and Computational Approaches via the Second Screen,https://doi-org.crai.referencistas.com/10.1177/0002716215569220,659,2015h,
article,doi:10.1177/0960327108097689,,LG Valerio,10.1177/0960327108097689,https://doi-org.crai.referencistas.com/10.1177/0960327108097689,Human & Experimental Toxicology,10,757–760,Tools for evidence-based toxicology: computational-based strategies as a viable modality for decision support in chemical safety evaluation and risk assessment,https://doi-org.crai.referencistas.com/10.1177/0960327108097689,27,2008i,PMID:19042961
article,doi:10.1068/p7327,"David Marr’s book Vision attempted to formulate a thoroughgoing formal theory of perception. Marr borrowed much of the “computational” level from James Gibson: a proper understanding of the goal of vision, the natural constraints, and the available information are prerequisite to describing the processes and mechanisms by which the goal is achieved. Yet, as a research program leading to a computational model of human vision, Marr’s program did not succeed. This article asks why, using the perception of 3D shape as a morality tale. Marr presumed that the goal of vision is to recover a general-purpose Euclidean description of the world, which can be deployed for any task or action. On this formulation, vision is underdetermined by information, which in turn necessitates auxiliary assumptions to solve the problem. But Marr’s assumptions did not actually reflect natural constraints, and consequently the solutions were not robust. We now know that humans do not in fact recover Euclidean structure—rather, they reliably perceive qualitative shape (hills, dales, courses, ridges), which is specified by the second-order differential structure of images. By recasting the goals of vision in terms of our perceptual competencies, and doing the hard work of analyzing the information available under ecological constraints, we can reformulate the problem so that perception is determined by information and prior knowledge is unnecessary.",William H Warren,10.1068/p7327,https://doi-org.crai.referencistas.com/10.1068/p7327,Perception,9,1053–1060,"Does This Computational Theory Solve the Right Problem? Marr, Gibson, and the Goal of Vision",https://doi-org.crai.referencistas.com/10.1068/p7327,41,2012j,PMID:23409371
article,doi:10.1177/1094342012474997,"The simulation of cardiac electrophysiology is a mature field in computational physiology. Recent advances in medical imaging, high-performance computing and numerical methods mean that computational models of electrical propagation in human heart tissue are ripe for use in patient-specific simulation for diagnosis, for prognosis and for selection of treatment methods. However, in order to move in this direction, it is necessary to make efficient use of modern petascale computing resources. This paper focuses on an existing open source simulation framework (Chaste) and documents work done to improve the parallel scaling on a small range of electrophysiology benchmark problems. These benchmarks involve the numerical solution of the monodomain or bidomain equations via the finite-element method. At the beginning of this study the electrophysiology libraries within Chaste were already enabled to run in parallel and were able to solve for electrical propagation using the monodomain or bidomain equations, but parallel efficiency dropped rapidly when run on more than about 64 processors. Throughout the course of the study, improvements were made to problem definition input; geometric mesh partitioning; finite-element assembly of large, sparse linear systems; problem-specific matrix preconditioning; numerical solution of the linear system; and output of the approximate solution. The consequence of these improvements is that, at the end of the study, Chaste is able to solve a monodomain benchmark problem in close to real time. While some of the improvements made to the parallel Chaste code are specific to cardiac electrophysiology, many of the techniques documented in this paper are generic to the parallel finite-element method in other scientific application areas.",Miguel O Bernabeu and James Southern and Nicholas Wilson and Peter Strazdins and Jonathan Cooper and Joe Pitt-Francis,10.1177/1094342012474997,https://doi-org.crai.referencistas.com/10.1177/1094342012474997,The International Journal of High Performance Computing Applications,1,13–32,Chaste: A case study of parallelisation of an open source finite-element solver with          applications to computational cardiac electrophysiology simulation,https://doi-org.crai.referencistas.com/10.1177/1094342012474997,28,2014a,
article,doi:10.2500/ajra.2010.24.3428,"Background Septal deviation is an extremely common anatomic variation in healthy adults. However, there are no standard criteria to determine when a deviated septum is clinically relevant. Presently, selection of patients for septoplasty is based on mostly clinical examination, which is prone to observer bias and may lead to unsuccessful treatment. The objective of this article is twofold. First, we investigate whether the location of a septal deviation within the nasal passages affects nasal resistance. Second, we test whether computer simulations are consistent with rhinomanometry studies in predicting that anterior septal deviations increase nasal resistance more than posterior deviations. Methods A three-dimensional computational model of a healthy nose was created from computed tomography scans. Geometry-deforming software was used to produce models with septal deviations. Computational fluid dynamics techniques were used to simulate nasal airflow and compute nasal resistance. Results Our results revealed that the posterior nasal cavity can accommodate significant septal deviations without a substantial increase in airway resistance. In contrast, a deviation in the nasal valve region more than doubled nasal resistance. These findings are in good agreement with the rhinomanometry literature and with the observation that patients with anterior septal deviations benefit the most from septoplasty. Conclusions In the model, anterior septal deviations increased nasal resistance more than posterior deviations. This suggests, in agreement with the literature, that other causes of nasal obstruction (dysfunction of the nasal valve, allergy, etc.) should be carefully considered in patients with posterior septal deviations because such deviations may not affect nasal resistance. This study illustrates how computational modeling and virtual manipulation of the nasal geometry are useful to investigate nasal physiology.",Guilherme J.M. Garcia and John S. Rhee and Brent A. Senior and Julia S. Kimbell,10.2500/ajra.2010.24.3428,https://doi-org.crai.referencistas.com/10.2500/ajra.2010.24.3428,American Journal of Rhinology & Allergy,1,e46–e53,Septal Deviation and Nasal Resistance: An Investigation using Virtual Surgery and Computational Fluid Dynamics,https://doi-org.crai.referencistas.com/10.2500/ajra.2010.24.3428,24,2010b,PMID:20109325
article,doi:10.1177/20552076231186513,"Objective Healthcare systems require transformation to meet societal challenges and projected health demands. Digital and computational tools and approaches are fundamental to this transformation, and hospitals have a key role to play in their development and implementation. This paper reports on a study with the objective of exploring the challenges encountered by hospital leaders and innovators as they implement a strategy to become a data-driven hospital organisation. In doing so, this paper provides guidance to future leaders and innovators seeking to build computational and digital capabilities in complex clinical settings. Methods Interviews were undertaken with 42 participants associated with a large public hospital organisation within England’s National Health Service. Using the concept of institutional readiness as an analytical framework, the paper explores participants’ perspectives on the organisation’s capacity to support the development of, and benefit from, digital and computational approaches. Results Participants’ accounts reveal a range of specific institutional readiness criteria relating to organisational vision, technical capability, organisational agility, and talent and skills that, when met, enhance the organisations’ capacity to support the development and implementation of digital and computational tools. Participant accounts also reveal challenges relating to these criteria, such as unrealistic expectations and the necessary prioritisation of clinical work in resource-constrained settings. Conclusions The paper identifies a general set of institutional readiness criteria that can guide future hospital leaders and innovators aiming to improve their organisation’s digital and computational capability. The paper also illustrates the challenges of pursuing digital and computational innovation in resource-constrained hospital environments.",John Gardner and Daniel Herron and Nick McNally and Bryan Williams,10.1177/20552076231186513,https://doi-org.crai.referencistas.com/10.1177/20552076231186513,DIGITAL HEALTH, ,20552076231186510,Advancing the digital and computational capabilities of healthcare providers: A qualitative study of a hospital organisation in the NHS,https://doi-org.crai.referencistas.com/10.1177/20552076231186513,9,2023c,PMID:36644660
article,doi:10.1177/1076217517707233,"Digital technology offers new possibilities for children to play, express themselves, learn, and communicate. A recent development in online practice is a shift toward youth engaged in computer programming online communities. Programming is argued to be the new literacy of the millennium. In this article, I examine the use of Scratch, an online programming community, as a means to support digital literacy for early adolescent gifted, talented, and creative students. In addition, I share the experiences of an early adolescent gifted student with Scratch and consider the use of Scratch to promote interdisciplinary curricular concepts.",Julia Hagge,10.1177/1076217517707233,https://doi-org.crai.referencistas.com/10.1177/1076217517707233,Gifted Child Today,3,154–162,Scratching Beyond the Surface of Literacy: Programming for Early Adolescent Gifted Students,https://doi-org.crai.referencistas.com/10.1177/1076217517707233,40,2017d,
article,doi:10.1177/1475090218763199,"Determining and understanding the performance characteristics of marine propellers by experiments is quite a complex and costly task. Numerical predictions using computational fluid dynamics simulations could be a valuable alternative provided that the laminar-to-turbulent transition flow effects are fundamentally understood with the suitable numerical models developed. Experience suggests that the use of classical turbulent flow models may lead to high discrepancies especially at low rotational speeds where the effects of fluid flow transition from the laminar to the turbulent state may influence the predicted propeller’s performance. This article proposes a complete and detailed procedure for the computational fluid dynamics simulation of non-cavitating flow over marine propellers using the “k–kl–ω” transition-sensitive turbulence model. Results are evaluated by “ANSYS FLUENT 16” for the “INSEAN E779A” propeller. Comparisons against the fully turbulent standard “k–ε” model and against experiments show improved agreement in way of flow transition zones at lower rotational speeds, that is, at low Reynolds numbers.",Mohamed M Helal and Tamer M Ahmed and Adel A Banawan and Mohamed A Kotb,10.1177/1475090218763199,https://doi-org.crai.referencistas.com/10.1177/1475090218763199,"Proceedings of the Institution of Mechanical Engineers, Part M: Journal of Engineering for the Maritime Environment",2,515–527,Numerical prediction of the performance of marine propellers using computational fluid dynamics simulation with transition-sensitive turbulence model,https://doi-org.crai.referencistas.com/10.1177/1475090218763199,233,2019e,
article,doi:10.1177/0306419015604432,"This paper describes the use of computational fluid dynamics in teaching graduate students who were in a four‐year B. Tech program. Many of these students did not have a good background in mathematics, fluid dynamics, heat transfer, and programming; however, most of them were good at computer‐aided design in ProE and were very interested in learning computational fluid dynamics as a design tool in industries. Solidworks flow simulator was chosen as the computational fluid dynamics software to teach students the entire computational fluid dynamics process in a single integrated software environment. Based on projects, computational fluid dynamics numerical methods and fundamentals of heat transfer and fluid flow were introduced to help students understand the computational fluid dynamics process, interpret, and validate simulation results. The computational fluid dynamics simulation of an orifice meter is given as the basic example for the students. Orifice meters are the most common equipment used for measuring fluid flow because of their simple mechanical structure, versatility, and low cost. In this paper, computational fluid dynamics simulation has been used to predict the orifice flow with better accuracy. Computational fluid dynamics simulations have been performed using solidworks flow simulator and validated with the data available in published literature. A new system has been proposed to accurately measure the flow using orifice metering systems.",KS Jithish and PV Ajay Kumar,10.1177/0306419015604432,https://doi-org.crai.referencistas.com/10.1177/0306419015604432,International Journal of Mechanical Engineering Education,4,233–246,Analysis of turbulent flow through an orifice meter using experimental and computational fluid dynamics simulation approach—A case study,https://doi-org.crai.referencistas.com/10.1177/0306419015604432,43,2015f,
article,doi:10.1177/1468087418808949,"Past research has shown that multidimensional computational fluid dynamics modeling in combination with a genetic algorithm method is an effective approach for optimizing internal combustion engine design. However, optimization studies performed with a detailed computational fluid dynamics model are time intensive, which limits the practical application of this approach. This study addresses this issue by using a machine learning approach called Gaussian process regression in combination with computational fluid dynamics modeling to reduce the computational optimization time. An approach was proposed where the Gaussian process regression model could be used instead of the computational fluid dynamics model to predict the outputs of the genetic algorithm optimization. In this approach, for every nth generation of the genetic algorithm, the data from the previous n − 1 generations was used to train the Gaussian process regression model. The approach was tested on an engine optimization study with five input parameters. When the genetic algorithm was run solely with computational fluid dynamics, the optimization took 50 days to complete. In comparison with the computational fluid dynamics and Gaussian process regression approach, the computational time was reduced by 62%, and the optimization was completed in 19 days using the same amount of computational resources. Additional parametric studies were performed to investigate the impact of genetic algorithm + Gaussian process regression parameters. Results showed that either reducing the initial dataset size or relaxing the error criterion resulted in increased Gaussian process regression evaluations within the genetic algorithm. However, relaxing the error criterion was found to impact the model predictions negatively. The initial dataset size was found to have a negligible impact on the final optimum design. Finally, the potential of machine learning in further improving the optimization process was explored by using the Gaussian process regression model to check for the robustness of the designs to operating parameter variations during the optimization. The genetic algorithm was repeated with the modified procedure and it was shown that adding the stability check resulted in a different, more reliable and stable optimum solution.",Chaitanya Kavuri and Sage L Kokjohn,10.1177/1468087418808949,https://doi-org.crai.referencistas.com/10.1177/1468087418808949,International Journal of Engine Research,7,1251–1270,Exploring the potential of machine learning in reducing the computational time/expense and improving the reliability of engine optimization studies,https://doi-org.crai.referencistas.com/10.1177/1468087418808949,21,2020g,
article,doi:10.1177/1468087420916380,"The effects of hydrogen addition to internal combustion engines operated by natural gas/methane has been widely demonstrated experimentally in the literature. Already small hydrogen contents in the fuel show promising benefits with respect to increased engine efficiency, lower CO2 emissions, extended lean operating limits and a higher exhaust gas recirculation tolerance while maintaining the knock resistance of methane. In this article, the influence of hydrogen addition to methane on a spark ignited single cylinder engine is investigated. This article proposes a modelling approach to consider hydrogen addition within three-dimensional reactive computational fluid dynamics in order to establish a framework to gain further insights into the involved processes. Experiments have been performed on a single-cylinder spark-ignition engine situated at a test bed and cater as reference data for validating the proposed reactive computational fluid dynamics modelling approach based around the G-Equation combustion model. Within the course of the first part, crucial aspects relevant to the modelling of the mean engine cycle are highlighted. In this article, a simplified early combustion phase model which considers the transition towards a fully developed turbulent flame following ignition is introduced, along with a second submodel considering combined effects of the walls. The sensitivity of the combustion process towards the modelling approach is presented. The submodels were calibrated for a reference operating point, and a sweep in hydrogen content in the fuel as well as stoichiometric and lean operation has been considered. It is shown that the flame speed coefficient A appearing in the used turbulent flame speed closure, weighting the influence of the turbulent fluctuating speed , has to be adjusted for different hydrogen contents. The introduced submodels allowed for significant improvement of the in-cylinder pressure and heat release rate evolution throughout all considered operating conditions.",Jann Koch and Christian Schürch and Yuri M Wright and Konstantinos Boulouchos,10.1177/1468087420916380,https://doi-org.crai.referencistas.com/10.1177/1468087420916380,International Journal of Engine Research,5,1525–1539,Reactive computational fluid dynamics modelling of methane–hydrogen admixtures in internal combustion engines: Part I – RANS,https://doi-org.crai.referencistas.com/10.1177/1468087420916380,22,2021h,
article,doi:10.1177/0309524X17709732,"This article aims to present a two-dimensional parametric analysis of a modified Savonius wind turbine using computational fluid dynamics. The effects of three independent parameters of the rotor, namely, shape factor, overlap ratio, and tip speed ratio on turbine performance were studied and then optimized for maximum coefficient of performance using response surface methodology. The rotor performance was analyzed over specific domains of the parameters under study, and three-variable Box-Behnken design was used for design of experiment. The specific parametric combinations as per design of experiment were simulated using ANSYS Fluent®, and the response variable, coefficient of performance (Cp), was calculated. The sliding mesh model was utilized, and the flow was simulated using Shear Stress Transport (SST) k − ω model. The model was validated using past experimental results and found to predict parametric effects accurately. Minitab® and ReliaSoft DOE++® were used to develop regression equation and find the optimum combination of parameters for coefficient of performance over the specified parametric domains using response surface methodology.",Haris Moazam Sheikh and Zeeshan Shabbir and Hassan Ahmed and Muhammad Hamza Waseem and Muhammad Zubair Sheikh,10.1177/0309524X17709732,https://doi-org.crai.referencistas.com/10.1177/0309524X17709732,Wind Engineering,5,285–296,Computational fluid dynamics analysis of a modified Savonius rotor and optimization using response surface methodology,https://doi-org.crai.referencistas.com/10.1177/0309524X17709732,41,2017i,
article,doi:10.1177/19458924221137982,"Background Nasal adhesions (NAs) are a known complication of nasal airway surgery. Even minor NAs can lead to significant postoperative nasal airway obstruction (NAO). Division of such NAs often provides much greater relief than anticipated. Objective We examine the impact of NAs at various anatomical sites on nasal airflow and mucosal cooling using computational fluid dynamics (CFD) and multiple test subjects. Methods CT scans of healthy adult subjects were used to construct three-dimensional nasal airway computational models. A single virtual 2.5 mm diameter NA was placed at one of five sites commonly seen following NAO surgery within each nasal cavity bilaterally, resulting in 10 NA models and 1 NA-free control for each subject. CFD analysis was performed on each NA model and compared with the subject’s NA-free control model. Results 4 subjects were recruited to create 44 computational models. The NAs caused the airflow streamlines to separate, leading to a statistically significant increase in mucosal temperature immediately downstream to the NAs (wake region). Changes in the mucosal temperature in the wake region of the NAs were most prominent in anteriorly located NAs with a mean increase of 1.62 °C for the anterior inferior turbinate NAs (P < .001) and 0.63 °C for the internal valve NAs (P < .001). Conclusion NAs result in marked disruption to airflow patterns and reduced mucosal cooling on critical surfaces, particularly in the wake region. Reduced wake region mucosal cooling may be a contributing factor to the exaggerated perception of nasal obstruction experienced by patients with NAs.",Praween Senanayake and Patrick Warfield-McAlpine and Hana Salati and Kimberley Bradshaw and Eugene Wong and Kiao Inthavong and Narinder Singh,10.1177/19458924221137982,https://doi-org.crai.referencistas.com/10.1177/19458924221137982,American Journal of Rhinology & Allergy,3,273–283,The Impact of Adhesions on Nasal Airflow: A Quantitative Analysis Using Computational Fluid Dynamics,https://doi-org.crai.referencistas.com/10.1177/19458924221137982,37,2023j,PMID:36373577
article,doi:10.1177/1754073912439766,"This article discusses work on implementing emotional and cultural models into synthetic graphical characters. An architecture, FAtiMA, implemented first in the antibullying application FearNot! and then extended as FAtiMA-PSI in the cultural-sensitivity application ORIENT, is discussed. We discuss the modelling relationships between culture, social interaction, and cognitive appraisal. Integrating a lower level homeostatically based model is also considered as a means of handling some of the limitations of a purely symbolic approach. Evaluation to date is summarised and future directions discussed.",Ruth Aylett and Ana Paiva,10.1177/1754073912439766,https://doi-org.crai.referencistas.com/10.1177/1754073912439766,Emotion Review,3,253–263,Computational Modelling of Culture and Affect,https://doi-org.crai.referencistas.com/10.1177/1754073912439766,4,2012a,
article,doi:10.1037/gpr0000050,"The prefix meta is popular in psychology as well as in other sciences oriented on the investigation of psychology. In the first case the usage is quite simple: every term is “the sum” of meta and usual psychological concept. In the second case, the situation is much more complicated. Sometimes, it is related to transition on a higher level of abstraction, from first-order to second-order investigations. Why is such a transition necessary and is it useful for scientific progress? The comparative analysis of the meta-approach to different sciences shows both specific peculiarities (reasons for application of the prefix, methods of manipulation and investigation, main objects of analysis, goals raised, and status of metaresearcher) and common features and regularities that may be discovered only in an interdisciplinary context. In this special section, we suggest a new way of application of meta-approach to psychology—in terms of metathinking. Our main idea is as follows: The wide circulation of meta-approach to psychology with necessity leads to serious changes in thinking of both researchers in the field of psychology and in sciences oriented on investigation of psychology.",Ilya E. Garber and Steven E. Wallis,10.1037/gpr0000050,https://doi-org.crai.referencistas.com/10.1037/gpr0000050,Review of General Psychology,3,329–333,Transformation of Psychology: From Thinking/Thought to Metathinking/Metathought,https://doi-org.crai.referencistas.com/10.1037/gpr0000050,19,2015b,
article,doi:10.2500/ajra.2010.24.3428,"Background Septal deviation is an extremely common anatomic variation in healthy adults. However, there are no standard criteria to determine when a deviated septum is clinically relevant. Presently, selection of patients for septoplasty is based on mostly clinical examination, which is prone to observer bias and may lead to unsuccessful treatment. The objective of this article is twofold. First, we investigate whether the location of a septal deviation within the nasal passages affects nasal resistance. Second, we test whether computer simulations are consistent with rhinomanometry studies in predicting that anterior septal deviations increase nasal resistance more than posterior deviations. Methods A three-dimensional computational model of a healthy nose was created from computed tomography scans. Geometry-deforming software was used to produce models with septal deviations. Computational fluid dynamics techniques were used to simulate nasal airflow and compute nasal resistance. Results Our results revealed that the posterior nasal cavity can accommodate significant septal deviations without a substantial increase in airway resistance. In contrast, a deviation in the nasal valve region more than doubled nasal resistance. These findings are in good agreement with the rhinomanometry literature and with the observation that patients with anterior septal deviations benefit the most from septoplasty. Conclusions In the model, anterior septal deviations increased nasal resistance more than posterior deviations. This suggests, in agreement with the literature, that other causes of nasal obstruction (dysfunction of the nasal valve, allergy, etc.) should be carefully considered in patients with posterior septal deviations because such deviations may not affect nasal resistance. This study illustrates how computational modeling and virtual manipulation of the nasal geometry are useful to investigate nasal physiology.",Guilherme J.M. Garcia and John S. Rhee and Brent A. Senior and Julia S. Kimbell,10.2500/ajra.2010.24.3428,https://doi-org.crai.referencistas.com/10.2500/ajra.2010.24.3428,American Journal of Rhinology & Allergy,1,e46–e53,Septal Deviation and Nasal Resistance: An Investigation using Virtual Surgery and Computational Fluid Dynamics,https://doi-org.crai.referencistas.com/10.2500/ajra.2010.24.3428,24,2010c,PMID:20109325
article,doi:10.1177/20552076231186513,"Objective Healthcare systems require transformation to meet societal challenges and projected health demands. Digital and computational tools and approaches are fundamental to this transformation, and hospitals have a key role to play in their development and implementation. This paper reports on a study with the objective of exploring the challenges encountered by hospital leaders and innovators as they implement a strategy to become a data-driven hospital organisation. In doing so, this paper provides guidance to future leaders and innovators seeking to build computational and digital capabilities in complex clinical settings. Methods Interviews were undertaken with 42 participants associated with a large public hospital organisation within England’s National Health Service. Using the concept of institutional readiness as an analytical framework, the paper explores participants’ perspectives on the organisation’s capacity to support the development of, and benefit from, digital and computational approaches. Results Participants’ accounts reveal a range of specific institutional readiness criteria relating to organisational vision, technical capability, organisational agility, and talent and skills that, when met, enhance the organisations’ capacity to support the development and implementation of digital and computational tools. Participant accounts also reveal challenges relating to these criteria, such as unrealistic expectations and the necessary prioritisation of clinical work in resource-constrained settings. Conclusions The paper identifies a general set of institutional readiness criteria that can guide future hospital leaders and innovators aiming to improve their organisation’s digital and computational capability. The paper also illustrates the challenges of pursuing digital and computational innovation in resource-constrained hospital environments.",John Gardner and Daniel Herron and Nick McNally and Bryan Williams,10.1177/20552076231186513,https://doi-org.crai.referencistas.com/10.1177/20552076231186513,DIGITAL HEALTH, ,20552076231186510,Advancing the digital and computational capabilities of healthcare providers: A qualitative study of a hospital organisation in the NHS,https://doi-org.crai.referencistas.com/10.1177/20552076231186513,9,2023d,PMID:36644660
article,doi:10.1243/09544119JEIM649,"Abstract The topics of verification and validation have increasingly been discussed in the field of computational biomechanics, and many recent articles have applied these concepts in an attempt to build credibility for models of complex biological systems. Verification and validation are evolving techniques that, if used improperly, can lead to false conclusions about a system under study. In basic science, these erroneous conclusions may lead to failure of a subsequent hypothesis, but they can have more profound effects if the model is designed to predict patient outcomes. While several authors have reviewed verification and validation as they pertain to traditional solid and fluid mechanics, it is the intent of this paper to present them in the context of computational biomechanics. Specifically, the task of model validation will be discussed, with a focus on current techniques. It is hoped that this review will encourage investigators to engage and adopt the verification and validation process in an effort to increase peer acceptance of computational biomechanics models.",H B Henninger and S P Reese and A E Anderson and J A Weiss,10.1243/09544119JEIM649,https://doi-org.crai.referencistas.com/10.1243/09544119JEIM649,"Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine",7,801–812,Validation of computational models in biomechanics,https://doi-org.crai.referencistas.com/10.1243/09544119JEIM649,224,2010e,PMID:20839648
article,doi:10.3233/FI-2011-534,"We show that the popular pencil puzzle NURIKABE is intractable from the computational complexity point of view, that is, it is NP-complete, even when the involved numbers are 1 and 2 only. To this end, we show how to simulate Boolean gates by the puzzle under consideration. Moreover, we also study some NURIKABE variants, which remain NP-complete, too.",Markus Holzer and Andreas Klein and Martin Kutrib and Oliver Ruepp,10.3233/FI-2011-534,https://doi-org.crai.referencistas.com/10.3233/FI-2011-534,Fundamenta Informaticae,1–4,159–174,Computational Complexity of NURIKABE,https://doi-org.crai.referencistas.com/10.3233/FI-2011-534,110,2011f,
article,doi:10.1177/1468087418808949,"Past research has shown that multidimensional computational fluid dynamics modeling in combination with a genetic algorithm method is an effective approach for optimizing internal combustion engine design. However, optimization studies performed with a detailed computational fluid dynamics model are time intensive, which limits the practical application of this approach. This study addresses this issue by using a machine learning approach called Gaussian process regression in combination with computational fluid dynamics modeling to reduce the computational optimization time. An approach was proposed where the Gaussian process regression model could be used instead of the computational fluid dynamics model to predict the outputs of the genetic algorithm optimization. In this approach, for every nth generation of the genetic algorithm, the data from the previous n − 1 generations was used to train the Gaussian process regression model. The approach was tested on an engine optimization study with five input parameters. When the genetic algorithm was run solely with computational fluid dynamics, the optimization took 50 days to complete. In comparison with the computational fluid dynamics and Gaussian process regression approach, the computational time was reduced by 62%, and the optimization was completed in 19 days using the same amount of computational resources. Additional parametric studies were performed to investigate the impact of genetic algorithm + Gaussian process regression parameters. Results showed that either reducing the initial dataset size or relaxing the error criterion resulted in increased Gaussian process regression evaluations within the genetic algorithm. However, relaxing the error criterion was found to impact the model predictions negatively. The initial dataset size was found to have a negligible impact on the final optimum design. Finally, the potential of machine learning in further improving the optimization process was explored by using the Gaussian process regression model to check for the robustness of the designs to operating parameter variations during the optimization. The genetic algorithm was repeated with the modified procedure and it was shown that adding the stability check resulted in a different, more reliable and stable optimum solution.",Chaitanya Kavuri and Sage L Kokjohn,10.1177/1468087418808949,https://doi-org.crai.referencistas.com/10.1177/1468087418808949,International Journal of Engine Research,7,1251–1270,Exploring the potential of machine learning in reducing the computational time/expense and improving the reliability of engine optimization studies,https://doi-org.crai.referencistas.com/10.1177/1468087418808949,21,2020g,
article,doi:10.1177/14782103231177107,"To aid in the development of a globally competitive workforce, federal policymakers have expressed the priority of preparing students and adults with disabilities to succeed in science, technology, engineering, and mathematics (STEM) fields. Yet, no research has examined the extent to which information-processing, literacy, numeracy, and problem-solving skills in technologically rich environments may associate with having a STEM degree for various disability populations. This study analyzed the United States nationally representative data from the Programme for the International Assessment of Adult Competencies (PIAAC) to examine associations between adult skills and having a STEM degree for people with and without disabilities. No direct associations were found between adult skills and having a STEM degree for people with learning disabilities or for people without disabilities. These groups’ information processing, literacy, numeracy, and problem-solving skills were not determining factors in STEM degree attainment. However, findings suggest a significant association between problem-solving skills and having a STEM degree for people with visual and/or hearing impairments. Policy implications are discussed.",J Jacob Kirksey and Kristin Mansell and Teresa Lansford,10.1177/14782103231177107,https://doi-org.crai.referencistas.com/10.1177/14782103231177107,Policy Futures in Education,3,427–453,"Literacy, numeracy, and problem-solving skills of adults with disabilities in STEM fields",https://doi-org.crai.referencistas.com/10.1177/14782103231177107,22,2024h,
article,doi:10.3233/jid-2017-0004,"Constructionism is at once a learning epistemology, a theory of learning, and a pedagogical approach that literally places education in the hands of learners. Constructionism situates students and mentors together in student-directed, project-oriented environments, often enabled with state-of-the-art computational technologies, to foster playful exploration and experimentation. Over time, shared learning experiences in constructionist environments may lead to the formation of learning cultures. To orient the design of constructionist environments for designers of engineering design education, this paper provides a historical context for Seymour Papert’s development of constructionism and distinguishes it from Jean Piaget’s philosophy of constructivism. Constructionism is introduced as an effort targeted at the reform of traditional education. Examples of constructionist environments for learning are then provided. The applicability of constructionism for the design of learning environments for engineering design is also discussed and observations are given for designing the tools, strategies, and activities that comprise constructionist learning environments for engineering design education.",Carolyn E. Psenka and Kyoung-Yun Kim and Gül E. Okudan Kremer and Karl R. Haapala and Kathy L. Jackson,10.3233/jid-2017-0004,https://doi-org.crai.referencistas.com/10.3233/jid-2017-0004,Journal of Integrated Design and Process Science,2,3–20,Translating Constructionist Learning to Engineering Design Education,https://doi-org.crai.referencistas.com/10.3233/jid-2017-0004,21,2017i,
article,doi:10.1177/1362361310363281,"We present results obtained with new instrumental methods for the acoustic analysis of prosody to evaluate prosody production by children with Autism Spectrum Disorder (ASD) and Typical Development (TD). Two tasks elicit focal stress — one in a vocal imitation paradigm, the other in a picture-description paradigm; a third task also uses a vocal imitation paradigm, and requires repeating stress patterns of two-syllable nonsense words. The instrumental methods differentiated significantly between the ASD and TD groups in all but the focal stress imitation task. The methods also showed smaller differences in the two vocal imitation tasks than in the picture-description task, as was predicted. In fact, in the nonsense word stress repetition task, the instrumental methods showed better performance for the ASD group. The methods also revealed that the acoustic features that predict auditory-perceptual judgment are not the same as those that differentiate between groups. Specifically, a key difference between the groups appears to be a difference in the balance between the various prosodic cues, such as pitch, amplitude, and duration, and not necessarily a difference in the strength or clarity with which prosodic contrasts are expressed.",Jan P.H. Van Santen and Emily T. Prud’hommeaux and Lois M. Black and Margaret Mitchell,10.1177/1362361310363281,https://doi-org.crai.referencistas.com/10.1177/1362361310363281,Autism,3,215–236,Computational prosodic markers for autism,https://doi-org.crai.referencistas.com/10.1177/1362361310363281,14,2010j,PMID:20591942
article,doi:10.1177/07356331231165099,"The current study aims to determine the effect of teaching a mechanic neuro-computerized course through virtual learning environments (VLE) to develop computational thinking among mathematics pre-service teachers. The neuro-computerized virtual learning environments (NCVLE) model was designed to be used to teach the mechanics course to third-year students of the mathematics department. To achieve the targeted learning outcomes, the study recruited (102) third-year students of the Faculty of Education and classified them into a control group of (50) students and an experimental group of (52) students. The experiment lasted for 14 weeks during one semester of the 2021-2022 academic year. The results agreed with most of what has been found from relevant literature and studies. Also, the results indicated that the NCVLE model played a vital role in the purposeful teaching, learning, and assessment processes and enhanced the learning of computational thinking.",Yousri Attia Mohamed Abouelenein and Mohamed Ali Nagy Elmaadaway,10.1177/07356331231165099,https://doi-org.crai.referencistas.com/10.1177/07356331231165099,Journal of Educational Computing Research,6,1175–1206,Impact of Teaching a Neuro-Computerized Course Through VLE to Develop Computational Thinking Among Mathematics Pre-service Teachers,https://doi-org.crai.referencistas.com/10.1177/07356331231165099,61,2023a,
article,doi:10.1177/07356331231205052,"Computational thinking (CT) has gained considerable attention and in-depth discussion over the last two decades. Although the significance of CT has been highlighted, it could be challenging for educators to teach CT. Fortunately, adopting robots in education has been evidenced to be of benefit to promoting students’ learning motivation, CT, and higher-order thinking skills. However, several significant factors affecting students’ programming performances in robot-assisted learning activities have been identified, such as cognitive needs and organization. In this study, a CMR-BBP (concept map robot block-based programming) approach was designed by integrating concept maps into robot block-based programming to enhance students’ programming learning. Moreover, a three-group experiment was carried out in an elementary school to evaluate their learning outcomes. The experimental results revealed that the CMR-BBP approach benefited the students’ perceptions of their computational thinking and problem solving in comparison with the R-BBP (robot block-based programming) and C-BBP (conventional block-based programming) approaches. Furthermore, regarding cognitive load, both the CMR-BBP and R-BBP approaches enhanced the students’ germane cognitive load, while the CMR-BBP approach effectively reduced their extrinsic cognitive load. This study could be a notable reference for designing other courses in conjunction with programming learning activities.",Chih-Hung Chen and Hsiang-Yu Chung,10.1177/07356331231205052,https://doi-org.crai.referencistas.com/10.1177/07356331231205052,Journal of Educational Computing Research,1,406–427,Fostering Computational Thinking and Problem-Solving in Programming: Integrating Concept Maps Into Robot Block-Based Programming,https://doi-org.crai.referencistas.com/10.1177/07356331231205052,62,2024b,
article,doi:10.1177/07356331221114183,"Computational thinking is believed to be beneficial for Science, Technology, Engineering, and Mathematics (STEM) learning as it is closely related to many other skills required by STEM disciplines. There has been an increasing interest in integrating computational thinking into STEM and many studies have been conducted to examine the effects of this intervention. This meta-analysis examined the effects of computational thinking integration in STEM on students’ STEM learning performance in the K-12 education context. Following systematic procedures, we identified 20 publications with 21 studies meeting the inclusion and exclusion criteria from a range of academic databases. We extracted effect sizes on student learning outcomes in one-group pretest-posttest designs. We also examined a range of moderating variables in the models, including student levels, STEM disciplines, intervention durations, alignment with content standards (e.g., CSTA/NGSS), types of intervention (e.g., simulation), and the use of unplugged/plugged activities. Overall, we found a statistically significant large effect size (g = 0. 85 [95% CI of 0.57–1.14]; p < .001), indicating a large overall effect of computational thinking integration on STEM learning outcomes. The effect sizes were significantly moderated by intervention durations. We provide a discussion of the findings and present implications for future research and practice.",Li Cheng and Xiaoman Wang and Albert D. Ritzhaupt,10.1177/07356331221114183,https://doi-org.crai.referencistas.com/10.1177/07356331221114183,Journal of Educational Computing Research,2,416–443,The Effects of Computational Thinking Integration in STEM on Students’ Learning Performance in K-12 Education: A Meta-analysis,https://doi-org.crai.referencistas.com/10.1177/07356331221114183,61,2023c,
article,doi:10.1177/27527263231181963,"We presented a design-based study within the context of a four-session Scratch programming activity among 23 fourth-grade students in Hong Kong. Inspired by the computational thinking (CT) strategies and the 5E instructional model, we investigated students’ mathematical learning of fractions in a Scratch (block-based programming) environment. Students developed CT concepts, practices, and perspectives by building a “fraction magic calculator” in groups. This study analyzed the lesson design, students’ drawings, interviews, and work expressing their mathematical understanding of fractions in Scratch applications. The learning tasks were designed to support the students’ fraction learning and utilized computational abstractions in the form of variables, functions, and iterations to formulate mathematical models in a programming context. Students’ artifacts and feedback showed they were interested in learning fractions in a programming learning context, contributing to exercising and improving their fraction concepts and CT. Ultimately, we emphasized the benefits of CT integrated into mathematics education, promoting students’ understanding of fraction concepts, a set of CT abilities (concepts, practices, perspectives), and learning motivation. Moreover, we suggested a set of non-cognitive skills (e.g., socializing, expressing) to enrich the CT perspectives in the framework and show the importance of developing coding communities to co-create digital artifacts among learners. Overall, we highlighted that mathematics teachers should apply and create learning tasks that promote computational thinking to forge mathematical ideas and thinking.",Xiaoxuan Fang and Davy Tsz Kit Ng and Wing Tung Tam and Manwai Yuen,10.1177/27527263231181963,https://doi-org.crai.referencistas.com/10.1177/27527263231181963,Asian Journal for Mathematics Education,2,220–239,Integrating computational thinking into primary mathematics: A case study of fraction lessons with Scratch programming activities,https://doi-org.crai.referencistas.com/10.1177/27527263231181963,2,2023d,
article,doi:10.2190/EC.49.4.b,"The paper-and-pencil programming strategy (PPS) is a way of representing an idea logically by any representation that can be created using paper and pencil. It was developed for non-computer majors to improve their understanding and use of computational thinking and increase interest in learning computer science. A total of 110 non-majors in their sophomore year were assigned to either a Logo or a PPS course with attendance being 2 hours per week for 15 weeks. To measure the effectiveness of PPS, the Group Assessment of Logical Thinking and a self-assessment survey pre- and post-test were used. Findings indicated that PPS not only improved students’ overall logical thinking as much as did Logo programming learning, but also increased scores on one more subscale of logical thinking than did the Logo course. In addition, PPS significantly helped students understand the concept of computational thinking and increased their interest in learning computer science.",Byeongsu Kim and Taehun Kim and Jonghoon Kim,10.2190/EC.49.4.b,https://doi-org.crai.referencistas.com/10.2190/EC.49.4.b,Journal of Educational Computing Research,4,437–459,Paper-and-Pencil Programming Strategy toward Computational Thinking for Non-Majors: Design Your Solution,https://doi-org.crai.referencistas.com/10.2190/EC.49.4.b,49,2013e,
article,doi:10.1177/07356331231210946,"Educational technologists and practitioners have made substantial strides in developing affordable digital and tangible resources to support both formal and informal computer science instruction. However, there is a lack of research on practice-based assignments, such as Internet of Things (IoT) projects, that allow undergraduate students to design and demonstrate educational robots using digital or physical assistance, especially when it comes to computational thinking (CT) and programming skills development in association with their psycho-emotional experience. This study compares the impact of Scratch and LEGO® WeDo robotic kits on students’ CT and programming skills development. A quasi-experimental approach was conducted, involving two hundred forty-six participants (n = 246), who were equally divided between Scratch and LEGO® WeDo groups. Results indicate that the LEGO® WeDo group showed greater improvement in CT and programming skills development, while designing and presenting IoT projects. Nevertheless, no significant association between motivation, grit, and CT skills was observed. The findings highlight the potential of tangible robotics in facilitating students’ hands-on learning and enhancing motivation to foster CT and programming skills. This study provides a wide range of implications for instructional designers on how to use tangible robotics to support hands-on IoT projects in computer science courses.",Nikolaos Pellas,10.1177/07356331231210946,https://doi-org.crai.referencistas.com/10.1177/07356331231210946,Journal of Educational Computing Research,2,620–644,"Assessing Computational Thinking, Motivation, and Grit of Undergraduate Students Using Educational Robots",https://doi-org.crai.referencistas.com/10.1177/07356331231210946,62,2024f,
article,doi:10.1177/10567879221076077,"Computational Thinking (CT) and the understanding of how programs are being executed is internationally acknowledging as a necessity for today’s students and citizens of tomorrow. Despite the multifaceted nature of CT, the introduction of CT and associate concepts such as coding is regarded as developmental acceptable for preschool and kindergarten children. For a decade, there has been a focus on educational reform in the form of educational apps. For young children, an influx of mobile apps offering various interfaces and styles promote themselves as having educational value to introduce children aged 5–7 to essential CT, coding, and problem-solving skills. On the contrary, little is known about the educational value of these apps. The fast pace at which developers produce these apps and the breadth of the available apps have gone beyond what it is reasonable for researchers and experts in the domain to evaluate. This article presents a literature review on how the ScratchJr app affects young children’s CT, coding, and general literacy skills. The literature review includes 18 studies. The main conclusion is that although ScratchJr is not a panacea, it seems to be a helpful app that positively affects children’s CT and coding skills.",Papadakis Stamatios,10.1177/10567879221076077,https://doi-org.crai.referencistas.com/10.1177/10567879221076077,International Journal of Educational Reform,1,28–61,Can Preschoolers Learn Computational Thinking and Coding Skills with ScratchJr? A Systematic Literature Review,https://doi-org.crai.referencistas.com/10.1177/10567879221076077,33,2024g,
article,doi:10.1177/09610006221084126,"This study examines the current state of assessment of computational thinking (CT) programming in public libraries in the United States. In particular, this study identifies the assessment tools and strategies that public library staff use to evaluate the success of CT youth programming, as well as how they share these assessment results, what they share, and with whom. This work also examines the perceptions of library staff on assessment of CT learning in libraries. Through our work, we highlight the need for a change of mindset in the perception of library staff toward assessment of CT learning in libraries. We also demonstrate the need for suitable assessment strategies to measure learning in CT programming in libraries beyond attendance and retention, that communicate to library staff on how they can revise their programs and to share their program impact with library stakeholders who make decisions on budget and resource allocations.",Mega Subramaniam and Nitzan Koren and Shandra Morehouse and David Weintrop,10.1177/09610006221084126,https://doi-org.crai.referencistas.com/10.1177/09610006221084126,Journal of Librarianship and Information Science,2,358–370,"Capturing computational thinking in public libraries: An examination of assessment strategies, audience, and mindset",https://doi-org.crai.referencistas.com/10.1177/09610006221084126,55,2023h,
article,doi:10.1177/07356331241236744,"The interest in Computational Thinking (CT) development among young learners increases with the number of studies located in literature. In this study, a meta-analysis was conducted to address two main objectives: (a) the effectiveness of empirical interventions on the development of CT in children aged of 3–8 years; and (b) the variables that influence the effectiveness of the interventions. Following PRISMA procedures, we identified 17 empirical studies with 34 effect sizes and 1665 participants meeting the inclusion criteria from Web of Science database. Overall, we found a statistically significant large effect size (d = .83 [95% CI: 730, .890]; p < .001) on the CT development of 3–8 years old children, which provides empirical support for having young children to engage in CT experiences. The effect size was significantly influenced by moderating variables including gender, scaffolding, and education level. Intervention length showed a marginally significant effect. Therefore, educators could refer to the significant moderators when designing tailored interventions for CT development in early childhood education while a call for more empirical studies of CT development in young children is proposed.",Xiaowen Wang and Kan Kan Chan and Qianru Li and Shing On Leung,10.1177/07356331241236744,https://doi-org.crai.referencistas.com/10.1177/07356331241236744,Journal of Educational Computing Research,5,1182–1208,Do 3–8 Years Old Children Benefit From Computational Thinking Development? A Meta-Analysis,https://doi-org.crai.referencistas.com/10.1177/07356331241236744,62,2024i,
article,doi:10.1177/07356331211057143,"This paper examined the effect of the Unplugged Programming Teaching Aids (UPTA) on students’ computational thinking and classroom interaction. A set of UPTA was created and used in a primary school in southern China. A total of 48 students aged 6–8 were assigned to two classes, with the same instructor and learning materials, but only the treatment group was provided with the UPTA. Both groups were tested on computational thinking ability, children’s concrete operation status, degree of ego-centricity, and in-classroom interaction. Results indicated that the children aged 6–8 years old could classify things according to two kinds of criteria at the same time, but their cognitive style was still ego-centered and they found it difficult to deal with problems from a third-party perspective, no matter whether in the treatment group or the control group. However, students in the treatment group achieved significantly higher scores on the test of computational thinking and were more engaged in the classroom interaction patterns. These findings provide evidence of the positive effect of the UPTA on promoting children’s computational thinking by guiding them to decompose and solve problems, as well as enhancing their interaction and communication in the classroom, so as to transform from simple imitation to collaborative inquiry.",Zehui Zhan and Wenchang He and Xitian Yi and Shuyao Ma,10.1177/07356331211057143,https://doi-org.crai.referencistas.com/10.1177/07356331211057143,Journal of Educational Computing Research,5,1277–1300,Effect of Unplugged Programming Teaching Aids on Children’s Computational Thinking and Classroom Interaction: with Respect to Piaget’s Four Stages Theory,https://doi-org.crai.referencistas.com/10.1177/07356331211057143,60,2022j,
article,doi:10.1177/0888406421992376,"Increasingly in K–12 schools, students are gaining access to computational thinking (CT) and computer science (CS). This access, however, is not always extended to students with disabilities. One way to increase CT and CS (CT/CS) exposure for students with disabilities is through preparing special education teachers to do so. In this study, researchers explore exposing special education preservice teachers to the ideas of CT/CS in the context of a mathematics methods course for students with disabilities or those at risk of disability. Through analyzing lesson plans and reflections from 31 preservice special education teachers, the researchers learned that overall emerging promise exists with regard to the limited exposure of preservice special education teachers to CT/CS in mathematics. Specifically, preservice teachers demonstrated the ability to include CT/CS in math lesson plans and showed understanding of how CT/CS might enhance instruction with students with disabilities via reflections on these lessons. The researchers, however, also found a need for increased experiences and opportunities for preservice special education teachers with CT/CS to more positively impact access for students with disabilities.",Emily C. Bouck and Phil Sands and Holly Long and Aman Yadav,10.1177/0888406421992376,https://doi-org.crai.referencistas.com/10.1177/0888406421992376,Teacher Education and Special Education,3,221–238,Preparing Special Education Preservice Teachers to Teach Computational Thinking and Computer Science in Mathematics,https://doi-org.crai.referencistas.com/10.1177/0888406421992376,44,2021a,
article,doi:10.1177/07356331221098793,"The importance of computational thinking (CT) as a 21st-century skill for future generations has been a key consideration in the reforms of many national and regional educational systems. Much attention has been paid to integrating CT into the traditional subject classrooms. This paper describes a scoping review of learning tools for integrating CT and mathematics in current empirical studies published from 2015 to 2021. The review showed that most of the studies implemented CT-intensive Math-connected integration. Five major types of CT tools had been identified, i.e., digital tangibles, apps and games, programming languages, formative or summative assessments, and other technological tools. In many instances, the tools also provide functions of assessment of CT skills. The most assessed CT competencies were including algorithms and algorithmic thinking, abstraction, testing and debugging, loops, and sequences. Geometry and Measurement was the most assessed mathematics topic. Our scoping review is beneficial in the investigation of the literature on CT and mathematics education, as well as guides those who are interested in developing curriculum, programs, or assessments that involve the integration of CT and mathematics.",Shiau-Wei Chan and Chee-Kit Looi and Weng Kin Ho and Mi Song Kim,10.1177/07356331221098793,https://doi-org.crai.referencistas.com/10.1177/07356331221098793,Journal of Educational Computing Research,8,2036–2080,Tools and Approaches for Integrating Computational Thinking and Mathematics: A Scoping Review of Current Empirical Studies,https://doi-org.crai.referencistas.com/10.1177/07356331221098793,60,2023b,
article,doi:10.1177/0735633119872908,"This study investigated young children’s computational thinking (CT) development by integrating ScratchJr into a programming curriculum. Twelve third graders (six males and six females) voluntarily participated in an experiment-based computer class conducted at a public elementary school in Taiwan. This study adopted a case study methodology to investigate research questions in one specific case (8-week CT educational training). A one-group quasi-experimental pretest and posttest design with the support of qualitative observation was used to examine four research topics: CT competence progress, programming behaviors in a CT framework, factors influencing CT competence, and learning responses to CT training. The quantitative results indicated that students immersing in weekly programming projects significantly improved in terms of their CT competence, which was mostly retained 1 month after completion of the class. The programming behaviors indicated that students’ CT concepts (sequence, event, and parallelism) and practice (testing and debugging as well as reusing and remixing) significantly improved. Moreover, parents’ active involvement in take-home assignments influenced students’ long-term CT competence retention. The qualitative results indicated that students enjoyed using tablet computers to learn ScratchJr programming and demonstrated various leaning behaviors in a three-stage instructional design model.",Pao-Nan Chou,10.1177/0735633119872908,https://doi-org.crai.referencistas.com/10.1177/0735633119872908,Journal of Educational Computing Research,3,570–595,Using ScratchJr to Foster Young Children’s Computational Thinking Competence: A Case Study in a Third-Grade Computer Class,https://doi-org.crai.referencistas.com/10.1177/0735633119872908,58,2020c,
article,doi:10.1177/07356331211060470,"Scholars believe that computational thinking is one of the essential competencies of the 21st century and computer programming courses have been recognized as a potential means of fostering students’ computational thinking. In tradition instruction, PFCT (problem identification, flow definition, coding, and testing) is a commonly adopted procedure to guide students to learn and practice computer programming. However, without further guidance, students might focus on learning the syntax of computer programming language rather than the concept of solving problems. This study proposes a peer-assessment-supported PFCT (PA-PFCT) approach for boosting students’ computer programming knowledge and computational thinking awareness. A quasi-experiment was conducted on a computer programming course in a high school to evaluate its influence on students’ learning achievement, computational thinking awareness, learning motivation, and self-efficacy. An experimental group of 51 students learned with the proposed approach, while a control group of 49 students learned with the traditional PFCT (T-PFCT) approach. The experimental results show that the proposed approach significantly enhanced the students’ computational thinking awareness, learning motivation, and self-efficacy, while not having significant impacts on their computer programming knowledge test scores.",Jian-Wen Fang and Dan Shao and Gwo-Jen Hwang and Shao-Chen Chang,10.1177/07356331211060470,https://doi-org.crai.referencistas.com/10.1177/07356331211060470,Journal of Educational Computing Research,5,1301–1324,"From Critique to Computational Thinking: A Peer-Assessment-Supported Problem Identification, Flow Definition, Coding, and Testing Approach for Computer Programming Instruction",https://doi-org.crai.referencistas.com/10.1177/07356331211060470,60,2022d,
article,doi:10.1177/0735633121992480,"This study proposed plugged and unplugged approaches for young students to simultaneously improve their interdisciplinary learning performance in English and Computational Thinking (CT). The plugged approach involved adopting educational robots to enhance CT and to provide English vocabulary and sentence practice via a board game. The unplugged version of the educational board game involved using a conventional board game without a computer, although it was designed for practicing CT as well as some foreign language vocabulary and conversational sentences. The results show that both approaches were helpful for simultaneously improving the students’ English proficiency of the target vocabulary and sentences, and their CT competence. The students’ foreign language learning anxiety during the English conversation in the plugged game was significantly lower than that of the students playing the unplugged game. On one hand, the cooperation tendency of the CT scale improved significantly for the students playing the unplugged game. On the other hand, the critical thinking of the CT scale improved significantly for those using the plugged approach. This research provides an innovation development and evaluation for plugged and unplugged approaches.",Ting-Chia Hsu and Yi-Sian Liang,10.1177/0735633121992480,https://doi-org.crai.referencistas.com/10.1177/0735633121992480,Journal of Educational Computing Research,6,1184–1207,Simultaneously Improving Computational Thinking and Foreign Language Learning: Interdisciplinary Media With Plugged and Unplugged Approaches,https://doi-org.crai.referencistas.com/10.1177/0735633121992480,59,2021e,
article,doi:10.1177/07356331241240670,"This study employs meta-analysis to synthesize findings from 30 articles investigating gender differences in computational thinking (CT) among K-12 students. Encompassing 51 independent effect sizes, the meta-analysis involves a participant pool of 9181 individuals from various countries, comprising 4254 males and 4927 females. Results indicate statistically significant gender differences in CT (Hedges’s g = 0.091, p < .05), albeit with a modest effect size, revealing higher CT scores among males compared to females. Further moderation analyses unveil the multifaceted nature of these gender differences. Specifically, while gender differences become significant during high school, recent studies suggest a gradual reduction in CT gender differences with societal progress among K-12 students. Moreover, findings illustrate variations in gender differences across geographical regions. Notably, while the overall gender disparity in CT is non-significant in the “East Asia and Pacific” region, it widens in “North America” and “Europe”, with males scoring higher than females. Conversely, in “Europe and Central Asia”, such gender differences present inconsistent outcomes, with females scoring higher than males. Importantly, assessment tool type does not significantly influence gender differences. Lastly, this study offers recommendations to address CT gender gaps, providing valuable insights for promoting gender equality in education.",Linlin Hu,10.1177/07356331241240670,https://doi-org.crai.referencistas.com/10.1177/07356331241240670,Journal of Educational Computing Research,5,1358–1384,Exploring Gender Differences in Computational Thinking Among K-12 Students: A Meta-Analysis Investigating Influential Factors,https://doi-org.crai.referencistas.com/10.1177/07356331241240670,62,2024f,
article,doi:10.1177/07356331221121106,"This study investigates how digital game co-creation promotes Computational Thinking (CT) skills among children in sub-urban primary schools. Understanding how CT skills can be fostered in learning programming concepts through co-creating digital games is crucial to determine instructional strategies that match the young students’ interests and capacities. The empirical study has successfully produced a new checklist that can be used as a tool to describe the learning of CT skills when children co-create digital games. The checklist consists of 10 core CT skills: abstraction, decomposition, algorithmic thinking, generalisation, representation, socialisation, code literacy, automation, coordination, and debugging. Thirty-six 10–12 year-olds from sub-urban primary schools in Borneo participated in creating games in three separate eight-hour sessions. In addition, one pilot session with five participants was conducted. The game co-creation process was recorded to identify and determine how these young, inexperienced, untrained young learners collaborated while using CT skills. Analysis of their narratives while co-creating digital games revealed a pattern of using CT while developing the games. Although none of the groups demonstrated the use of all ten CTs, conclusively, all ten components of the CT were visibly present in their co-created digital games.",Mohd Kamal Othman and Syazni Jazlan and Fatin Afiqah Yamin and Shaziti Aman and Fitri Suraya Mohamad and Nurfarahani Norman Anuar and Abdulrazak Yahya Saleh and Ahmad Azaini Abdul Manaf,10.1177/07356331221121106,https://doi-org.crai.referencistas.com/10.1177/07356331221121106,Journal of Educational Computing Research,2,355–389,Mapping Computational Thinking Skills Through Digital Games Co-Creation           Activity Amongst Malaysian Sub-urban Children,https://doi-org.crai.referencistas.com/10.1177/07356331221121106,61,2023g,
article,doi:10.1177/07356331231210560,"Pair programming (PP) can help improve students’ computational thinking (CT), but the trajectory of CT skills and the differences between high-scoring and low-scoring students in PP are unknown and need further exploration. In this study, a total of 32 fifth graders worked on Scratch tasks in 16 pairs. The group discourse of three learning topics (comprising 9 projects) was collected. After the audio files were transcribed, 1,303 conversations were obtained. They were analyzed via Epistemic Network Analysis (ENA) Webkit, which can reveal the trajectory of students’ CT development via analyzing codes of discourse related to CT in PP. Three Scratch learning topics were assessed based on the Dr. Scratch platform to acquire the level of students’ CT and to determine the low- and high-scoring groups. Results indicated that CT concepts and CT practices were always closely related in PP and CT practices, and CT perspectives could be gradually and closely related after a long period of CT training. A significant difference between the two groups’ CT structures was found. The high-scoring group had more fragments of CT practice and connecting of CT perspectives, while the low-scoring group showed more fragments of CT concepts and expressing of CT perspectives. This research provides insights into cultivating primary school students’ CT using Scratch in the context of PP. The findings can provide suggestions for instructors to design instructional interventions to facilitate students’ CT skills via PP learning. Instructors can improve CT skills by guiding students to constantly ask questions, and specifying the role swap between driver and navigator in PP. Besides, instructors could give more consideration to the development of CT perspectives, and especially the ability to question.",Yu-Sheng Su and Shuwen Wang and Xiaohong Liu,10.1177/07356331231210560,https://doi-org.crai.referencistas.com/10.1177/07356331231210560,Journal of Educational Computing Research,2,559–593,Using Epistemic Network Analysis to Explore Primary School Students’ Computational Thinking in Pair Programming Learning,https://doi-org.crai.referencistas.com/10.1177/07356331231210560,62,2024h,
article,doi:10.1177/07356331241227793,"Computational thinking (CT), an essential 21st century skill, incorporates key computer science concepts such as abstraction, algorithms, and debugging. Debugging is particularly underrepresented in the CT training literature. This multi-level meta-analysis focused on debugging as a core CT skill, and investigated the effects of various debugging interventions. Moderator analyses revealed which interventions were effective, in which situations, and for what kind of learner. A significant overall mean effect of debugging interventions ( = 0.64, CI = (0.32, 0.96), p < .001), was found based on 62 effect sizes from 18 source articles. Significant between-studies variation indicated that true effects could range from −0.54 to 1.82. In addition, sensitivity analyses and checks on confounding provided further understandings of intervention features and their impacts. Interventions using enhanced debuggers and systematic instruction were particularly effective in fostering debugging skills. Debugging intervention effects varied by participant population and potentially by publication type. Moreover, debugging interventions had impact regardless of how debugging skills were measured, programming medium used, control-group type, and whether the study was randomized. Future studies should investigate the best practices for improving debugging abilities for whom and under what circumstances.",Chen Sun and Stephanie Yang and Betsy Becker,10.1177/07356331241227793,https://doi-org.crai.referencistas.com/10.1177/07356331241227793,Journal of Educational Computing Research,4,1087–1121,Debugging in Computational Thinking: A Meta-analysis on the Effects of Interventions on Debugging Skills,https://doi-org.crai.referencistas.com/10.1177/07356331241227793,62,2024i,
article,doi:10.1177/07356331211035182,"In this work, we studied the influence of different programming approaches on the development of students’ computational thinking (CT) skills, the programming experience and gender differences in CT development were also discussed. A total of 158 junior high school students and one teacher participated in the study over 5 months. The sample students were divided into four experimental groups in four single or combined programming approaches (i.e., plugged-in, unplugged, unplugged first, and plugged-in first) and one control group without programming. Data sources included the results of four CT tests, as well as interviews with the teacher and surveys with 24 representative participants. The results showed that the four programming approaches can effectively improve students’ CT skills and can be retained after two months. Among them, the form of implementing unplugged activities before plugged-in can most effectively improve CT skills, and can better weaken the impact of previous programming experience. Finally, the qualitative analysis results provided insights into the process of programming and CT education. These findings will provide implications for the introduction of CT in junior high school, and help expand students’ participation in computing.",Lihui Sun and Linlin Hu and Danhua Zhou,10.1177/07356331211035182,https://doi-org.crai.referencistas.com/10.1177/07356331211035182,Journal of Educational Computing Research,2,283–321,Single or Combined? A Study on Programming to Promote Junior High School Students’ Computational Thinking Skills,https://doi-org.crai.referencistas.com/10.1177/07356331211035182,60,2022j,
article,doi:10.1177/0162643420978564,"The ideas of computational thinking (CT) and computer science (CS) are increasingly being integrated into K-12 education. Yet, insufficient attention exists regarding access and exposure of CT and CS for students with disabilities. In this Technology in Action, the authors sought to present an argument—as well as actual activities—for teachers to start to expose and engage students with disabilities in CT and CS. Through the presentation of case studies as well as other non-case situated activities, practical ideas, and steps for integrating CT and CS in mathematics teaching and learning for students with disabilities are presented.",Emily C. Bouck and Aman Yadav,10.1177/0162643420978564,https://doi-org.crai.referencistas.com/10.1177/0162643420978564,Journal of Special Education Technology,1,151–160,Providing Access and Opportunity for Computational Thinking and Computer Science to Support Mathematics for Students With Disabilities,https://doi-org.crai.referencistas.com/10.1177/0162643420978564,37,2022a,
article,doi:10.1177/0735633120979930,"In this paper, we explore the challenges experienced by a group of Primary 5 to 6 (age 12–14) students as they engaged in a series of problem-solving tasks through block-based programming. The challenges were analysed according to a taxonomy focusing on the presence of computational thinking (CT) elements in mathematics contexts: preparing problems, programming, create computational abstractions, as well as troubleshooting and debugging. Our results suggested that the challenges experienced by students were compounded by both having to learn the CT-based environment as well as to apply mathematical concepts and problem solving in that environment. Possible explanations for the observed challenges stemming from differences between CT and mathematical thinking are discussed in detail, along with suggestions towards improving the effectiveness of integrating CT into mathematics learning. This study provides evidence-based directions towards enriching mathematics education with computation.",Zhihao Cui and Oi-Lam Ng,10.1177/0735633120979930,https://doi-org.crai.referencistas.com/10.1177/0735633120979930,Journal of Educational Computing Research,5,988–1012,The Interplay Between Mathematical and Computational Thinking in Primary School Students’ Mathematical Problem-Solving Within a Programming Environment,https://doi-org.crai.referencistas.com/10.1177/0735633120979930,59,2021b,
article,doi:10.1177/07356331241251397,"Previous research has not adequately explored students’ behavioral processes when addressing computational thinking (CT) problems of varying difficulty, limiting insights into students’ detailed CT development characteristics. This study seeks to fill this gap by employing gamified CT items across multiple difficulty levels to calculate comprehensive behavioral sequence quality indicators. And then, through latent profile analysis, we identified four distinct latent classes of behavioral process. We then examined the in-game performance differences among these classes, uncovering each class’s unique attributes. Class 1 students consistently demonstrated high-quality, efficient behavioral sequences regardless of item difficulty. In contrast, class 2 students applied significant cognitive effort and trial-and-error strategies, achieving acceptable scores despite low behavioral sequence quality. Class 3 students excelled in simpler items but faltered with more complex ones. Class 4 students displayed low motivation for challenging items, often guessing answers quickly. Additionally, we investigated the predictive value of students’ performance in gamified items and their behavioral process classes for their external CT test scores. The study finally elaborated on the theoretical implications for researchers and the practical suggestions for teachers in CT cultivation.",Qing Guo and Huan Li and Sha Zhu,10.1177/07356331241251397,https://doi-org.crai.referencistas.com/10.1177/07356331241251397,Journal of Educational Computing Research,6,1475–1508,Understanding the Characteristics of Students’ Behavioral Processes in Solving Computational Thinking Problems Based on the Behavioral Sequences,https://doi-org.crai.referencistas.com/10.1177/07356331241251397,62,2024c,
article,doi:10.1177/21582440231217715,"The capability of computer programming language logic is one of the basics of technical education. How to improve students “interest in program logic design and help overcome students” fears of coding has become vital for educators. Cultivating practical talents with information technology application and basic programming development will become one of the important topics in the department of information related science. The objective of this research is to improve the ability of learning basic programming courses by using Zuvio interactive software. Zuvio employs the mathematical logic of computational thinking to analyze problems and enhance learners’ interest in learning programming skills through a graphical interface tool with building blocks. It uses innovative interactive teaching to use peer and self-assessment to study the content of the course. Zuvio improves the design ability of different groups of class learning Python programming. In line with the innovative teaching policy of the schools and the current stage of the learner’s learning model, learning effectiveness can be achieved. The research results were analyzed by midterm and final experimental group scores, and the progress of the experimental group’s scores was examined through descriptive statistics. The average and standard deviation of the assessment were used to analyze the progress of the experimental group students in the programming course. In the classroom, assessment criteria were set up as the basis for peer assessment scoring. After the midterm and final exams, the teacher assessment and peer assessment scores were analyzed for cognitive differences, and possible learning differences were analyzed. The students’ professional ability was examined to see if it met the professional standards required by the course, and whether innovative teaching methods could improve the learning outcomes of learners with different professional backgrounds in Python programming.",Tsung-Chih Hsiao and Ya-Hsueh Chuang and Chien-Yun Chang and Tzer-Long Chen and Hong-Bo Zhang and Jhih-Chung Chang,10.1177/21582440231217715,https://doi-org.crai.referencistas.com/10.1177/21582440231217715,Sage Open,4,21582440231217716,Combining Building Block Process With Computational Thinking Improves Learning Outcomes of Python Programming With Peer Assessment,https://doi-org.crai.referencistas.com/10.1177/21582440231217715,13,2023d,
article,doi:10.1177/0735633119887187,"Persistence has proven to be a great challenge in online learning environments. Gaming and interactivity have been suggested as essential features in reducing dropout and increasing persistence in online learning. Yet in interactive game-based learning environments, persistence in moving forward in the game may come at the expense of investing in each of the game’s levels. That is, the motivation to complete the game may have a deleterious effect on learning at specific levels and hence on learning from the game in general. Therefore, we have chosen to focus on microlevel persistence (i.e., persistence during each component of the learning process). We study microlevel persistence in the context of acquiring computational thinking—the thought process of solving problems through abstraction—which is a key component of the new literacies needed for tomorrow’s citizens. In this study, we analyze data collected from an online, game-based learning environment (CodeMonkeyTM). The data document the activity of first to sixth graders (N = 2,040). Overall, we find that persistence is positively associated with difficulty and that the most determined learners were highly persistent across topics in achieving the best solution.",Rotem Israel-Fishelson and Arnon Hershkovitz,10.1177/0735633119887187,https://doi-org.crai.referencistas.com/10.1177/0735633119887187,Journal of Educational Computing Research,5,891–918,Persistence in a Game-Based Learning Environment: The Case of Elementary School Students Learning Computational Thinking,https://doi-org.crai.referencistas.com/10.1177/0735633119887187,58,2020e,
article,doi:10.1177/0022487117732317,"This article examines teacher preparation and teacher change in engineering and computer science education. We examined culturally responsive teaching self-efficacy (CRTSE), culturally responsive teaching outcome expectancy (CRTOE) beliefs, and attitudes toward computational thinking (CT) as teachers participated in one of three treatment groups: robotics only, game design only, or blended robotics/game design. Descriptive data revealed that CRTSE gain scores were higher in the robotics only and blended contexts than in the game design only context. However, CRTOE beliefs were consistent across all treatment groups. In regard to CT attitudes, teachers’ gain scores were higher in the game design only and blended contexts than in the robotics only context. In addition, there were differences by treatment group related to STEM (science, technology, engineering, and mathematics) practices, while cultural artifacts were evident in each learning environment. The results of this study reveal some variability by treatment type and inform future research on equitable practices in engineering and computer science education.",Jacqueline Leonard and Monica Mitchell and Joy Barnes-Johnson and Adrienne Unertl and Jill Outka-Hill and Roland Robinson and Carla Hester-Croff,10.1177/0022487117732317,https://doi-org.crai.referencistas.com/10.1177/0022487117732317,Journal of Teacher Education,4,386–407,"Preparing Teachers to Engage Rural Students in Computational Thinking Through Robotics, Game Design, and Culturally Responsive Teaching",https://doi-org.crai.referencistas.com/10.1177/0022487117732317,69,2018f,
article,doi:10.1177/07356331221133822,"Underpinning the teaching of coding with Computational Thinking has proved relevant for diverse learners, particularly given the increasing demand in upskilling for today’s labour market. While literature on computing education is vast, it remains unexplored how existing CT conceptualisations relate to the learning opportunities needed for a meaningful application of coding in non-Computer Scientists’ lives and careers. In order to identify and organise the learning opportunities in the literature about CT, we conducted a configurative literature review of studies published on Web of Science, between 2006 and 2021. Our sample gathers 34 papers and was analysed on NVivo to find key themes. We were able to organise framings of CT and related learning opportunities into three dimensions: functional, collaborative, and critical and creative. These dimensions make visible learning opportunities that range from individual cognitive development to interdisciplinary working with others, and to active participation in a technologically evolving society. By comparing and contrasting frameworks, we identify and explain different perspectives on skills. Furthermore, the three-dimensional model can guide pedagogical design and practice in coding courses.",Ana Melro and Georgie Tarling and Taro Fujita and Judith Kleine Staarman,10.1177/07356331221133822,https://doi-org.crai.referencistas.com/10.1177/07356331221133822,Journal of Educational Computing Research,4,901–924,What Else Can Be Learned When Coding? A Configurative Literature Review of Learning Opportunities Through Computational Thinking,https://doi-org.crai.referencistas.com/10.1177/07356331221133822,61,2023g,
article,doi:10.1177/07356331231225269,"Computational thinking (CT), as a new future-oriented literacy, has gained attention at the basic education level. Graphical programming is the common way to develop CT in primary students, but this drag-and-drop programming may weaken students’ understanding of programming’s abstract concepts and code logic. Text-based programming approaches can solve the problems faced by graphical programming, but few studies have explored the impact of text-based programming on CT. Therefore, we conducted a quasi-experimental study with 98 6th graders to explore the impact of gamified Python programming on CT. The findings showed that CT skills, as well as abstraction and decomposition, pattern recognition and evaluation in CT sub-skills, were significantly higher with students in the experimental group than in the control group. Furthermore, we found that gamified Python programming enabled boys and girls to reach the same level of CT skills. However, in terms of CT sub-skills, we found that gamified Python programming was more beneficial to the development of pattern recognition and evaluation skills for boys and abstraction and decomposition skills for girls. This demonstrated the effectiveness of gamified Python programming to improve primary students’ CT skills while clarifying the impact of gender and enriching research in the field of text-based programming.",Lihui Sun and Junjie Liu,10.1177/07356331231225269,https://doi-org.crai.referencistas.com/10.1177/07356331231225269,Journal of Educational Computing Research,3,846–874,Effects of Gamified Python Programming on Primary School Students’ Computational Thinking Skills: A Differential Analysis of Gender,https://doi-org.crai.referencistas.com/10.1177/07356331231225269,62,2024h,
article,doi:10.1177/07356331211051043,"This study aimed to develop the Computational Thinking Test for Elementary School Students (CTT-ES) to assess young children’s CT competencies in non-programming contexts and also examine the relationship between CT competencies and CT dispositions. A survey including a pool of CTT-ES candidate items and the Computational Thinking Scale (CTS) was administered to 631 elementary school students. Rasch model of the Item Response Theory and the discrimination analysis of the Classical Testing Theory were conducted for item analyses. Pearson’s correlation analyses and hierarchical multiple regression analyses were used to examine the relationships between CTT-ES and CTS scores. The results showed that the final CTT-ES including 16 items had a good fitness, discrimination, and reliability to evaluate elementary students’ domain-general CT competencies. The convergent validity of CTT-ES was confirmed by its significant correlations with the CTS scores. The significant regression model not only showed students’ CT competencies can be predicted by their CT dispositions but also supported The Developmental Model of CT. This study provided a valid and reliable tool for assessing young children’s CT abilities. It also furthered our understanding about the developmental orders of CT abilities and contributed to the theoretical construction of CT.",Meng-Jung Tsai and Francis Pingfan Chien and Silvia Wen-Yu Lee and Chung-Yuan Hsu and Jyh-Chong Liang,10.1177/07356331211051043,https://doi-org.crai.referencistas.com/10.1177/07356331211051043,Journal of Educational Computing Research,5,1110–1129,Development and Validation of the Computational Thinking Test for Elementary School Students (CTT-ES): Correlate CT Competency With CT Disposition,https://doi-org.crai.referencistas.com/10.1177/07356331211051043,60,2022i,
article,doi:10.1177/07356331211039961,"Many countries have incorporated computational thinking (CT) and programming languages into their science and technology courses. Students can improve their CT ability by learning programming languages. Moreover, situated learning enables students to generate knowledge and master problem-solving skills through interaction with situations. This study incorporated Webduino learning and the situated learning strategy into a programming course and analyzed its impact on high school students’ CT ability, learning motivation, and course satisfaction. A quasi-experimental research method was adopted, wherein the experimental group was subjected to the situated learning strategy and the control group was subjected to a traditional teaching method. The study results revealed that integrating Webduino programming with situated learning could effectively improve five categories of CT skills; moreover, the activity models of situated learning enhanced the value and expectation dimensions of learning motivation. In addition, satisfaction with the course content and self-identity slightly improved. However, because teachers were required to elaborate on stories to promote learner engagement with life situations, the time available for programming was limited. Thus, no significant difference was observed in teaching satisfaction.",Ting-Ting Wu and Jian-Ming Chen,10.1177/07356331211039961,https://doi-org.crai.referencistas.com/10.1177/07356331211039961,Journal of Educational Computing Research,3,631–660,"Combining Webduino Programming With Situated Learning to Promote Computational Thinking, Motivation, and Satisfaction Among High School Students",https://doi-org.crai.referencistas.com/10.1177/07356331211039961,60,2022j,
article,doi:10.1177/1326365X20970421,,Kayt Davies,10.1177/1326365X20970421,https://doi-org.crai.referencistas.com/10.1177/1326365X20970421,Asia Pacific Media Educator,2,234–242,Why I Do Not Talk About Computational Thinking in Journalism Classes: Sorry (Not Really Sorry),https://doi-org.crai.referencistas.com/10.1177/1326365X20970421,30,2020a,
article,doi:10.1177/0735633120973432,"This study explored (1) pedagogical strategies in Educational Coding and Robotics (ECR) learning which can develop computational thinking of students and (2) the degree of teacher centrality in the ECR classroom. In addition, we investigated (3) the added value of the Small Private Online Course (SPOC) to teacher professional development (TPD). We analyzed reflections of 80 in-service teachers on TPD through the SPOC (1,091 statements) and conducted semi-structured interviews with 13 of them one year after completing the course and teaching ECR in the classroom (328 statements). The most prominent strategies immediately after the TPD were constructing learning experiences, tinkering & debugging, and interdisciplinary learning, while one year later, experiential learning and collaborative learning were more common. Regarding the degree of teacher centrality, a year after teaching ECR curriculum the teachers had a significantly higher percentage of statements reflecting their role as a guide-on-the-side and as a partner of students in the learning process. Regarding the contribution of the SPOC for TPD, teacher statements revealed significantly more benefits than challenges in both points of time. Interestingly, the same categories emerged bottom-up as benefits and challenges: a variety of control dimensions, independent learning, learning and knowledge management and collaboration. Implications for educational theory and ECR practice are discussed.",Shlomit Hadad and Tamar Shamir-Inbal and Ina Blau and Eynat Leykin,10.1177/0735633120973432,https://doi-org.crai.referencistas.com/10.1177/0735633120973432,Journal of Educational Computing Research,4,763–791,Professional Development of Code and Robotics Teachers Through Small Private Online Course (SPOC): Teacher Centrality and Pedagogical Strategies for Developing Computational Thinking of Students,https://doi-org.crai.referencistas.com/10.1177/0735633120973432,59,2021b,
article,doi:10.1177/0040059915594790,,Maya Israel and Quentin M. Wherfel and Jamie Pearson and Saadeddine Shehab and Tanya Tapia,10.1177/0040059915594790,https://doi-org.crai.referencistas.com/10.1177/0040059915594790,TEACHING Exceptional Children,1,45–53,Empowering K–12 Students With Disabilities to Learn Computational Thinking and Computer Programming,https://doi-org.crai.referencistas.com/10.1177/0040059915594790,48,2015c,
article,doi:10.1177/07356331231211916,"Science, Technology, Engineering, and Mathematics (STEM) education is essential for developing future-ready learners in both secondary and higher education levels. However, as students transition to higher education, many encounter challenges with independent learning and research. This can negatively impact their Higher-Order Thinking Skills (HOTS), engagement, and practical expertise. This study introduces a solution: Computational Thinking Scaffolding (CTS) in the Jupyter Notebook environment, designed to enhance STEM education at the tertiary level. CTS incorporates five phases: Decomposition, Pattern Recognition, Abstraction, Algorithm Design, and Evaluation. Utilizing a quasi-experimental method, we assessed the impact of CTS on the HOTS, engagement, and practical skills of undergraduate and postgraduate students. Our findings hold substantial relevance for university educators, academic advisors, and curriculum designers aiming to enhance students’ HOTS and hands-on capabilities in STEM disciplines. The results validate the effectiveness of CTS in elevating tertiary STEM learning outcomes, and they spotlight the adaptability of the Jupyter Notebook as a valuable tool in higher education. In conclusion, our research underscores the merits of CTS for improving outcomes in higher STEM education and sets a benchmark for future endeavors in this domain.",Hsin-Yu Lee and Ting-Ting Wu and Chia-Ju Lin and Wei-Sheng Wang and Yueh-Min Huang,10.1177/07356331231211916,https://doi-org.crai.referencistas.com/10.1177/07356331231211916,Journal of Educational Computing Research,2,431–467,"Integrating Computational Thinking Into Scaffolding Learning: An Innovative Approach to Enhance Science, Technology, Engineering, and Mathematics Hands-On Learning",https://doi-org.crai.referencistas.com/10.1177/07356331231211916,62,2024d,
article,doi:10.1177/1461444820923674,"Although socializing is a powerful driver of youth engagement online, platforms struggle to leverage social engagement to promote learning. We seek to understand this dynamic using a multi-stage analysis of over 14,000 comments on Scratch, an online platform designed to support learning about programming. First, we inductively develop the concept of “participatory debugging”—a practice in which users learn through the process of collaborative technical troubleshooting. Second, we use a content analysis to establish how common the practice is on Scratch. Third, we conduct a qualitative analysis of user activity over time and identify three factors that serve as social antecedents of participatory debugging: (1) sustained community, (2) identifiable problems, and (3) what we call “topic porousness” to describe conversations that are able to span multiple topics. We integrate these findings in a framework that highlights a productive tension between the desire to promote learning and the interest-driven sub-communities that drive user engagement in many new media environments.",Samantha Shorey and Benjamin Mako Hill and Samuel Woolley,10.1177/1461444820923674,https://doi-org.crai.referencistas.com/10.1177/1461444820923674,New Media & Society,8,2327–2344,From hanging out to figuring it out: Socializing online as a pathway to computational thinking,https://doi-org.crai.referencistas.com/10.1177/1461444820923674,23,2021e,
article,doi:10.1177/07356331231204653,"Although previous research has provided some insights into the effects of block-based and text-based programming modalities, there is a dearth of a detailed, multi-dimensional analysis of the transition process from different introductory programming modalities to professional programming learning. This study employed a quasi-experimental design to address this gap, involving 64 secondary school students in two groups. For the beginning five weeks, the first group used an introductory block-based programming environment, while the second group used an introductory text-based programming environment. Then, both groups transitioned to professional text-based programming for the subsequent eight weeks. The results showed that participants who transitioned from introductory text-based programming to professional text-based programming (1) significantly outperformed in computational thinking skills; (2) had more code-writing and debugging behaviors and fewer irrelevant behaviors, and (3) had more interactions with the instructor. No significant differences were observed between the two groups regarding enjoyment, confidence, and interest in programming. Drawing on these findings, this study proposes pedagogical implications that could facilitate the adoption of programming modalities within the broader context of STEM education.",Dan Sun and Chengcong Zhu and Fan Xu and Yan Li and Fan Ouyang and Miaoting Cheng,10.1177/07356331231204653,https://doi-org.crai.referencistas.com/10.1177/07356331231204653,Journal of Educational Computing Research,3,647–674,"Transitioning From Introductory to Professional Programming in Secondary Education: Comparing Learners’ Computational Thinking Skills, Behaviors, and Attitudes",https://doi-org.crai.referencistas.com/10.1177/07356331231204653,62,2024f,
article,doi:10.1177/07356331241248686,"A growing body of research is focusing on integrating artificial intelligence (AI) and computational thinking (CT) to enhance student learning outcomes. Many researchers have designed instructional activities to achieve various learning goals within this field. Despite the prevalence of studies focusing on instructional design and student learning outcomes, how instructional efforts result in the integration of AI and CT in students’ learning processes remains unclear. To address this research gap, we conducted a systematic literature review of empirical studies that have integrated AI and CT for student development. We collected 18 papers from four prominent research databases in the fields of education and AI technology: Web of Science, Scopus, IEEE, and ACM. We coded the collected studies, highlighting the students’ learning processes in terms of research methodology and context, learning tools and instructional design, student learning outcomes, and the interaction between AI and CT. The integration of AI and CT occurs in two ways: the integration of disciplinary knowledge and leveraging AI tools to learn CT. Specifically, we discovered that AI- and CT-related tools, projects, and problems facilitated student-centered instructional designs, resulting in productive AI and CT learning outcomes.",Xiaojing Weng and Huiyan Ye and Yun Dai and Oi-lam Ng,10.1177/07356331241248686,https://doi-org.crai.referencistas.com/10.1177/07356331241248686,Journal of Educational Computing Research,6,1640–1670,Integrating Artificial Intelligence and Computational Thinking in Educational Contexts: A Systematic Review of Instructional Design and Student Learning Outcomes,https://doi-org.crai.referencistas.com/10.1177/07356331241248686,62,2024g,
article,doi:10.1177/07356331241226459,"Computational Thinking (CT) is essential for developing creativity, problem-solving, and digital competence in the 21st century. Coding tools like robotic toys and tablet apps have become popular in early childhood education to support CT development, but there is a debate on which tool is more effective. Little evidence exists on the effect of coding on children’s Social-Emotional Competence (SEC), which is crucial for lifelong development and extends beyond cognitive development. This experimental study aimed to compare the effectiveness of two 9-week programs on promoting 73 preschool children’s CT and SEC, one using coding robots and the other using coding apps. The results showed that children who participated in the Coding Robot Program had higher CT scores than those in the Coding App Program, after controlling for age, gender, family socioeconomic status, and baseline CT scores. While the SEC scores showed no substantial disparities between the groups, it was revealed that the initial performance levels moderated the intervention effects on emotional regulation and overall SEC. This suggests that the Coding Robot Program could be especially advantageous for a subset of children who initially have difficulties with emotional regulation and social skills. Implications of this study are presented for research and practice.",Weipeng Yang,10.1177/07356331241226459,https://doi-org.crai.referencistas.com/10.1177/07356331241226459,Journal of Educational Computing Research,4,938–960,Coding With Robots or Tablets? Effects of Technology-Enhanced Embodied Learning on Preschoolers’ Computational Thinking and Social-Emotional Competence,https://doi-org.crai.referencistas.com/10.1177/07356331241226459,62,2024h,
article,doi:10.1177/02103702241253407,"Fostering young children’s computational thinking (CT) has garnered global interest as it aligns with the cultivation of twenty-first-century skills. Previous studies have focused on physical, virtual and hybrid kits with virtual programming blocks, but rarely explored the use of hybrid kits that combine virtual sprites and physical programming environments. We conducted a quasi-experimental study to investigate the effect of using a hybrid programming kit on young children’s CT. Furthermore, we explored the characteristics of children’s programming engagement and the instructional strategies employed by teachers through video analysis and interviews. The results showed that: (1) children’s CT in the experimental group significantly improved, compared to that of peers in the control group; (2) children’s programming behaviour demonstrated a change from ‘action preceding thought’ to ‘thought preceding action’ and from ‘relying on trial and error’ to ‘active debugging’ with the support of teachers; (3) teachers used multiple strategies to support young children’s programming. These findings further indicate the importance of introducing programming in early childhood education and emphasize the critical role that teachers play in supporting young children’s learning of programming.",Yue Zeng and Weipeng Yang and Alfredo Bautista,10.1177/02103702241253407,https://doi-org.crai.referencistas.com/10.1177/02103702241253407,Journal for the Study of Education and Development,2,408–441,Developing young children’s computational thinking through programming with a hybrid kit / Desarrollo del pensamiento computacional infantil a través de la programación con un kit híbrido,https://doi-org.crai.referencistas.com/10.1177/02103702241253407,47,2024i,
article,doi:10.1177/01626434221116077,,,10.1177/01626434221116077,https://doi-org.crai.referencistas.com/10.1177/01626434221116077,Journal of Special Education Technology,3,417–417,Corrigendum to “Providing Access and Opportunity for Computational Thinking and Computer Science to Support Mathematics for Students With Disabilities”,https://doi-org.crai.referencistas.com/10.1177/01626434221116077,38,2023j,
article,doi:10.1177/07356331221102312,"Block programming has been suggested as a way of engaging young learners with the foundations of programming and computational thinking in a syntax-free manner. Indeed, syntax errors—which form one of two broad categories of errors in programming, the other one being logic errors—are omitted while block programming. However, this does not mean that errors are omitted at large in such environments. In this exploratory case study of a learning environment for early programming (Kodetu), we explored errors in block programming of middle school students (N = 123), using log files drawn from a block-based online. Analyzing 1033 failed executions, we found that errors may be driven by either learners’ knowledge and behavior, or by the learning environment design. The rate of error types was not associated with the learners’ and contextual variables examined, with the exception of task complexity (as defined by SOLO taxonomy). Our findings highlight the importance of learning from errors and of learning environment design.",Anat Ben-Yaacov and Arnon Hershkovitz,10.1177/07356331221102312,https://doi-org.crai.referencistas.com/10.1177/07356331221102312,Journal of Educational Computing Research,1,178–207,"Types of Errors in Block Programming: Driven by Learner, Learning Environment",https://doi-org.crai.referencistas.com/10.1177/07356331221102312,61,2023a,
article,doi:10.1177/1729881418820425,"The development of skills related to computer programming and robotics and the introduction of computational thinking principles in high schools are worldwide trends today. An effective way of initiating young students in this world consists in proposing them stimulating challenges. This work presents a robotic platform that has been successfully used to develop a competition (called Drone Challenge) in which students had to program the navigation system for a simulated unmanned aerial vehicle (or drone). Both the competition and the supporting platform are described in detail. In particular, the article provides a deep technical description of the main components of the platform, namely the drone simulator and the navigation development framework. The results of the survey conducted after the challenge point to the suitability of the working platform deployed.",Aurelio Bermúdez and Rafael Casado and Guillermo Fernández and María Guijarro and Pablo Olivas,10.1177/1729881418820425,https://doi-org.crai.referencistas.com/10.1177/1729881418820425,International Journal of Advanced Robotic Systems,1,1729881418820425,Drone challenge: A platform for promoting programming and robotics skills in K-12 education,https://doi-org.crai.referencistas.com/10.1177/1729881418820425,16,2019b,
article,doi:10.1177/07356331241236882,"This research aimed to investigate the structural relationships among teachers’ computational thinking (CT), design thinking (DT), robotics teaching beliefs, and robotics pedagogical content knowledge (RPCK). A total of 98 in-service and pre-service teachers who participated in a robotics teaching professional development workshop served as the sample of the study. A survey including the Computational Thinking Scale, the Design Thinking Disposition Scale, the Robotics Teaching Beliefs Scale and the Technological Pedagogical Content Knowledge–Robotics Scale was conducted after the workshop. A confirmatory factor analysis was employed to validate the measurement constructs, and Partial Least Squares - Structural Equation Modeling (PLS-SEM) analysis was utilized to examine the relationships among the factors. The results revealed that both CT and DT dispositions could positively predict teachers’ robotics teaching beliefs, which subsequently predicted their RPCK. Moreover, a direct positive relationship between CT and RPCK was identified, while such a relationship was not evident for DT. The model demonstrates the critical role of CT in shaping teachers’ beliefs and pedagogical strategies of robotics teaching, and provides insights into the indirect influence of DT. Finally, the Model of Robotics Teaching Professional Development (MRTPD) was proposed to profile how to promote teachers’ pedagogical content knowledge of robotics teaching from their CT and DT dispositions.",Chung-Yuan Hsu and Meng-Jung Tsai,10.1177/07356331241236882,https://doi-org.crai.referencistas.com/10.1177/07356331241236882,Journal of Educational Computing Research,5,1159–1181,Predicting Robotics Pedagogical Content Knowledge: The Role of Computational and Design Thinking Dispositions via Teaching Beliefs,https://doi-org.crai.referencistas.com/10.1177/07356331241236882,62,2024c,
article,doi:10.1177/10534512211024939,"States increasingly are adopting computer science standards to help students develop coding and computational thinking skills. In an effort to support teachers in introducing computer science content to their students with high-incidence disabilities, a new model, computer science integration planning plus universal design for learning (CSIP+), offers ways to integrate computational thinking and coding into content area instruction. This column presents an example of how a teacher might implement the CSIP+ model when designing instruction accessible to all learners. Guiding questions to support teachers at each phase of the planning cycle are provided.",Amy Hutchison and Anya S. Evmenova,10.1177/10534512211024939,https://doi-org.crai.referencistas.com/10.1177/10534512211024939,Intervention in School and Clinic,4,262–267,Planning Computer Science Instruction for Students With High-Incidence Disabilities,https://doi-org.crai.referencistas.com/10.1177/10534512211024939,57,2022d,
article,doi:10.1177/14639491211033663,"Algorithms are the essence of computational thinking, which refers to a set of problem-solving processes that help children become logical thinkers in this increasingly digital society. It is important for teachers of young children to carefully plan and implement algorithm design tasks that involve repeated step-by-step procedures to build strong foundational computational thinking skills. In this article, the authors present algorithm tasks, including following a recipe, creating a treasure map, modeling how to perform a task, and sharing a routine, which can be easily integrated in the daily activities in early childhood classrooms. Fostering young children’s aptitude for algorithm-specific thinking-and-doing processes creates a foundation for logical thinking.",Joohi Lee and Candace Joswick and Kathryn Pole and Robin Jocius,10.1177/14639491211033663,https://doi-org.crai.referencistas.com/10.1177/14639491211033663,Contemporary Issues in Early Childhood,2,198–202,Algorithm design for young children,https://doi-org.crai.referencistas.com/10.1177/14639491211033663,23,2022e,
article,doi:10.1080/11356405.2017.1305075,"The pedagogical integration of computing is interesting in educational contexts based on the contributions of Seymour Papert and Wing’s concept of computational thinking. Integrating arts in education can lead to the design of activities using Scratch combined with devices. The main goal is to evaluate the integration of computational thinking in art education making use of technological resources, sensor cards and minicomputers, with a student-centred pedagogical approach. This research assesses the results of a control group of 35 students and an experimental group of 109 students in four different schools, using Mann-Whitney’s U-test for independent samples assessing ‘Active Learning’, ‘computational concepts’ and ‘fun’ scales. Applying data triangulation, and consistent with design-based research, the results of interviews and focus groups reinforced the results obtained in the aforementioned test, providing validity to the study. There are advantages regarding student interest, motivation and commitment related to programming technologies in art and education, particularly pedagogical sessions with music. Handling devices, sensors and Raspberry Pi provides participating students with a factor of commitment and enthusiasm, with significant improvements. Working with coding and devices brings an additional advantage in the development of computational thinking and digital competence. The results show an increase in creativity and artistic competence related to the ability to create music from the activities and technological resources described in the technological intervention.",José-Manuel Sáez-López and María-Luisa Sevillano-García,10.1080/11356405.2017.1305075,https://doi-org.crai.referencistas.com/10.1080/11356405.2017.1305075,Culture and Education,2,350–384,"Sensors, programming and devices in Art Education sessions. One case in the context of primary education / Sensores, programación y dispositivos en sesiones de Educación Artística. Un caso en el contexto de Educación Primaria",https://doi-org.crai.referencistas.com/10.1080/11356405.2017.1305075,29,2017f,
article,doi:10.1177/14780771221139911,"In a problem-based, digital-intensive learning environment, the increased proliferation of computational tools used for architectural design has led to a fundamental transformation in architectural studios. Many studies have shown that this has significantly led to the change in cognition of design environments in academia. Design decisions are made through a recursive process that is cyclically refined by allowing constant feedback and testing. This paper represents an observational study with an aim to understand the impact of digital mediums on design processes and design outcomes focusing on associative modeling using VPL. It contextualizes the difference, the associative modeling system as a parametric subset brings to design thinking when used as a medium to explore architectural design. It analyzes specific attributes of associative modeling, otherwise native to computational thinking, that contribute to the legibility of the design process. The paper demonstrates how associative modeling allows the design process to be examined and edited at any stage during and even after algorithmic development, bringing in flexibility. It is argued that digital design tool affordances enable students to develop multilayered and more structured design logic that augments cognition bringing more legibility to the design thinking process.",Dhanashree Sardeshpande and Vasudha Gokhale,10.1177/14780771221139911,https://doi-org.crai.referencistas.com/10.1177/14780771221139911,International Journal of Architectural Computing,4,728–741,“Legibility” a product of obligatory processes in parametric architectural design: A study of implications of associative modeling on design thinking in a parametric architectural design studio,https://doi-org.crai.referencistas.com/10.1177/14780771221139911,20,2022g,
article,doi:10.1177/1076217519880587,"The Thunkable online platform is an easy-to-use resource for creating apps for mobile devices. Computational thinking is at the heart of problem solving in computer science, and research suggests students’ computational thinking improves when they use simple block coding systems similar to the format used for Thunkable.",Del Siegle,10.1177/1076217519880587,https://doi-org.crai.referencistas.com/10.1177/1076217519880587,Gifted Child Today,1,64–71,"There’s an App for That, and I Made It",https://doi-org.crai.referencistas.com/10.1177/1076217519880587,43,2020h,
article,doi:10.1177/21582440231205409,"The cultivation of computational thinking and programing education have gained prominence in K-12 education worldwide. Primary school teachers should be proficient in visual programing and using microcontrollers to teach programing courses. To cope with these trends, a learning activity was developed and implemented in Taiwan’s primary teacher education curriculum. The activity aimed to help preservice primary teachers learn about Scratch visual programing and micro:bit microcontroller boards by engaging in a physical computing project involving the design of an educational motion sensor game about energy. The results of the preliminary study found that the preservice primary teachers who participated in the activity were able to collaborate and develop motion sensor games suitable for primary school students. They also demonstrated significant improvements in their computational thinking concepts (t(10) = 3.13, p < .05) and energy knowledge test scores (t(10) = 2.74, p < .05). Furthermore, most participants expressed satisfaction with the activity, implying the activity’s feasibility for teacher education.",Fu-Hsing Tsai,10.1177/21582440231205409,https://doi-org.crai.referencistas.com/10.1177/21582440231205409,Sage Open,4,21582440231205410,Using a Physical Computing Project to Prepare Preservice Primary Teachers for Teaching Programing,https://doi-org.crai.referencistas.com/10.1177/21582440231205409,13,2023i,
article,doi:10.1177/07356331231225468,"The relationship between computational thinking (CT) and academic self-efficacy for building students’ academic resilience—a trait crucial for problem-solving, peer relationships, and confidence development—was investigated. A mixed-methods approach was employed in a study involving 60 participants; half were given CT instruction and half were instructed traditionally. Quantitative data were analyzed using analysis of covariance and path analysis, while MAXQDA software was employed for qualitative interview data. The study found a positive correlation between CT instruction and academic self-efficacy with increased academic resilience, particularly in the experimental group, and identified key factors contributing to resilience. This study demonstrates the effectiveness of computational thinking (CT) and academic self-efficacy in enhancing academic performance, offering a new understanding of how these elements can be integrated into education to boost student resilience. It establishes a direct empirical link between CT instruction and increased academic self-efficacy, underscoring the value of specific teaching methodologies in fostering resilience. The findings are significant for educators, policymakers, and stakeholders in developing strategies to enhance students’ academic and personal success, thereby promoting their overall well-being. Recognizing the importance of CT and self-efficacy paves the way for customized educational programs that effectively support and empower students to thrive.",Ting-Ting Wu and Lusia Maryani Silitonga and Budi Dharmawan and Astrid Tiara Murti,10.1177/07356331231225468,https://doi-org.crai.referencistas.com/10.1177/07356331231225468,Journal of Educational Computing Research,3,816–845,Empowering Students to Thrive: The Role of CT and Self-Efficacy in Building Academic Resilience,https://doi-org.crai.referencistas.com/10.1177/07356331231225468,62,2024j,
